<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on hnakamur&#39;s blog at github</title>
    <link>/blog/post/</link>
    <description>Recent content in Posts on hnakamur&#39;s blog at github</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-JP</language>
    <lastBuildDate>Thu, 11 Aug 2016 22:58:21 +0900</lastBuildDate>
    <atom:link href="/blog/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>LXDのDHCPで使っていないIPアドレスを一括で解放するスクリプトを書いた</title>
      <link>/blog/2016/08/11/release-all-unused-addresses-of-lxd-bridge/</link>
      <pubDate>Thu, 11 Aug 2016 22:58:21 +0900</pubDate>
      
      <guid>/blog/2016/08/11/release-all-unused-addresses-of-lxd-bridge/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;/blog/blog/2016/05/07/how-to-use-fixed-ip-address-for-a-lxd-container/&#34;&gt;LXDコンテナで固定IPアドレスを使うための設定 · hnakamur&amp;rsquo;s blog at github&lt;/a&gt; の設定を行ってもIPアドレスが指定通りにならないことがありました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;journal -xe&lt;/code&gt; で見てみると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Aug 11 22:46:55 bai1b7faf04 dnsmasq-dhcp[11082]: not using configured address 10.155.92.102 because it is leased to 00:16:3e:1e:08:8a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;というメッセージが出ていて、他のMACアドレスに貸出中になっています。&lt;/p&gt;

&lt;p&gt;ググってみると &lt;a href=&#34;http://www.linuxquestions.org/questions/linux-newbie-8/dnsmasq-force-release-renew-of-dhcp-clients-how-933535/&#34;&gt;[SOLVED] dnsmasq force release/renew of dhcp clients, how?&lt;/a&gt; に回答がありました。&lt;/p&gt;

&lt;h2 id=&#34;使っていないipアドレスを手動で消す&#34;&gt;使っていないIPアドレスを手動で消す&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl stop lxd-bridge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で止めて&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo vi /var/lib/lxd-bridge/dnsmasq.lxdbr0.leases
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で使っていないIPアドレスの行を全て削除します。&lt;/p&gt;

&lt;p&gt;その後&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl start lxd-bridge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で再起動します。&lt;/p&gt;

&lt;h2 id=&#34;自動で消すスクリプトも書きました&#34;&gt;自動で消すスクリプトも書きました&lt;/h2&gt;

&lt;p&gt;これでよいかと思ったら、
&lt;a href=&#34;http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2013q3/007356.html&#34;&gt;http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2013q3/007356.html&lt;/a&gt;
を見て &lt;code&gt;dhcp_release&lt;/code&gt; というコマンドを使えば &lt;code&gt;lxd-bridge&lt;/code&gt; の再起動が不要なことを知りました。&lt;/p&gt;

&lt;p&gt;ということでスクリプトを書いてみました。
&lt;a href=&#34;https://gist.github.com/hnakamur/7ed3f7c6175817b633586a1b468bd5c1&#34;&gt;https://gist.github.com/hnakamur/7ed3f7c6175817b633586a1b468bd5c1&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh
set -eu

# Set value of LXD_BRIDGE
. /etc/default/lxd-bridge

addr_list_file=/tmp/lxd-addr-list.`date +%Y-%m-%dT%H:%M:%S`
lxc list | awk &#39;$4==&amp;quot;RUNNING&amp;quot;{print $6}&#39; &amp;gt; $addr_list_file
cleanup() {
  rm $addr_list_file
}
trap cleanup EXIT

awk -v addr_list_file=$addr_list_file -v interface=$LXD_BRIDGE &#39;{
  mac_addr = $2
  addr = $3
  ret = system(sprintf(&amp;quot;awk -v addr=%s &#39;\&#39;&#39;BEGIN{rc=1} $1==addr{rc=0} END{exit rc}&#39;\&#39;&#39; %s&amp;quot;, addr,  addr_list_file))
  if (ret == 1) {
    system(sprintf(&amp;quot;sudo dhcp_release %s %s %s&amp;quot;, interface, addr, mac_addr))
  }
}&#39; /var/lib/lxd-bridge/dnsmasq.$LXD_BRIDGE.leases
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ubuntu 16.04 の場合 &lt;code&gt;dhcp_release&lt;/code&gt; コマンドを使うには以下のように &lt;code&gt;dnsmasq-utils&lt;/code&gt; パッケージをインストールする必要があります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt -y install dnsmasq-utils
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ブログ記事「Go言語(Golang) はまりどころと解決策」についてのコメント</title>
      <link>/blog/2016/08/02/about-go-pitfalls/</link>
      <pubDate>Tue, 02 Aug 2016 05:57:52 +0900</pubDate>
      
      <guid>/blog/2016/08/02/about-go-pitfalls/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://www.yunabe.jp/docs/golang_pitfall.html&#34;&gt;Go言語(Golang) はまりどころと解決策&lt;/a&gt;の記事についてのコメント記事を誰かが書くだろうと思ってスルーしてましたが、見かけないので書いてみます。&lt;/p&gt;

&lt;p&gt;ただし私はGo言語を使って開発していますが、言語自体を詳細に知るエキスパートでは無いです。Go言語にかぎらず個人的にはややこしいところにはなるべく近づかないスタンスなので、詳しい方から見ると物足りないかもしれません。そう感じた方は是非ブログ記事なりを書いていただけると嬉しいです。&lt;/p&gt;

&lt;h2 id=&#34;interface-とnil-goのinterfaceは単なる参照ではない&#34;&gt;interface とnil (Goのinterfaceは単なる参照ではない)&lt;/h2&gt;

&lt;p&gt;特にコメントはなくてそのとおりだと思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/doc/faq&#34;&gt;Frequently Asked Questions (FAQ)&lt;/a&gt;に加えて &lt;a href=&#34;https://golang.org/doc/effective_go.html&#34;&gt;Effective Go&lt;/a&gt;も早めに読んでおいたほうが良いと思います。&lt;/p&gt;

&lt;p&gt;またnilに関する文献としては &lt;a href=&#34;https://speakerdeck.com/campoy/understanding-nil&#34;&gt;Understanding Nil // Speaker Deck&lt;/a&gt; もおすすめです。&lt;/p&gt;

&lt;h2 id=&#34;メソッド内でレシーバ-this-self-がnilでないことをチェックすることに意味がある&#34;&gt;メソッド内でレシーバ(this, self)がnilでないことをチェックすることに意味がある&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/ref/spec#Method_declarations&#34;&gt;Method declarations&lt;/a&gt; に&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The type of a method is the type of a function with the receiver as first argument.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;とあります。メソッドの型はメソッドの引数の前にレシーバを第一引数として入れた関数の型になるとのことです。&lt;/p&gt;

&lt;p&gt;大雑把に言えば、メソッドは第一引数にレシーバを追加した関数と実質同じです。と考えればメソッド内でポインタ型のレシーバのnilチェックをすることは特に違和感ないと思います。&lt;/p&gt;

&lt;h2 id=&#34;errorしか返り値がない関数でerrorを処理し忘れる&#34;&gt;errorしか返り値がない関数でerrorを処理し忘れる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/alecthomas/gometalinter&#34;&gt;alecthomas/gometalinter&lt;/a&gt;でチェックできました。&lt;/p&gt;

&lt;p&gt;実行例を示します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ gometalinter 
main.go:8:6:warning: exported type Data should have comment or be unexported (golint)
main.go:4:2:error: could not import encoding/json (reading export data: /usr/local/go1.7rc3/pkg/linux_amd64/encoding/json.a: unknown version: v1json    E$GOROOT/src/encoding/json/decode.go?Un) (gotype)
-$GOROOT/src/fmt/scan.go not impStatr) (gotype)g export data: /usr/local/go1.7rc3/pkg/linux_amd64/fmt.a: unknown version: v1fmt
main.go:14:2:error: undeclared name: json (gotype)
main.go:15:2:error: undeclared name: fmt (gotype)
main.go:14:16:warning: error return value not checked (json.Unmarshal([]byte(&amp;quot;not json&amp;quot;), d)) (errcheck)
main.go:9:2:warning: unused struct field github.com/hnakamur/forgotten-error-experiment.Data.a (structcheck)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;jsonやfmt関連のエラーは何言ってるのかよくわからないで無視するとして&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;main.go:14:16:warning: error return value not checked (json.Unmarshal([]byte(&amp;quot;not json&amp;quot;), d)) (errcheck)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で error の戻り値がチェックされていないことを指摘されています。&lt;/p&gt;

&lt;p&gt;gometalinterのセットアップと使い方は&lt;a href=&#34;http://qiita.com/spiegel-im-spiegel/items/238f6f0ee27bdf1de2a0&#34;&gt;gometalinter で楽々 lint - Qiita&lt;/a&gt;にわかりやすい記事がありました。&lt;/p&gt;

&lt;h2 id=&#34;基本型がメソッドを持たない&#34;&gt;基本型がメソッドを持たない&lt;/h2&gt;

&lt;p&gt;FAQの&lt;a href=&#34;https://golang.org/doc/faq#methods_on_basics&#34;&gt;Why is len a function and not a method?&lt;/a&gt;によると &lt;code&gt;len&lt;/code&gt; などをメソッドにすることも検討したけど、 &lt;code&gt;len&lt;/code&gt; がメソッドではなく関数でも実用上困らないし、そのほうが基本型の (Go言語の型の意味での) インタフェースについての質問を複雑にしないので、 &lt;code&gt;len&lt;/code&gt; などは関数として実装することにしたそうです。&lt;/p&gt;

&lt;p&gt;「インタフェースについての質問」あたりはとりあえずそう訳しましたが、意味はよくわかりません。詳しい方のコメントを期待したいところです。&lt;/p&gt;

&lt;h2 id=&#34;stringが単なるバイト列&#34;&gt;stringが単なるバイト列&lt;/h2&gt;

&lt;p&gt;「正直本当に正しいのかはよく分かりません」については私は正しいかどうかという話というよりは、Go言語ではそう決めたというだけの話かと思っています。&lt;/p&gt;

&lt;p&gt;言語の利用者がハマりにくい決定をするほうが望ましいという意味で「正しいか」と言われているのだとは思いますが、私自身はほぼ常にUTF-8の文字列しか使ってないので特にハマったことはないです。&lt;/p&gt;

&lt;p&gt;文字コード変換には&lt;a href=&#34;https://github.com/golang/text&#34;&gt;golang/text: [mirror] Go text processing support&lt;/a&gt;というパッケージがあります。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;io.Reader&lt;/code&gt; からEUC-JP, Shift_JIS, ISO-2022-JPの文字列を読み込んで UTF-8に変換するのは&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/goqueryja/blob/01aead01dd3ac586c6256140a26a50fb30451971/lib.go#L27-L40&#34;&gt;https://github.com/hnakamur/goqueryja/blob/01aead01dd3ac586c6256140a26a50fb30451971/lib.go#L27-L40&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;というコードで実現できます。&lt;/p&gt;

&lt;h2 id=&#34;継承がない&#34;&gt;継承がない&lt;/h2&gt;

&lt;p&gt;継承を敢えて排除したのはGoの好きな点の1つです。&lt;/p&gt;

&lt;h2 id=&#34;genericsがない&#34;&gt;Genericsがない&lt;/h2&gt;

&lt;p&gt;私が他の言語で知ってるのはJavaのGenericsとHaskellの型クラスです。Haskellは軽く勉強した程度ですが、型クラスはシンプルで汎用的で美しさを感じました。&lt;/p&gt;

&lt;p&gt;一方Javaは10年近く仕事で書いてましたが、 &lt;code&gt;? extends&lt;/code&gt; とか &lt;code&gt;? super&lt;/code&gt; のあたりはよくわからなくて避けてました。当時はそれでも困らなかったです。&lt;/p&gt;

&lt;p&gt;複雑なものが苦手な私としては、Javaのような複雑さになるぐらいならGenericsは無いほうが良いと思うので、Goの決断は私は賛成です。&lt;/p&gt;

&lt;p&gt;Genericsが無いとMap, Each, Selectのような関数を []interface{} に対して書いてみたくなると思います。 &lt;a href=&#34;http://qiita.com/hnakamur/items/76b06603013279b14aeb&#34;&gt;goでEach, Map, Selectのサンプル - Qiita&lt;/a&gt;で私も昔書いてみました。でも&lt;a href=&#34;http://qiita.com/hnakamur/items/76b06603013279b14aeb#comment-3d16d66e68bad9626f56&#34;&gt;コメント&lt;/a&gt;に書いたように、Goの開発者のRob Pikeさんもこういう関数は使わずに &lt;code&gt;for&lt;/code&gt; ループを使うべきと書かれています。&lt;/p&gt;

&lt;p&gt;Goに入ってはGoに従え (When in Go, do as the gophers do) ということで &lt;code&gt;for&lt;/code&gt; で書くのが良いと思います。&lt;/p&gt;

&lt;h2 id=&#34;goroutine-はgcされない&#34;&gt;goroutine はGCされない&lt;/h2&gt;

&lt;p&gt;同意です。&lt;/p&gt;

&lt;p&gt;Dave Cheneyさんのツイート
&lt;a href=&#34;https://twitter.com/davecheney/status/714053897841577985&#34;&gt;https://twitter.com/davecheney/status/714053897841577985&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;とスライド
&lt;a href=&#34;https://github.com/davecheney/high-performance-go-workshop/blob/ee2e7a82092a72d742b12b00308b0145f124d593/high-performance-go-workshop.slide#L648-L658&#34;&gt;https://github.com/davecheney/high-performance-go-workshop/blob/ee2e7a82092a72d742b12b00308b0145f124d593/high-performance-go-workshop.slide#L648-L658&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;にある&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Never start a goroutine without knowing how it will stop.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;というルールを守るのが良い習慣だと思います。&lt;/p&gt;

&lt;h2 id=&#34;goroutineはgenerator-yield-の実装には使えない&#34;&gt;goroutineはgenerator (yield) の実装には使えない&lt;/h2&gt;

&lt;p&gt;内容自体は同意です。&lt;/p&gt;

&lt;p&gt;ちょっと脱線になりますが、こういう他の言語の仕組みを同じようなものを作ろうとするのは、そもそもGoの文化になじまないです。Goは他の言語では常識とされている仕組みも一から吟味して取捨選択して最低限のものだけを残して、それ以外は敢えて含めていないと感じていて、ミニマリストな私には非常に魅力的です。&lt;/p&gt;

&lt;p&gt;less is moreの精神を感じます。言語の仕組みが最低限で、同じようなことは同じように書くことになるので、サードパーティのライブラリなど人のコードを読むときに非常に読みやすいというメリットがあります。&lt;/p&gt;

&lt;p&gt;また、自分でコードを書くときにも、似たようなことを実現するために複数の仕組みがあるとこのケースではどれを選ぶべきかと考える必要がありますが、決まったパターンがあれば悩む時間がありません。&lt;/p&gt;

&lt;p&gt;この結果Go言語だと言語でどう書くかよりもアプリケーションやライブラリの問題領域の方に注力しやすいと感じています。&lt;/p&gt;

&lt;p&gt;yieldみたいなことはせずに、goroutineを複数動かしてchannelでデータをやり取りするか、変数を sync.Mutex などで排他制御してデータをやり取りするのがGo流だと思います。あるいは簡単なイテレータなら関数を返すような関数で実現可能だと思います。&lt;/p&gt;

&lt;h2 id=&#34;例外が-推奨され-ない&#34;&gt;例外が(推奨され)ない&lt;/h2&gt;

&lt;p&gt;Java, Python, Rubyなどを書いていた私としても例外がないのは不便なのではと最初は思いましたが、今では err が戻り値で毎回&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if err != nil {
   return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と書くほうが、エラーの処理漏れが無いことが明確で安心感を感じます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/errors-are-values&#34;&gt;Errors are values - The Go Blog&lt;/a&gt;のbufioのScannerのようにエラーがチェックする関数が別になっている例もあります。が、個人的には、記事中にある、もしもの例で &lt;code&gt;Scan()&lt;/code&gt; がエラーも返す例のほうがわかりやすいと思います。&lt;/p&gt;

&lt;p&gt;というのも、初めて &lt;code&gt;bufio.Scanner&lt;/code&gt; のドキュメントを見た時は &lt;code&gt;Err()&lt;/code&gt; の存在に気づいて無かったです。ただし、 &lt;a href=&#34;https://golang.org/pkg/bufio/#Scanner&#34;&gt;https://golang.org/pkg/bufio/#Scanner&lt;/a&gt; の Example (Lines) とかを見れば &lt;code&gt;Err()&lt;/code&gt; を使ったサンプルコードが書いてあるんですけどね。&lt;/p&gt;

&lt;p&gt;余談ですけど、APIドキュメントに Example でサンプルコードがついているときは必ず見たほうが良いです。関数のシグネチャ見ただけでは気づかない使い方が説明されていることが多いので。&lt;/p&gt;

&lt;p&gt;エラー処理は&lt;a href=&#34;https://blog.golang.org/error-handling-and-go&#34;&gt;Error handling and Go - The Go Blog&lt;/a&gt;のブログ記事も読みましょう。&lt;/p&gt;

&lt;p&gt;あと &lt;code&gt;panic&lt;/code&gt; と &lt;code&gt;recover&lt;/code&gt; で例外もどきを実現しようとするのも止めましょう。私は &lt;code&gt;recover&lt;/code&gt; は一度足りとも使ったことが無いです。&lt;/p&gt;

&lt;p&gt;panic はエラーがほぼ起きないケースでerrorをreturnして呼び出し側で処理したくないケースは使うこともあります。panicすると標準エラー出力にエラーメッセージとスタックトレースが出力されて異常終了します。&lt;/p&gt;

&lt;p&gt;Goのアプリケーションをsystemdから起動する場合は、panicするとjournalctlでログが見られてそちらで発生日時もわかるので、それでチェックしています。&lt;/p&gt;

&lt;h2 id=&#34;繰り返す-if-err-nil-return-err&#34;&gt;繰り返す if err != nil {return err}&lt;/h2&gt;

&lt;p&gt;ひとつ前の「例外が(推奨され)ない」にまとめて書きました。
個人的には同じパターンで繰り返すほうが、ケースバイケースで書き方が違うより、読みやすいです。&lt;/p&gt;

&lt;h2 id=&#34;return-nil-err-このerrorどこで発生したの&#34;&gt;return nil, err → このerrorどこで発生したの？&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;if err != nil {
  return nil, fmt.Errorf(&amp;quot;Some context: %v&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でコンテキストを追加するのがGo流らしいです。&lt;/p&gt;

&lt;p&gt;でも個人的にはスタックトレースのほうが楽だと感じます。あと個人的にはエラーが起きた地点での関連する変数もログ出力したいので、自作のログライブラリでは
&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LTSVLogger.ErrorWithStack&#34;&gt;func (l *LTSVLogger) ErrorWithStack(lv &amp;hellip;LV)&lt;/a&gt; というメソッドを用意して、エラーが起きた箇所でメッセージと変数の値とスタックトレースを出力するようにしています。&lt;/p&gt;

&lt;h2 id=&#34;関数より狭いスコープで-defer&#34;&gt;関数より狭いスコープで defer&lt;/h2&gt;

&lt;p&gt;わかりやすい名前がつけられるケースならprivateの関数に切り出してそちらでdeferするようにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func myFuncHelper(filename string) (*dataType, error) {
  r, err := os.Open(filename)
  if err != nil {
    return err
  }
  defer r.Close()
  data, err := readDataFromReader(r)  // 実際にはもう少し複雑な処理
  if err != nil {
    return nil, err
  }
  return data, nil
}

func myFunc() error {
  data, err := myFunHelper(filename)
  if err != nil {
    return err
  }
  // その後の他の処理
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとエラーで抜けるケースが少なければdeferを使わずに &lt;code&gt;Close()&lt;/code&gt; を呼べば良いと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func myFunc() error {
  // ...
  r, err := os.Open(filename)
  if err != nil {
    return err
  }
  data, err := readDataFromReader(r)  // 実際にはもう少し複雑な処理
  if err != nil {
    r.Close()
    return err
  }
  r.Close()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;「実際にはもう少し複雑な処理」と書いているので、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  if err != nil {
    r.Close()
    return err
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;が何回も出てくるのでしょうが、多すぎと感じたら別の方法を考える感じで。&lt;/p&gt;

&lt;h2 id=&#34;structとc-javaのクラスとの違い&#34;&gt;structとC++/Javaのクラスとの違い&lt;/h2&gt;

&lt;h3 id=&#34;コンストラクタがない&#34;&gt;コンストラクタがない&lt;/h3&gt;

&lt;p&gt;コンストラクタは無いので &lt;code&gt;NewSomething&lt;/code&gt; とか &lt;code&gt;somepackage.New&lt;/code&gt; のような関数を定義する習慣というのはその通りです。&lt;/p&gt;

&lt;h3 id=&#34;ゼロ初期化が避けられない&#34;&gt;ゼロ初期化が避けられない&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;structが外部に公開されるのならばstructは全てがゼロ初期化された場合にも正しく動くように常に設計しなくてはならないのです。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;これは現実には無理だと思います。例えばファイル名のフィールドのstringが空文字だった時にはどのファイルを処理すれば良いかはわかりっこないです。zero valueでも構わないフィールドについては、zero valueだとどう解釈されるかをAPIドキュメントに書いておけば良い話です。それ以外は呼び出し側が設定する責任があるということで。&lt;/p&gt;

&lt;h3 id=&#34;コピーされるのが避けられない&#34;&gt;コピーされるのが避けられない&lt;/h3&gt;

&lt;p&gt;Go言語自体にコピー防止の仕組みを入れる議論はあったようです。&lt;a href=&#34;https://github.com/golang/go/issues/8005&#34;&gt;runtime: add NoCopy documentation struct type? · Issue #8005 · golang/go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;このスレッドの&lt;a href=&#34;https://github.com/golang/go/issues/8005#issuecomment-190753527&#34;&gt;コメント&lt;/a&gt;で実現する方法が紹介されています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/valyala/fasthttp&#34;&gt;valyala/fasthttp&lt;/a&gt;ではこの技を使っていて
&lt;a href=&#34;https://github.com/valyala/fasthttp/blob/master/nocopy.go&#34;&gt;fasthttp/nocopy.go&lt;/a&gt;に &lt;code&gt;noCopy&lt;/code&gt; の定義があり、 &lt;a href=&#34;https://github.com/valyala/fasthttp/blob/45697fe30a130ec6a54426a069c82f3abe76b63d/http.go#L16-L45&#34;&gt;https://github.com/valyala/fasthttp/blob/45697fe30a130ec6a54426a069c82f3abe76b63d/http.go#L16-L45&lt;/a&gt; に使用例があります。&lt;/p&gt;

&lt;h2 id=&#34;型が後置&#34;&gt;型が後置&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/gos-declaration-syntax&#34;&gt;Go&amp;rsquo;s Declaration Syntax - The Go Blog&lt;/a&gt; で理由が説明されています。&lt;/p&gt;

&lt;h2 id=&#34;1-0-が浮動小数点型にならない-時がある&#34;&gt;1.0 が浮動小数点型にならない(時がある)&lt;/h2&gt;

&lt;p&gt;これは知りませんでした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;e := float64(a / 3.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と書けば回避できました。 &lt;a href=&#34;https://play.golang.org/p/Y7_LUdQeeq&#34;&gt;https://play.golang.org/p/Y7_LUdQeeq&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;名前が&#34;&gt;名前が…&lt;/h2&gt;

&lt;p&gt;golang で検索すればOKです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LXDコンテナでPostgreSQLの非同期リプリケーションを試してみた</title>
      <link>/blog/2016/07/23/tried-postgresql-async-replication-in-lxd-containers/</link>
      <pubDate>Sat, 23 Jul 2016 21:13:52 +0900</pubDate>
      
      <guid>/blog/2016/07/23/tried-postgresql-async-replication-in-lxd-containers/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://lets.postgresql.jp/documents/technical/replication/1/&#34;&gt;ストリーミング・レプリケーションの構築 — Let&amp;rsquo;s Postgres&lt;/a&gt; と &lt;a href=&#34;http://d.hatena.ne.jp/hiroe_orz17/20111113/1321180635&#34;&gt;PostgreSQL9.1ためしてみた【非同期レプリケーション編】 - ごろねこ日記&lt;/a&gt; を読んで、2台のLXDコンテナを使ってPostgreSQLの非同期リプリケーションを試してみたのでメモです。&lt;/p&gt;

&lt;p&gt;また&lt;a href=&#34;https://www.packtpub.com/big-data-and-business-intelligence/postgresql-replication-second-edition&#34;&gt;PostgreSQL Replication - Second Edition | PACKT Books&lt;/a&gt;が $10 と安かったので、買って非同期レプリケーションの章まで読みました。&lt;/p&gt;

&lt;p&gt;手順はAnsible playbookとしてまとめました。 &lt;a href=&#34;https://github.com/hnakamur/postgresql-async-replication-example-playbook&#34;&gt;hnakamur/postgresql-async-replication-example-playbook&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ansible.cfg&lt;/code&gt; で &lt;code&gt;ask_vault_pass = True&lt;/code&gt; と指定しているので、プレイブック実行時に &lt;code&gt;Vault password:&lt;/code&gt; と聞かれます。パスワードは &lt;code&gt;password&lt;/code&gt; です。サンプルなので単純なパスワードにしていますが、実案件でのプレイブックはきちんとしたパスワードをつけています。&lt;/p&gt;

&lt;h2 id=&#34;テスト環境構築&#34;&gt;テスト環境構築&lt;/h2&gt;

&lt;p&gt;ホストマシンのディストリビューションはUbuntu 16.04でLXD 2.0.3, curl, jqをインストール済みの状態で試しました。&lt;/p&gt;

&lt;p&gt;作業ディレクトリを作って、そこに移動し上記のプレイブックを取得します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/hnakamur/postgresql-async-replication-example-playbook
cd postgresql-async-replication-example-playbook
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;lxd_container&lt;/code&gt; モジュールを使うため、 github から最新のAnsibleをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;virtualenv venv
source venv/bin/activate
pip install git+https://github.com/ansible/ansible
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;masterとstandbyのコンテナを作成&#34;&gt;masterとstandbyのコンテナを作成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook launch_containers.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行すると &lt;code&gt;development&lt;/code&gt; というインベントリファイルを生成します。初期状態ではコンテナ &lt;code&gt;pgsql1&lt;/code&gt; が master, コンテナ &lt;code&gt;pgsql2&lt;/code&gt; が standby になります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[development]
pgsql1 postgresql_peer_ipaddr=10.155.92.234 postgressql_master_standby_type=master
pgsql2 postgresql_peer_ipaddr=10.155.92.202 postgressql_master_standby_type=standby

[development:vars]
ansible_connection=lxd
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コンテナ内にpostgresqlの非同期レプリケーションの環境設定&#34;&gt;コンテナ内にPostgreSQLの非同期レプリケーションの環境設定&lt;/h2&gt;

&lt;p&gt;以下のコマンドを実行してセットアップを実行します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook initial_setup.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完了したら、2つ端末を開いて片方で&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lxc exec pgsql1 bash
sudo -u postgres -i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行し、もう片方で&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lxc exec pgsql2 bash
sudo -u postgres -i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行し、データベースを作ったり pgbench を動かしたりして変更が同期されるのを確認します。&lt;/p&gt;

&lt;p&gt;test というデータベースを作ってpgbenchを実行する手順は以下の通りです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;createdb test
/usr/pgsql-9.5/bin/pgbench -i test
/usr/pgsql-9.5/bin/pgbench -T 180 test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記の手順を1歩ずつ試し、 test データベースを作る前は pgsql2 では &lt;code&gt;psql test&lt;/code&gt; が失敗しますが作った後は成功するなどで同期が確認できます。&lt;/p&gt;

&lt;h2 id=&#34;レプリケーションの状態確認&#34;&gt;レプリケーションの状態確認&lt;/h2&gt;

&lt;h3 id=&#34;master側での確認&#34;&gt;master側での確認&lt;/h3&gt;

&lt;p&gt;以下のコマンドを実行します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;watch -n 0.5 &#39;psql -x -c &amp;quot;SELECT * FROM pg_stat_replication&amp;quot;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じで確認できます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Every 0.5s: psql -x -c &amp;quot;SELECT * FROM pg_stat_replication&amp;quot;         Sat Jul 23 12:47:27 2016

-[ RECORD 1 ]----+------------------------------
pid              | 2160
usesysid         | 16384
usename          | repl_user
application_name | walreceiver
client_addr      | 10.155.92.234
client_hostname  |
client_port      | 44822
backend_start    | 2016-07-23 08:34:43.696331+00
backend_xmin     |
state            | streaming
sent_location    | 0/30031E0
write_location   | 0/30031E0
flush_location   | 0/30031E0
replay_location  | 0/30031E0
sync_priority    | 0
sync_state       | async
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;standby側での確認&#34;&gt;standby側での確認&lt;/h3&gt;

&lt;p&gt;以下のコマンドを実行します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;watch -n 0.5 &#39;ps auxww | grep &amp;quot;[p]ostgres:&amp;quot;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんな感じで確認できます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Every 0.5s: ps auxww | grep &amp;quot;[p]ostgres:&amp;quot;                                   Sat Jul 23 12:49:30 2016
ailabl
postgres  2051  0.0  0.0  86736  3420 ?        Ss   08:34   0:00 postgres: logger process
postgres  2052  0.0  0.0 233948  5996 ?        Ss   08:34   0:00 postgres: startup process   recover
ing 000000010000000000000003
postgres  2071  0.0  0.0 234012  7016 ?        Ss   08:34   0:00 postgres: checkpointer process
postgres  2072  0.0  0.0 233912  5916 ?        Ss   08:34   0:00 postgres: writer processl
postgres  2073  0.0  0.0  88856  3444 ?        Ss   08:34   0:00 postgres: stats collector process

postgres  2078  0.0  0.0 240632  7016 ?        Ss   08:34   0:05 postgres: wal receiver process   st
reaming 0/30031E0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;フェイルオーバー&#34;&gt;フェイルオーバー&lt;/h2&gt;

&lt;p&gt;masterのPostgreSQLを停止し、 standbyをmasterにpromote (昇格)させます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook failover.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;旧masterを新standbyとして稼働再開&#34;&gt;旧masterを新standbyとして稼働再開&lt;/h2&gt;

&lt;p&gt;ここでインベントリファイル &lt;code&gt;development&lt;/code&gt; 内の &lt;code&gt;postgressql_master_standby_type&lt;/code&gt; 変数の &lt;code&gt;master&lt;/code&gt; と &lt;code&gt;standby&lt;/code&gt; を入れ替えます。&lt;/p&gt;

&lt;p&gt;その後、新standbyのPostgreSQLを起動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook start_new_standby.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もし復旧できない自体になった場合は、今のstandbyであるpgsql1 のデータディレクトリを退避して一からリプリケーション環境を構築します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lxc exec pgsql1 -- mv /var/lib/pgsql/9.5/data /var/lib/pgsql/9.5/data.bak
ansible-playbook initial_setup.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;フェイルバック&#34;&gt;フェイルバック&lt;/h2&gt;

&lt;p&gt;masterとstandbyを入れ替えているので、フェイルバックの手順はフェイルオーバーと同じです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook failover.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;コンテナの削除&#34;&gt;コンテナの削除&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;ansible-playbook delete_containers.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ansible-vaultを使う際の変数命名規則のtips&#34;&gt;Ansible vaultを使う際の変数命名規則のtips&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ansible-vault encrypt&lt;/code&gt; で暗号化したファイルの内容を確認するには &lt;code&gt;ansible-vault decrypt&lt;/code&gt; で復号化する必要があります。どんな変数があったかを確認する度に行うのは面倒なので、以下のように暗号化するファイル内で定義する変数を一旦別の変数で受け取ってplaybookではそれを参照するようにしました。&lt;/p&gt;

&lt;p&gt;playbookの構成として環境ごとに development, production のようにグループを分けるようにしています（このサンプルでは development だけです）。暗号化するファイルとしないファイルを以下のような配置で作っています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;group_vars/development/secrets.yml
group_vars/development/vars.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;group_vars/development/secrets.yml&lt;/code&gt; では&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;development:
  secrets:
    postgresql_replication_password: _YOUR_PASSWORD_HERE_
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;のように定義します。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;group_vars/development/vars.yml&lt;/code&gt; では&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;postgresql_replication_password: &amp;quot;{{ development.secrets.postgresql_replication_password }}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;のようにその変数を参照するようにするという具合です。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;LXDを使えば複数サーバ構成のテスト環境も簡単に作れてとても便利です！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>私のソースコードの書き方</title>
      <link>/blog/2016/07/16/my-way-of-writing-source-codes/</link>
      <pubDate>Sat, 16 Jul 2016 01:37:48 +0900</pubDate>
      
      <guid>/blog/2016/07/16/my-way-of-writing-source-codes/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://note.mu/ruiu/n/n1083b2a5d547&#34;&gt;ソースコードって実際のところどういうふうに書いていますか？｜Rui Ueyama｜note&lt;/a&gt; を読んで参考になるなーと思ったのですが、はてブ見ても、みんなだいたい同じですみたいなコメントばかりで面白くないので、「上手い人」では無いかもしれませんが、私の書き方をまとめてみました。&lt;/p&gt;

&lt;h2 id=&#34;ボトムアップアプローチ&#34;&gt;ボトムアップアプローチ&lt;/h2&gt;

&lt;p&gt;私はわりと新規プロジェクトで一からコードを書くことが多いです。人が書いたコードを引き継いで保守した経験はほとんど無いような気がします。&lt;/p&gt;

&lt;p&gt;私はトップダウン型で書くのが徹底的に苦手なので、常にボトムアップで書いています。
大規模なプログラムを汎用的に設計するとかは私には無理です。&lt;a href=&#34;https://ja.wikipedia.org/wiki/YAGNI&#34;&gt;YAGNI&lt;/a&gt;大好き。&lt;/p&gt;

&lt;p&gt;具体的なコードの書き方ですが、最初はドキュメントに書かれているサンプルコードをコピペして動かします。すんなり動くこともあれば、環境やライブラリのバージョン違いなどで多少手直しが必要なこともあります。&lt;/p&gt;

&lt;p&gt;次に、やりたいことに向けて1つずつ機能を追加していきます。ちょっと書いたらコンパイルしてエラーを解消します。で、すかさず動作確認します。自分で書き足すだけではなくて複数のサンプルコードをコピペして、つなぎ合わせる部分を書くこともあります。例えば&lt;a href=&#34;http://hnakamur.github.io/blog/2016/06/12/wrote_remoteworkers_go_pacakge/&#34;&gt;Goで複数のリモートのワーカーにジョブを実行させるremoteworkersというパッケージを書いた&lt;/a&gt;です。ちなみにこのパッケージは実案件では出番がなくて使ってないです。&lt;/p&gt;

&lt;p&gt;私は頭の中で全体を把握したり、先に設計してから実装とかが出来ないので、まず書いて動かしてみてから考えます。書くときもなんとなく雰囲気で書いてみることも多いです。で、動かしてみて、あ、こうなるのか、じゃあこう変えよ、という感じで理解を深めながら、コードを書き足していく感じです。&lt;/p&gt;

&lt;h2 id=&#34;gitでのバージョン管理&#34;&gt;gitでのバージョン管理&lt;/h2&gt;

&lt;p&gt;コンパイルが通ったところや、ちゃんと動くようになったところでGitでコミットしていますが、ついつい他のこともついでにやっているのでコミットの単位はきちんと分かれていないことが日常茶飯事です。きちんと整理したほうが良いだろうなと思いつつ、新規開発の時はさっさと開発をすすめるほうが優先と思って妥協しています。&lt;/p&gt;

&lt;p&gt;実際のところ、新規開発時のコミットを後で見直すことは無いので困ったことは特に無いです。一度リリースした後に保守するときは、修正ごとに極力コミットを分けるようにしています。&lt;/p&gt;

&lt;p&gt;私も一直線にゴールに向かうわけではないです。開発初期の時はmasterブランチにどんどんコミットしていますが、横道にそれてなにか試すときはブランチを切って試しています。で結局使わなかった時はmasterに戻って作業を続けて、将来だいぶ立ってから流石にもう使うことはないかと思った時点で試した時のブランチは破棄しています。&lt;/p&gt;

&lt;p&gt;ちょっとした変更を試すときはmasterのままコミットして、結局不採用だけど後でみたいかもと思うときはrevertすることもあります。&lt;/p&gt;

&lt;p&gt;masterにどんどんコミットというのは1人で開発している時で、複数人で開発するようになったらプルリクエストベースに切り替えています。一方で1人で開発している時でも一連のコミットをまとめておきたいときはプルリクエストを送って自分でマージしています。&lt;/p&gt;

&lt;h2 id=&#34;テスト&#34;&gt;テスト&lt;/h2&gt;

&lt;p&gt;動いている状態を維持しつつ機能追加していきますが、私はテストはめったに書かないです。私は3歩歩けば忘れる鳥頭なのでソースコードも書いた瞬間から忘れていきますが、再度コードを読んで何やっているか理解できればOKです。コード読んだだけでは、どうなるかよくわからないところについてはテストを書きます。&lt;/p&gt;

&lt;p&gt;例えば&lt;a href=&#34;https://github.com/hnakamur/ltsvlog&#34;&gt;hnakamur/ltsvlog&lt;/a&gt;というLTSV形式のログラブラリではログが出力されるかといったテストは一切書いてなくて、いろんな型の値がどう文字列化されるかという箇所だけテストを書いています。&lt;/p&gt;

&lt;h2 id=&#34;デバッグはログ出力派&#34;&gt;デバッグはログ出力派&lt;/h2&gt;

&lt;p&gt;デバッガはほとんど使わないです。サードパーティのアプリケーションやライブラリのコードをどこから読んでよいかわからないときに、気になる関数でブレークしてコールスタックを見たりするときとか、デバッグでたまに使う程度です。&lt;/p&gt;

&lt;p&gt;自分のプログラムでもサードパーティのプログラムでも、想定外の動きになったり、挙動がよくわからない時はデバッグログ出力のコードを追加してビルドして再度実行して、呼び出し関係や変数の値を確認します。呼び出し関係は、気になるポイントでスタックトレースを出力するデバッグログを追加します。Pythonとかでは例外を投げてすぐキャッチしてスタックトレースを出力したり、Goだと&lt;a href=&#34;https://golang.org/pkg/runtime/#Stack&#34;&gt;runtime.Stack&lt;/a&gt;でスタックトレースを出力します。&lt;/p&gt;

&lt;p&gt;今だと拙作のltsvlogパッケージの&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LTSVLogger.ErrorWithStack&#34;&gt;func (l *LTSVLogger) ErrorWithStack(lv &amp;hellip;LV)&lt;/a&gt;を一時的に埋め込むという手もあります。この関数はエラーを出力するためのものですけど、あくまで一時的に埋め込んで動作させて、確認したらすぐ消す感じで。&lt;/p&gt;

&lt;p&gt;デバッガだとプログラム修正後に再起動してブレークポイント指定してそこまで進んでという手間が面倒ですし、変数の中から見たい情報を見たい形に加工するのも面倒だと感じます。デバッグログなら一回仕込んでビルドすれば後はプログラム実行するだけで毎回必要な情報を出力してくれるので楽です。&lt;/p&gt;

&lt;h2 id=&#34;リファクタリング&#34;&gt;リファクタリング&lt;/h2&gt;

&lt;p&gt;リファクタリングするときに互換レイヤを作るという発想はありませんでした。1つのコミットの変更内容が大きくなり過ぎないように、変更をいくつかのステップに分けて、それぞれコミットしておくようにはしています。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;ということで正直ベースで書いてみました。&lt;/p&gt;

&lt;p&gt;Rui Ueyamaさんのような凄い方と比べるとレベルが低いですが、こんな人もいますよということで。この記事が他の方の話の呼び水になれば嬉しいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>1台のサーバに異なる設定でApache Traffic Serverを複数立ち上げるためのビルド設定</title>
      <link>/blog/2016/07/02/config-for-multiple-installations-of-apache-traffic-server/</link>
      <pubDate>Sat, 02 Jul 2016 01:00:00 +0900</pubDate>
      
      <guid>/blog/2016/07/02/config-for-multiple-installations-of-apache-traffic-server/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;Apache Traffic Serverには&lt;a href=&#34;https://docs.trafficserver.apache.org/en/latest/admin-guide/configuration/hierachical-caching.en.html&#34;&gt;Hierarchical Caching&lt;/a&gt;という機能があって、キャッシュを親と子の2階層にすることが出来ます。&lt;/p&gt;

&lt;p&gt;CentOSで1つのサーバに親と子の2つのTraffic Server 6.1.1を異なる設定で起動するような構成にしたかったのですが、本家のrpmでは出来ないようでした。
ソースを見ていたらconfigureオプションをうまく指定すれば可能だとわかり、カスタムrpmを作りました。&lt;/p&gt;

&lt;p&gt;rpmのspecファイルは&lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec&#34;&gt;apache-traffic-server-rpm/trafficserver.spec&lt;/a&gt;、ビルドしたrpmは &lt;a href=&#34;https://copr.fedorainfracloud.org/coprs/hnakamur/apache-traffic-server-6/&#34;&gt;hnakamur/apache-traffic-server-6 Copr&lt;/a&gt; で公開しています。&lt;/p&gt;

&lt;h2 id=&#34;起動オプションではやりたいことは出来なさそうでした&#34;&gt;起動オプションではやりたいことは出来なさそうでした&lt;/h2&gt;

&lt;p&gt;カスタムrpmを作る前に、本家のrpmを使いつつコマンドラインオプションや環境変数の設定によってやりたいことが実現できないか調べてみたのですが、出来なさそうでした。&lt;/p&gt;

&lt;p&gt;バージョン6.1.1のソースを見た時のメモです。&lt;/p&gt;

&lt;p&gt;まず、 &lt;code&gt;traffic_server&lt;/code&gt; コマンドには &lt;code&gt;-conf_dir&lt;/code&gt; というオプションがあります。ソースは &lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/proxy/Main.cc#L206&#34;&gt;proxy/Main.cc&lt;/a&gt; です。&lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/appendices/command-line/traffic_server.en.html&#34;&gt;traffic_serverのドキュメント&lt;/a&gt;には記載がありません。&lt;/p&gt;

&lt;p&gt;一方、 &lt;code&gt;traffic_manager&lt;/code&gt; コマンドには &lt;code&gt;-tsArgs&lt;/code&gt; というオプションがあります。 ソースは &lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/cmd/traffic_manager/traffic_manager.cc#L453&#34;&gt;cmd/traffic_manager/traffic_manager.cc&lt;/a&gt; で &lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/appendices/command-line/traffic_manager.en.html#cmdoption-traffic_manager--tsArgs&#34;&gt;traffic_managerのドキュメント&lt;/a&gt; にも説明はありませんが載っています。&lt;/p&gt;

&lt;p&gt;しかし、 &lt;code&gt;traffic_cop&lt;/code&gt; コマンドが &lt;code&gt;traffic_manager&lt;/code&gt; コマンドを起動する際には &lt;code&gt;-tsArgs&lt;/code&gt; オプションは指定していません。ソースは &lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/cmd/traffic_cop/traffic_cop.cc#L758&#34;&gt;cmd/traffic_cop/traffic_cop.cc&lt;/a&gt; です。 &lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/appendices/command-line/traffic_cop.en.html&#34;&gt;traffic_cop&lt;/a&gt; のドキュメントを見ても traffic_manager にオプションを渡すためのオプションは無いようです。&lt;/p&gt;

&lt;p&gt;rpmでインストールされるサービス起動スクリプトだと &lt;code&gt;traffic_cop&lt;/code&gt; →　&lt;code&gt;traffic_manger&lt;/code&gt; →　&lt;code&gt;traffic_sever&lt;/code&gt; という呼び出し関係になるので、こ &lt;code&gt;traffic_server&lt;/code&gt;   に &lt;code&gt;-conf_dir&lt;/code&gt; オプションを渡すことは出来なさそうです。&lt;/p&gt;

&lt;h2 id=&#34;ts-rootという環境変数を発見&#34;&gt;TS_ROOTという環境変数を発見&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/lib/ts/Layout.cc#L146-L187&#34;&gt;lib/ts/Layout.cc&lt;/a&gt; で &lt;code&gt;TS_ROOT&lt;/code&gt; という環境変数を参照しているのを見つけました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Layout::Layout(const char *_prefix)
{
  if (_prefix) {
    prefix = ats_strdup(_prefix);
  } else {
    char *env_path;
    char path[PATH_NAME_MAX];
    int len;

    if ((env_path = getenv(&amp;quot;TS_ROOT&amp;quot;))) {
      len = strlen(env_path);
      if ((len + 1) &amp;gt; PATH_NAME_MAX) {
        ink_error(&amp;quot;TS_ROOT environment variable is too big: %d, max %d\n&amp;quot;, len, PATH_NAME_MAX - 1);
        return;
      }
      ink_strlcpy(path, env_path, sizeof(path));
      while (len &amp;gt; 1 &amp;amp;&amp;amp; path[len - 1] == &#39;/&#39;) {
        path[len - 1] = &#39;\0&#39;;
        --len;
      }
    } else {
      // Use compile time --prefix
      ink_strlcpy(path, TS_BUILD_PREFIX, sizeof(path));
    }

    prefix = ats_strdup(path);
  }
  exec_prefix = layout_relative(prefix, TS_BUILD_EXEC_PREFIX);
  bindir = layout_relative(prefix, TS_BUILD_BINDIR);
  sbindir = layout_relative(prefix, TS_BUILD_SBINDIR);
  sysconfdir = layout_relative(prefix, TS_BUILD_SYSCONFDIR);
  datadir = layout_relative(prefix, TS_BUILD_DATADIR);
  includedir = layout_relative(prefix, TS_BUILD_INCLUDEDIR);
  libdir = layout_relative(prefix, TS_BUILD_LIBDIR);
  libexecdir = layout_relative(prefix, TS_BUILD_LIBEXECDIR);
  localstatedir = layout_relative(prefix, TS_BUILD_LOCALSTATEDIR);
  runtimedir = layout_relative(prefix, TS_BUILD_RUNTIMEDIR);
  logdir = layout_relative(prefix, TS_BUILD_LOGDIR);
  mandir = layout_relative(prefix, TS_BUILD_MANDIR);
  infodir = layout_relative(prefix, TS_BUILD_INFODIR);
  cachedir = layout_relative(prefix, TS_BUILD_CACHEDIR);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/lib/ts/Layout.cc#L51-L70&#34;&gt;layout_relative関数の定義&lt;/a&gt; と &lt;a href=&#34;https://github.com/apache/trafficserver/blob/d6906e2a59858005d09018994262562b03ca24e9/lib/ts/ink_file.cc#L132-L323&#34;&gt;ink_filepath_merge関数の定義&lt;/a&gt; を見ると、 layout_relative の第2引数が &lt;code&gt;/&lt;/code&gt; で始まっていると第2引数がそのまま使われ、 &lt;code&gt;/&lt;/code&gt; で始まっていないと第1引数と第2引数を必要に応じて &lt;code&gt;/&lt;/code&gt; を挟んで連結した値になることがわかりました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;TS_BUILD_SYSCONFDIR&lt;/code&gt; などは&lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/lib/ts/ink_config.h.in#L110-L125&#34;&gt;trafficserver/ink_config.h.in&lt;/a&gt; で定義されていました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* Various &amp;quot;build&amp;quot; defines */
#define TS_BUILD_PREFIX &amp;quot;@prefix@&amp;quot;
#define TS_BUILD_EXEC_PREFIX &amp;quot;@rel_exec_prefix@&amp;quot;
#define TS_BUILD_BINDIR &amp;quot;@rel_bindir@&amp;quot;
#define TS_BUILD_SBINDIR &amp;quot;@rel_sbindir@&amp;quot;
#define TS_BUILD_SYSCONFDIR &amp;quot;@rel_sysconfdir@&amp;quot;
#define TS_BUILD_DATADIR &amp;quot;@rel_datadir@&amp;quot;
#define TS_BUILD_INCLUDEDIR &amp;quot;@rel_includedir@&amp;quot;
#define TS_BUILD_LIBDIR &amp;quot;@rel_libdir@&amp;quot;
#define TS_BUILD_LIBEXECDIR &amp;quot;@rel_libexecdir@&amp;quot;
#define TS_BUILD_LOCALSTATEDIR &amp;quot;@rel_localstatedir@&amp;quot;
#define TS_BUILD_RUNTIMEDIR &amp;quot;@rel_runtimedir@&amp;quot;
#define TS_BUILD_LOGDIR &amp;quot;@rel_logdir@&amp;quot;
#define TS_BUILD_MANDIR &amp;quot;@rel_mandir@&amp;quot;
#define TS_BUILD_CACHEDIR &amp;quot;@rel_cachedir@&amp;quot;
#define TS_BUILD_INFODIR &amp;quot;@rel_infodir@&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;rel_*&lt;/code&gt; という値は &lt;code&gt;configure&lt;/code&gt; 実行時にbuild/common.m4の &lt;a href=&#34;https://github.com/apache/trafficserver/blob/5a0952b01d01ef927a65fc44bac5f68c345747aa/build/common.m4#L252-L263&#34;&gt;TS_SUBST_LAYOUT_PATH&lt;/a&gt; で設定されるようです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dnl
dnl TS_SUBST_LAYOUT_PATH
dnl Export (via TS_SUBST) the various path-related variables that
dnl trafficserver will use while generating scripts and
dnl the default config file.
AC_DEFUN([TS_SUBST_LAYOUT_PATH], [
  TS_EXPAND_VAR(exp_$1, [$]$1)
  TS_PATH_RELATIVE(rel_$1, [$]exp_$1, ${prefix})
  TS_SUBST(exp_$1)
  TS_SUBST(rel_$1)
  TS_SUBST($1)
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここから呼ばれる &lt;a href=&#34;https://github.com/apache/trafficserver/blob/5a0952b01d01ef927a65fc44bac5f68c345747aa/build/common.m4#L223-L241&#34;&gt;TS_PATH_RELATIVE&lt;/a&gt; で実際の値が作られます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dnl
dnl Removes the value of $3 from the string in $2, strips of any leading
dnl slashes, and returns the value in $1.
dnl
dnl Example:
dnl orig_path=&amp;quot;${prefix}/bar&amp;quot;
dnl TS_PATH_RELATIVE(final_path, $orig_path, $prefix)
dnl    $final_path now contains &amp;quot;bar&amp;quot;
AC_DEFUN([TS_PATH_RELATIVE], [
ats_stripped=`echo $2 | sed -e &amp;quot;s#^$3##&amp;quot;`
# check if the stripping was successful
if test &amp;quot;x$2&amp;quot; != &amp;quot;x${ats_stripped}&amp;quot;; then
# it was, so strip of any leading slashes
    $1=&amp;quot;`echo ${ats_stripped} | sed -e &#39;s#^/*##&#39;`&amp;quot;
else
# it wasn&#39;t so return the original
    $1=&amp;quot;$2&amp;quot;
fi
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで、例えば &lt;code&gt;sysconfdir&lt;/code&gt; の値が &lt;code&gt;prefix&lt;/code&gt; の値で始まっていれば &lt;code&gt;rel_sysconfdir&lt;/code&gt; は &lt;code&gt;prefix&lt;/code&gt; からの相対パスになり、そうでなければ &lt;code&gt;sysconfdir&lt;/code&gt; そのままになるということがわかりました。&lt;/p&gt;

&lt;h2 id=&#34;configureオプションの指定方法&#34;&gt;configureオプションの指定方法&lt;/h2&gt;

&lt;p&gt;上記を踏まえて、私が作成した &lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec&#34;&gt;/trafficserver.spec&lt;/a&gt; では &lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec#L1&#34;&gt;1行目&lt;/a&gt;で&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%define _prefix /opt/trafficserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と設定し、 &lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec#L85-L94&#34;&gt;85〜94行目&lt;/a&gt; で以下のような configure オプションを指定しています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%configure \
  --enable-layout=opt \
  --sysconfdir=%{_prefix}%{_sysconfdir} \
  --localstatedir=%{_prefix}%{_localstatedir} \
  --libexecdir=%{_prefix}/%{_lib}/plugins \
  --with-tcl=/usr/%{_lib} \
  --enable-luajit \
  --with-user=ats --with-group=ats \
  --disable-silent-rules \
  --enable-experimental-plugins
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでビルドしたtrafficserverを実行する際に、環境変数TS_ROOTを設定することで以下のようなディレクトリを参照することが出来ました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sysconfdir: ${TS_ROOT}/etc&lt;/li&gt;
&lt;li&gt;localstatedir: ${TS_ROOT}/var/run&lt;/li&gt;
&lt;li&gt;libexecdir: ${TS_ROOT}/lib64/plugins&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;私が使っているディレクトリ構成&#34;&gt;私が使っているディレクトリ構成&lt;/h2&gt;

&lt;p&gt;実際には以下のようなシンボリックリンクを貼って使っています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1段目

&lt;ul&gt;
&lt;li&gt;/opt/trafficserver-first/etc -&amp;gt; /etc/trafficserver-first&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/bin -&amp;gt; /opt/trafficserver/bin&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/lib64 -&amp;gt; /opt/trafficserver/lib64&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/var/cache -&amp;gt; /var/cache/trafficserver-first&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/var/logs -&amp;gt; /var/log/trafficserver-first&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/var/run -&amp;gt; /var/run/trafficserver-first&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2段目

&lt;ul&gt;
&lt;li&gt;/opt/trafficserver-second/etc -&amp;gt; /etc/trafficserver-second&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/bin -&amp;gt; /opt/trafficserver/bin&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/lib64 -&amp;gt; /opt/trafficserver/lib64&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/var/cache -&amp;gt; /var/cache/trafficserver-second&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/var/logs -&amp;gt; /var/log/trafficserver-second&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/var/run -&amp;gt; /var/run/trafficserver-second&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;コマンド実行時の環境変数指定&#34;&gt;コマンド実行時の環境変数指定&lt;/h2&gt;

&lt;p&gt;コマンドを実行するときはPATHを通すかフルパスで指定するだけではなく、 TS_ROOT 環境変数も指定する必要があります。&lt;/p&gt;

&lt;p&gt;例えば、1段目のキャッシュを全クリアするときは &lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/admin-guide/storage/index.en.html#clearing-the-cache&#34;&gt;Clearing the Cache&lt;/a&gt; の説明では &lt;code&gt;traffic_server -Cclear&lt;/code&gt; ですが、このrpmの場合は&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TS_ROOT=/opt/trafficserver-first /opt/trafficserver-first/bin/traffic_server -Cclear
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と実行する必要があります。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>lxd_containerというAnsibleモジュールを書いたときに学んだtips</title>
      <link>/blog/2016/07/01/tips_for_writing_ansible_module/</link>
      <pubDate>Fri, 01 Jul 2016 22:44:12 +0900</pubDate>
      
      <guid>/blog/2016/07/01/tips_for_writing_ansible_module/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;lxd_containerというAnsibleのモジュールを書いたときに学んだtipsのメモです。&lt;/p&gt;

&lt;h2 id=&#34;モジュールでデバッグ出力は出来ないのでデバッグ情報は戻り値のjsonに入れる&#34;&gt;モジュールでデバッグ出力は出来ないのでデバッグ情報は戻り値のJSONに入れる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://groups.google.com/d/msg/ansible-devel/s0iSb7phnqY/UB9vaLFJAwAJ&#34;&gt;ansible-dev MLでの投稿&lt;/a&gt;によるとモジュールは何も出力できないとのことなので、デバッグ情報は戻り値のJSONに入れる必要があります。&lt;/p&gt;

&lt;p&gt;Ansible 2.1からはAnsibleModuleクラスでは &lt;code&gt;_verbosity&lt;/code&gt;、それ以外では &lt;code&gt;_ansible_verbosity&lt;/code&gt; で &lt;code&gt;-v&lt;/code&gt;, &lt;code&gt;-vv&lt;/code&gt;, &lt;code&gt;-vvv&lt;/code&gt;, &lt;code&gt;-vvvv&lt;/code&gt; を指定した場合の &lt;code&gt;v&lt;/code&gt; の個数が取得できるので、それに応じて戻り値のJSONにデバッグ情報を含めるかどうか制御することが出来ます。値は &lt;code&gt;-v&lt;/code&gt; を指定しない場合は 0 で、 &lt;code&gt;-vvvv&lt;/code&gt; だと4という感じです。&lt;/p&gt;

&lt;h2 id=&#34;コードフォーマットのチェック&#34;&gt;コードフォーマットのチェック&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ansible/ansible-modules-extras/pull/2208#discussion_r62996064&#34;&gt;Ansibleのコミッタの方からのコメント&lt;/a&gt; で &lt;code&gt;pep8&lt;/code&gt; というツールでコードフォーマットのチェックを行っているということを知りました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pep8 -r --ignore=E501,E221,W291,W391,E302,E251,E203,W293,E231,E303,E201,E225,E261,E241,E402 *.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;という感じで使います。 pep8はUbuntu 16.04 では &lt;code&gt;sudo apt install pep8&lt;/code&gt; でインストールできました。&lt;/p&gt;

&lt;h2 id=&#34;ansibleモジュールのチェック&#34;&gt;Ansibleモジュールのチェック&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ansible/ansible-modules-extras&#34;&gt;ansible/ansible-modules-extras&lt;/a&gt; にプルリクエストを送ると Travis CI でチェックが走るのですが、そのチェックの1つで &lt;code&gt;ansible-validate-modules&lt;/code&gt; というコマンドが使われていました。&lt;/p&gt;

&lt;p&gt;いろいろチェックしているようなのですが、例えばモジュール内にYAMLで書いたドキュメントの書式が間違っていると &lt;code&gt;ansible-validate-modules&lt;/code&gt; エラーになりました。コミットをプッシュしてからエラーになると面倒なのでローカルで先にチェックしておくのが良いです。&lt;/p&gt;

&lt;p&gt;私はPythonのvirtualenv環境内で &lt;code&gt;pip install ansible-testing&lt;/code&gt; でインストールしました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-validate-modules 対象ディレクトリ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でチェックできます。&lt;/p&gt;

&lt;h2 id=&#34;サードパーティのrequestsを使うとansible-module-utils-urlsを使うべきというエラーが出る&#34;&gt;サードパーティのrequestsを使うとansible.module_utils.urlsを使うべきというエラーが出る&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.python-requests.org/en/master/&#34;&gt;Requests: HTTP for Humans&lt;/a&gt;を使っているとansible-validate-modulesが &lt;code&gt;ansible.module_utils.urls&lt;/code&gt; を使うべきという&lt;a href=&#34;https://github.com/ansible/ansible-modules-extras/pull/2208#issuecomment-228027653&#34;&gt;エラーを出してきます&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;今回書いたlxd_containerモジュールは&lt;a href=&#34;https://github.com/lxc/lxd/blob/master/doc/rest-api.md&#34;&gt;LXD REST API&lt;/a&gt;を使うのですが (1) Unixドメインソケットでの通信、(2) クライアント証明書を使ったhttps通信の2つが必要です。が &lt;code&gt;ansible.module_utils.urls&lt;/code&gt; での実現方法がわからなかったので、今回はPython2標準ライブラリのhttplibを使って実装しました。&lt;/p&gt;

&lt;p&gt;サードパーティのライブラリを使わず標準ライブラリを使うことで、lxd_containerモジュールを使うときに依存するライブラリを入れる手間が発生しないので結果的には良かったと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>分散SQLデータベースCockroachDBのキーバリューストレージのデバッグコマンドを試してみた</title>
      <link>/blog/2016/06/30/experiment-cockroachdb-key-value-store/</link>
      <pubDate>Thu, 30 Jun 2016 06:40:12 +0900</pubDate>
      
      <guid>/blog/2016/06/30/experiment-cockroachdb-key-value-store/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;h/blog/2016/06/20/lsm-tree-and-rocksdb/&#34;&gt;LSM-TreeとRocksDB、TiDB、CockroachDBが気になる&lt;/a&gt; で紹介した &lt;a href=&#34;https://github.com/cockroachdb/cockroach#client-drivers&#34;&gt;CockroachDB&lt;/a&gt; は &lt;a href=&#34;https://github.com/cockroachdb/cockroach#what-is-cockroachdb&#34;&gt;What is CockroachDB?&lt;/a&gt; によるとスケールアウトできる分散SQLデータベースです。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach#client-drivers&#34;&gt;PostgreSQLのワイヤープロトコルをサポート&lt;/a&gt; していて、 &lt;a href=&#34;https://github.com/cockroachdb/cockroach#quickstart&#34;&gt;Quickstart&lt;/a&gt; の例のようにPostgreSQLで扱えるSQLのサブセットが使えます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach#overview&#34;&gt;Overview&lt;/a&gt; によるとストレージには &lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt; を使用し、複数台のサーバ間の合意アルゴリズムにはRaftを使用しています。&lt;/p&gt;

&lt;p&gt;分散SQLデータベースという本来の機能も魅力的なのですが、書き込みが多いケースに最適化したLSM Treeというデータ構造の実装であるRocksDBをRaftを使って分散トランザクションを実現しているという部分も個人的には興味があります。&lt;/p&gt;

&lt;p&gt;ということで、そのへんのソースを見ていこうと思います。といっても、まだ全体を把握しているわけではないので、だらだら書いていきます。
CockroachDBにデバッグ用のコマンドが用意されていたので、それで実験しつつ読み進めたいと思います。&lt;/p&gt;

&lt;h2 id=&#34;rocksdbラッパーレイヤとengineパッケージ&#34;&gt;RocksDBラッパーレイヤとengineパッケージ&lt;/h2&gt;

&lt;p&gt;RocksDBはC++で書かれているので、Goから呼び出すためcgoでラッピングしているレイヤがあります。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach/tree/master/storage/engine/rocksdb&#34;&gt;cockroach/storage/engine/rocksdb&lt;/a&gt; にC++で書かれたファイルがいくつかあります。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach/tree/master/storage/engine&#34;&gt;cockroach/storage/engine&lt;/a&gt; パッケージのドキュメント &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine&#34;&gt;engine - GoDoc&lt;/a&gt; にこのパッケージで低レベルのストレージを提供しているという説明があります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#Engine&#34;&gt;Engine&lt;/a&gt; はRocksDBなどのストレージバックエンドとやり取りするためのインターフェースです。 Engineは &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#ReadWriter&#34;&gt;ReadWriter&lt;/a&gt; インタフェースをエンベッドしていて、それがさらに &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#Reader&#34;&gt;Reader&lt;/a&gt; と &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#Writer&#34;&gt;Writer&lt;/a&gt; インタフェースをエンベッドしています。&lt;/p&gt;

&lt;p&gt;Reader や Writer インタフェースのメソッドを見るとキーバリューストアのキーは &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#MVCCKey&#34;&gt;MVCCKey&lt;/a&gt; という型になっています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type MVCCKey struct {
    Key       roachpb.Key
    Timestamp hlc.Timestamp
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/roachpb#Key&#34;&gt;roachpb.Key&lt;/a&gt; は &lt;code&gt;[]byte&lt;/code&gt; と定義されており、 &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/util/hlc#Timestamp&#34;&gt;hlc.Timestamp&lt;/a&gt; は以下のように定義されています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Timestamp struct {
    // Holds a wall time, typically a unix epoch time
    // expressed in nanoseconds.
    WallTime int64 `protobuf:&amp;quot;varint,1,opt,name=wall_time,json=wallTime&amp;quot; json:&amp;quot;wall_time&amp;quot;`
    // The logical component captures causality for events whose wall
    // times are equal. It is effectively bounded by (maximum clock
    // skew)/(minimal ns between events) and nearly impossible to
    // overflow.
    Logical int32 `protobuf:&amp;quot;varint,2,opt,name=logical&amp;quot; json:&amp;quot;logical&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine&#34;&gt;engine - GoDoc&lt;/a&gt; にEngineインタフェースの上にMVCC (Multi-Version Concurrency Control) システムが提供されていて、それがCockroachDBが分散トランザクションをサポートするための基礎になっていると書かれています。&lt;/p&gt;

&lt;p&gt;その下の &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#hdr-Notes_on_MVCC_architecture&#34;&gt;Notes on MVCC architecture&lt;/a&gt; にMVCCアーキテクチャについて詳細な説明があります。じっくり読んだほうが良いと思いますが、一旦飛ばして先に進みます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#RocksDB&#34;&gt;RocksDB&lt;/a&gt; という構造体定義があり、これが Engine インタフェースを実装しています。  &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#NewRocksDB&#34;&gt;NewRocksDB&lt;/a&gt; 関数で RocksDB を作成できます。&lt;/p&gt;

&lt;h2 id=&#34;newrocksdb関数の呼び出し箇所&#34;&gt;NewRocksDB関数の呼び出し箇所&lt;/h2&gt;

&lt;p&gt;NewRocksDB関数は、テストコード以外では、以下の2箇所で呼ばれていました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/server&#34;&gt;server&lt;/a&gt; パッケージの &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/server#Context.InitStores&#34;&gt;func (*Context) InitStores&lt;/a&gt;。

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/549d9b575e06921fa96b6ff4881ea348d8b6d00c/server/context.go#L260-L261&#34;&gt;cockroach/context.go at 549d9b575e06921fa96b6ff4881ea348d8b6d00c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/cli/debug.go&#34;&gt;cockroach/debug.go&lt;/a&gt; の &lt;code&gt;cli.openStore(cmd *cobra.Command, dir string, stopper *stop.Stopper) (engine.Engine, error)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/549d9b575e06921fa96b6ff4881ea348d8b6d00c/cli/debug.go#L65-L71&#34;&gt;cockroach/debug.go at 549d9b575e06921fa96b6ff4881ea348d8b6d00c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;後者を呼び出している箇所を見ていくとデバッグ用のサブコマンドがあることがわかりました。&lt;/p&gt;

&lt;h2 id=&#34;デバッグ用サブコマンドを試してみた&#34;&gt;デバッグ用サブコマンドを試してみた&lt;/h2&gt;

&lt;p&gt;前提条件としてLXDの3つのコンテナroach1, roach2, roach3で以下のようにCockroachDBを起動している状態とします。&lt;/p&gt;

&lt;p&gt;roach1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/sbin/cockroach start --host 192.168.0.13 --insecure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;roach2&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/sbin/cockroach start --join 192.168.0.13:26257 --insecure --host 192.168.0.14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;roach3&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/sbin/cockroach start --join 192.168.0.13:26257 --insecure --host 192.168.0.15
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特にコンテナでなくても1台のサーバで &lt;a href=&#34;https://github.com/cockroachdb/cockroach#quickstart&#34;&gt;Quickstart&lt;/a&gt;のlocal clusterでも構いません。その場合は下記のコマンドの &lt;code&gt;--host&lt;/code&gt; の部分を適宜読み替えてください。&lt;/p&gt;

&lt;h3 id=&#34;debug-kv-コマンドを試してみた&#34;&gt;debug kv コマンドを試してみた&lt;/h3&gt;

&lt;p&gt;debug kvコマンドで、キー・バリュー・ストアに値を設定したり取得したり出来ます。&lt;/p&gt;

&lt;p&gt;コンテナroach1で値をセットして取得してみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach1:~# cockroach debug kv scan --host 192.168.0.13
0 result(s)
root@roach1:~# cockroach debug kv put --host 192.168.0.13 foo bar
root@roach1:~# cockroach debug kv get --host 192.168.0.13 foo
&amp;quot;bar&amp;quot;
root@roach1:~# cockroach debug kv scan --host 192.168.0.13
&amp;quot;foo&amp;quot;   &amp;quot;bar&amp;quot;
1 result(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記で設定した値がコンテナroach2でも取得できました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug kv scan --host 192.168.0.14
&amp;quot;foo&amp;quot;   &amp;quot;bar&amp;quot;
1 result(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナroach2からroach1上の値を変更も出来ます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug kv put --host 192.168.0.13 foo &#39;Hello, key value store in CockroachDB&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナroach1上の値一覧を取得して更新されていることを確認しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach1:~# cockroach debug kv scan --host 192.168.0.13
&amp;quot;foo&amp;quot;   &amp;quot;Hello, key value store in CockroachDB&amp;quot;
1 result(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;debug-keys-コマンドを試してみた&#34;&gt;debug keys コマンドを試してみた&lt;/h3&gt;

&lt;p&gt;debug keysコマンドで、キー・バリュー・ストアの内部構造をダンプして見ることが出来ます。このコマンドはサーバを停止した状態でデータのディレクトリを指定して実行するようになっています。&lt;/p&gt;

&lt;p&gt;サーバが起動したまま実行すると以下のようにロックが取得できないというエラーになります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug keys ./cockroach-data
Error: storage/engine/rocksdb.go:158: could not open rocksdb instance: IO error: lock ./cockroach-data/LOCK: Resource temporarily unavailable
Usage:
  cockroach debug keys [directory] [flags]

Flags:
      --from string
        Start key in pretty-printed format. See also --raw.

      --raw
        Interpret keys as raw bytes.

      --to string
        Exclusive end key in pretty-printed format. See also --raw.

      --values
        Print values along with their associated key.

Global Flags:
      --alsologtostderr value[=INFO]   logs at or above this threshold go to stderr (default NONE)
      --log-backtrace-at value         when logging hits line file:N, emit a stack trace (default :0)
      --log-dir value                  if non-empty, write log files in this directory
      --logtostderr                    log to standard error instead of files
      --no-color value                 disable standard error log colorization
      --verbosity value                log level for V logs
      --vmodule value                  comma-separated list of pattern=N settings for file-filtered logging

Failed running &amp;quot;debug&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこでコンテナroach2のサーバを停止してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach quit --host 192.168.0.14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバを停止したらキーの一覧を表示してみます。以下の例では &lt;code&gt;foo&lt;/code&gt; の前後5行を表示しています。
fooという文字列の後にタイムスタンプがついているのがわかります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug keys ./cockroach-data | grep -A 5 -B 5 foo
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466351519.447511853,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466265107.436191749,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466265097.406397710,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466178687.396782782,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466178677.619687555,85&amp;quot;
&amp;quot;\&amp;quot;foo\&amp;quot;/1467234744.564568969,0&amp;quot;
&amp;quot;\&amp;quot;foo\&amp;quot;/1467221373.376922221,0&amp;quot;
&amp;quot;/Table/2/1/0/\&amp;quot;bank\&amp;quot;/3/1/1466178749.722011447,0&amp;quot;
&amp;quot;/Table/2/1/0/\&amp;quot;system\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&amp;quot;/Table/2/1/1/\&amp;quot;descriptor\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&amp;quot;/Table/2/1/1/\&amp;quot;eventlog\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&amp;quot;/Table/2/1/1/\&amp;quot;lease\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--values&lt;/code&gt; オプションも追加すると、キーだけではなく値も表示されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cockroach debug keys --values cockroach-data/ | less
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行して、 &lt;code&gt;foo&lt;/code&gt; のキーに対応する部分を見てみると以下のようになっていました。横に長過ぎるので折り返して表示しています。&lt;/p&gt;

&lt;p&gt;/Local/RangeID/21/u/RaftLog/logIndex:104861: Type:EntryNormal Term:51415 Index:104861  by {2 2 2}
  Put [&amp;ldquo;foo&amp;rdquo;,/Min)
  range_id:21 origin_replica:&lt;node_id:2 store_id:2 replica_id:2 &gt; cmd:&lt;header:&lt;timestamp:&lt;wall_time:1467234744564568969 logical:0 &gt; replica:&lt;node_id:2 store_id:2 replica_id:2 &gt; range_id:21 user_priority:NORMAL read_consistency:CONSISTENT trace:&lt;trace_id:4947902158296355776 span_id:7041358067641207168 &gt; max_scan_results:0 distinct_spans:false &amp;gt; requests:&lt;put:&lt;header:&lt;key:&#34;foo&#34; &gt; value:&lt;raw_bytes:&#34;s|S\306\003Hello, key value store in CockroachDB&#34; timestamp:&lt;wall_time:0 logical:0 &gt; &amp;gt; inline:false blind:false &amp;gt; &amp;gt; &amp;gt; max_lease_index:990&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;CockroachDBのキーバリューストレージのデバッグコマンドを試してみました。対応するソースコードも読んでみたいところですが、
&lt;a href=&#34;https://www.arangodb.com/2016/06/arangodb-3-0-a-solid-ground-to-scale/&#34;&gt;ArangoDB 3.0 – A Solid Ground to Scale – ArangoDB&lt;/a&gt;
というニュースを知ったので、今後はArangoDBのほうを先に調べたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>連番ファイル名の命名規則について実験してみた</title>
      <link>/blog/2016/06/22/experimented_with_naming_for_many_sequential_numbered_files/</link>
      <pubDate>Wed, 22 Jun 2016 23:40:27 +0900</pubDate>
      
      <guid>/blog/2016/06/22/experimented_with_naming_for_many_sequential_numbered_files/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;0〜1,000,000といった連番のファイルを作るときに、1つのディレクトリに全てのファイルを入れると、遅くなるとか取り扱いが面倒になるという懸念があります。&lt;/p&gt;

&lt;p&gt;そこで、ディレクトリを切って分割するのですが、数が少ない場合でも多い場合でも良さそうな方法を思いついたのでメモです。&lt;/p&gt;

&lt;h2 id=&#34;素朴な案&#34;&gt;素朴な案&lt;/h2&gt;

&lt;p&gt;最初に思いついたのは以下のような命名規則です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0/000/000
0/000/001
...
0/000/999
0/001/000
0/001/001
...
0/001/999
0/002/000
...
0/999/999
1/000/000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この方式には2つの欠点があります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイルを1つしか作らない場合でも、ディレクトリが必要になる。&lt;/li&gt;
&lt;li&gt;ゼロパディングする際にファイルの最大数を考えて桁数を決めておく必要がある。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;改善案&#34;&gt;改善案&lt;/h2&gt;

&lt;p&gt;上記の2つの欠点を解消する案を思いつきました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.b
1.b
...
999.b
1/000.b
1/001.b
...
1/999.b
2/000.b
...
999/999.b
1/000/000.b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイル名とディレクトリ名が衝突しないようにするため、ファイル名に拡張子を付ける必要があります。&lt;/p&gt;

&lt;p&gt;この方式には以下の利点があります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイル数が1000個以下ならディレクトリを作る必要が無い&lt;/li&gt;
&lt;li&gt;1つのディレクトリ直下にはファイルが最大1000、ディレクトリが最大1000で最大でも合計2000エントリで済む&lt;/li&gt;
&lt;li&gt;ファイルの最大数を事前に決めなくても、パスの長さ制限の範囲内であればこの命名規則でどんどん深いディレクトリを作ってファイルを格納できる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サンプルコード&#34;&gt;サンプルコード&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/many_files_experiment&#34;&gt;hnakamur/many_files_experiment&lt;/a&gt; におきました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LSM-TreeとRocksDB、TiDB、CockroachDBが気になる</title>
      <link>/blog/2016/06/20/lsm-tree-and-rocksdb/</link>
      <pubDate>Mon, 20 Jun 2016 22:23:54 +0900</pubDate>
      
      <guid>/blog/2016/06/20/lsm-tree-and-rocksdb/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;キーバリューストアについて調べていたらLSM-Treeというデータ構造とRocksDBが気になったということで調査メモです。ただし、それぞれの技術詳細を調査したり自分で検証してみたというメモではないです。&lt;/p&gt;

&lt;p&gt;そうではなく、いろんな記事で言及されていたり、ソフトウェアで採用されているのが気になったというだけの浅いメモです。が、脳内バッファからあふれる量になったので自分用に軽くまとめ。&lt;/p&gt;

&lt;h2 id=&#34;lsm-tree&#34;&gt;LSM Tree&lt;/h2&gt;

&lt;p&gt;Log-structured merge-treeを略してLSM Treeと呼ぶそうです。概要は&lt;a href=&#34;https://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;Log-structured merge-tree - Wikipedia&lt;/a&gt;を参照してください。&lt;/p&gt;

&lt;p&gt;CockroachDBのデザインドキュメントの&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/docs/design.md#read-vs-write-optimization-spectrum&#34;&gt;Read vs. Write Optimization Spectrum&lt;/a&gt;によると、B+ Treeというデータ構造は書き込みより読み取りが多いケースに最適化されているが、LSM Treeのほうは書き込みが多いケースに最適化されているそうです。&lt;/p&gt;

&lt;p&gt;一方、LSM Treeのほうはディスク使用量は肥大化しがちで定期的にコンパクションする必要があって、コンパクションには負荷がかかるので、この方式を各実装で工夫しているという話を何処かで読んだんですがリンクを紛失してしまいました。&lt;/p&gt;

&lt;h2 id=&#34;influxdbの事例&#34;&gt;InfluxDBの事例&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/concepts/storage_engine/&#34;&gt;InfluxData | Documentation | Storage Engine&lt;/a&gt;によるとInfluxDBのストレージエンジンは以下の変遷を辿ったそうです。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;LSM Treeの実装の1つである&lt;a href=&#34;https://github.com/google/leveldb&#34;&gt;LevelDB&lt;/a&gt;を採用&lt;/li&gt;
&lt;li&gt;B+Treeの実装の1つである&lt;a href=&#34;https://github.com/boltdb/bolt&#34;&gt;BoltDB&lt;/a&gt;を採用&lt;/li&gt;
&lt;li&gt;LSM Treeに似た独自のデータ構造でストレージエンジンを自作&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;tidbの事例&#34;&gt;TiDBの事例&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/pingcap/tidb&#34;&gt;pingcap/tidb: TiDB is a distributed NewSQL database compatible with MySQL protocol&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TiDB自体はGoで書かれている。&lt;/li&gt;
&lt;li&gt;MySQLのプロトコルを解釈できる。&lt;/li&gt;
&lt;li&gt;MySQLで使用できるSQLのサブセットを実装している。&lt;/li&gt;
&lt;li&gt;TiDBはRustで書かれRaftアルゴリズムを使った分散トランザクション対応のキーバリューデータベース &lt;a href=&#34;https://github.com/pingcap/tikv&#34;&gt;TiKV&lt;/a&gt;を使っている。

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/tidb#what-is-tidb&#34;&gt;What is TiDB?&lt;/a&gt;にはGolevelDB, LevelDB, RocksDB, LMDB, BoltDBに対応しているとあるのですが、TiDBの開発者のLi Shenさんによるとgoleveldbはローカルストレージとしてのみ利用可能で、分散環境ではTiKVを使っているそうです。&lt;/li&gt;
&lt;li&gt;TiKVのストレージエンジンはLSM Treeの実装である&lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;を採用。Li ShenさんによるとTiDBの開発チームはRocsDBのチームとも連絡をとっているそうです。&lt;/li&gt;
&lt;li&gt;TiKV用の&lt;a href=&#34;https://github.com/pingcap/tidb/blob/master/store/tikv/txn.go&#34;&gt;Goのクライアント&lt;/a&gt;もある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;現在バリバリ開発中。&lt;a href=&#34;https://github.com/pingcap/tidb/blob/master/docs/ROADMAP.md&#34;&gt;ロードマップ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TiDBの紹介記事: &lt;a href=&#34;https://www.infiniteloop.co.jp/blog/2016/05/install-tidb/&#34;&gt;MySQL は分散DBの夢を見るか、Google F1 論文を実装した TiDB を使ってみた | 株式会社インフィニットループ技術ブログ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TiDBの起源についてのブログ記事。&lt;a href=&#34;http://0xffff.me/thoughts-behind-tidb-part-1/&#34;&gt;Thoughts behind TiDB - Part I&lt;/a&gt;。私は中国語読めないのでGoogle翻訳で英語にして読みました。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cockroachdbの事例&#34;&gt;CockroachDBの事例&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach&#34;&gt;cockroachdb/cockroach: A Scalable, Survivable, Strongly-Consistent SQL Database&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;名前の由来: &lt;a href=&#34;https://github.com/cockroachdb/cockroach/wiki#why-the-name-cockroach&#34;&gt;Why the name Cockroach?&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CoackroachDBはGoで書かれている。&lt;/li&gt;
&lt;li&gt;PostgreSQLのプロトコルを解釈できる。&lt;/li&gt;
&lt;li&gt;PostgreSQLで使用できるSQLのサブセットを実装している。&lt;/li&gt;
&lt;li&gt;ストレージエンジンは&lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;を採用。&lt;/li&gt;
&lt;li&gt;現在バリバリ開発中。

&lt;ul&gt;
&lt;li&gt;バージョン1.0に向けてベータ版を頻繁に出している。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach/releases&#34;&gt;Releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/wiki&#34;&gt;ロードマップ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;デザインドキュメント &lt;a href=&#34;https://github.com/cockroachdb/cockroach#design&#34;&gt;Design overview&lt;/a&gt;, &lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/docs/design.md&#34;&gt;full design doc&lt;/a&gt;と&lt;a href=&#34;https://www.cockroachlabs.com/docs/frequently-asked-questions.html&#34;&gt;Frequently Asked Questions&lt;/a&gt;がとても充実しています

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/docs/design.md#lock-free-distributed-transactions&#34;&gt;Lock-Free Distributed Transactions&lt;/a&gt;にCockroachDBの分散トランザクションの設計について解説があります。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lsm-treeの実装はいろいろあるがrocksdbが良いらしい&#34;&gt;LSM Treeの実装はいろいろあるがRocksDBが良いらしい&lt;/h2&gt;

&lt;p&gt;InfluxDBの開発元influxdataのブログのベンチマーク記事 &lt;a href=&#34;https://influxdata.com/blog/benchmarking-leveldb-vs-rocksdb-vs-hyperleveldb-vs-lmdb-performance-for-influxdb/&#34;&gt;Benchmarking LevelDB vs. RocksDB vs. HyperLevelDB vs. LMDB Performance for InfluxDB | InfluxData&lt;/a&gt;でも値の書き込みとクエリ実行の性能が良いのはRocksDBとなっています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://smalldatum.blogspot.jp/2015/04/comparing-leveldb-and-rocksdb-take-2.html&#34;&gt;Small Datum: Comparing LevelDB and RocksDB, take 2&lt;/a&gt;にRocksDBとLevelDBのベンチマークがありますが、RocksDBのほうが良い感じです。&lt;/p&gt;

&lt;p&gt;上記の通りTiDBでもCockroachDBでもRocksDBを採用していますし、現在のところ有望そうです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://rocksdb.blogspot.jp/2013/11/the-history-of-rocksdb.html&#34;&gt;Rocksdb: The History of RocksDB&lt;/a&gt;にRocksDBを開始した頃の話が書かれていました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/facebook/rocksdb/wiki/RocksDB-FAQ&#34;&gt;RocksDB FAQ&lt;/a&gt;の &amp;ldquo;Q: What&amp;rsquo;s the maximum key and value sizes supported?&amp;rdquo; によると、RocksDBは大きなサイズのキー用にはデザインされておらず、推奨されるキーと値の最大サイズはそれぞれ8MBと3GBとのことです。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;書き込みが多いケースに向いているキーバリューストアであるRocksDBと、RocksDBをつかて分散トランザクションを実現しているデータベースであるTiDBとCockroachDBの今後に注目したいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>sleuthというGoのライブラリでサービスディスカバリを試してみた</title>
      <link>/blog/2016/06/15/tried-service-discovery-with-sleuth/</link>
      <pubDate>Wed, 15 Jun 2016 06:56:10 +0900</pubDate>
      
      <guid>/blog/2016/06/15/tried-service-discovery-with-sleuth/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://darian.af/post/master-less-peer-to-peer-micro-service-autodiscovery-in-golang-with-sleuth/&#34;&gt;Service autodiscovery in Go with sleuth - darian.af&lt;/a&gt;という記事を見かけて試してみたのでメモです。&lt;/p&gt;

&lt;h2 id=&#34;github-com-ursiform-sleuthのセットアップ&#34;&gt;github.com/ursiform/sleuthのセットアップ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ursiform/sleuth#installation&#34;&gt;Installation&lt;/a&gt;を見ながらセットアップします。&lt;/p&gt;

&lt;p&gt;いきなりgo getでインストールしてみるとZeroMQ version 4が必要というエラーメッセージが出ました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/ursiform/sleuth
# github.com/pebbe/zmq4
In file included from ../../../pebbe/zmq4/ctxoptions_unix.go:7:0:
zmq4.h:2:2: error: #error &amp;quot;You need ZeroMQ version 4 to build this&amp;quot;
 #error &amp;quot;You need ZeroMQ version 4 to build this&amp;quot;
  ^
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ubuntu 16.04では&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install -y libzmq3-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS 7では&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo yum install -y zeromq-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でZeroMQ 4.xのライブラリとヘッダファイルがインストールできます。&lt;/p&gt;

&lt;p&gt;このあとで go get でsleuthをインストールすると今度は大丈夫でした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/ursiform/sleuth
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動作確認のためエコーバックのサービスの例を試す&#34;&gt;動作確認のためエコーバックのサービスの例を試す&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ursiform/sleuth#examples&#34;&gt;Examples&lt;/a&gt;のExample (1)にエコーバックのサーバとクライアントがあるのでそれを試します。&lt;/p&gt;

&lt;p&gt;コードをコピペするのが面倒な人は&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get -d github.com/hnakamur/sleuth-echo-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で取得できます。&lt;/p&gt;

&lt;p&gt;以下のコマンドでプロジェクトのディレクトリに移動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd $GOPATH/src/github.com/hnakamur/sleuth-echo-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のコマンドでエコーバックのサーバを起動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(cd echo-server &amp;amp;&amp;amp; go run main.go &amp;amp;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動すると以下のようなログが出力されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/06/15 06:54:06 [**warning**] sleuth: config.Interface not defined [801]
2016/06/15 06:54:06 [ listening ] sleuth: [SLEUTH-v0:5670][echo-service E13055]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のコマンドでクライアントを実行し、&amp;rdquo;It works.&amp;rdquo; と表示されれば成功です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ (cd echo-client &amp;amp;&amp;amp; go run main.go)
It works.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;curlでも試してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s -d Hello 127.0.0.1:9873/echo-service/
Hello
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;サービスディスカバリの例を試す&#34;&gt;サービスディスカバリの例を試す&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;go get -u github.com/afshin/sleuth-example/...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でサンプルのコードと依存するライブラリを取得し&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd $GOPATH/src/github.com/afshin/sleuth-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でプロジェクトのディレクトリに移動します。&lt;/p&gt;

&lt;p&gt;この例にはarticle-serviceとcomment-serviceという2つのサービスが含まれています。&lt;/p&gt;

&lt;p&gt;まずは article-service を起動します。article-serviceはポート9872で起動されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ (cd article-service &amp;amp;&amp;amp; go run main.go)
2016/06/14 22:38:08 [**warning**] sleuth: config.Interface not defined [801]
2016/06/14 22:38:08 [ listening ] sleuth: [SLEUTH-v0:5670][client-only EC740A]
2016/06/14 22:38:08 [**blocked**] sleuth: waiting for client to find [comment-service]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログに書かれているようにcomment-serviceが見つからなくて待っている状態です。&lt;/p&gt;

&lt;p&gt;別の端末を開いて以下のコマンドを実行してcomment-serviceを起動します。comment-serviceはポート9871で起動されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ (cd comment-service &amp;amp;&amp;amp; go run main.go)
2016/06/15 07:47:42 [**warning**] sleuth: config.Interface not defined [801]
2016/06/15 07:47:42 [ listening ] sleuth: [SLEUTH-v0:5670][comment-service 0DBE04]
ready...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;comment-serviceを起動するとarticle-serviceの端末には以下のログが追加で出力されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/06/15 07:47:43 [*unblocked*] sleuth: client found [comment-service]
ready...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまりarticle-serviceがcomment-serviceを発見（サービスディカバリ）出来たということです。&lt;/p&gt;

&lt;p&gt;別の端末を開いて以下のコマンドを実行してcurlでarticle-serviceから記事のデータを1件取得してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s localhost:9872/articles/049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d | jq .
{
  &amp;quot;success&amp;quot;: true,
  &amp;quot;data&amp;quot;: {
    &amp;quot;guid&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
    &amp;quot;byline&amp;quot;: &amp;quot;Kristen Rasmussen&amp;quot;,
    &amp;quot;headline&amp;quot;: &amp;quot;Wanting the Unwanted: Why Eat Weeds&amp;quot;,
    &amp;quot;url&amp;quot;: &amp;quot;http://www.rootedfood.com/musings/2015/4/1/a-foraged-affair&amp;quot;,
    &amp;quot;time&amp;quot;: 1428168580
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;comment-serviceからコメントのデータを1件取得します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s localhost:9871/comments/06500da3-f9b0-4731-b0fa-fbc6cbe8c155 | jq .
{
  &amp;quot;success&amp;quot;: true,
  &amp;quot;data&amp;quot;: [
    {
      &amp;quot;guid&amp;quot;: &amp;quot;d7041752-6854-4b2c-ad6d-1b48d898668d&amp;quot;,
      &amp;quot;article&amp;quot;: &amp;quot;06500da3-f9b0-4731-b0fa-fbc6cbe8c155&amp;quot;,
      &amp;quot;text&amp;quot;: &amp;quot;Star Trek, on the other hand, consistently presents an optimistic view of our capacity for civilization. I love science-fiction, even when it&amp;amp;#x27;s dystopian. But why does so much of it have to be dystopian?&amp;quot;,
      &amp;quot;time&amp;quot;: 1452738329
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に2つのサービスを連携させた使い方として、以下のコマンドで1件の記事とそれに紐づくコメントを取得します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s localhost:9872/articles/049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d?includecomments=true | jq .
{
  &amp;quot;success&amp;quot;: true,
  &amp;quot;data&amp;quot;: {
    &amp;quot;guid&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
    &amp;quot;byline&amp;quot;: &amp;quot;Kristen Rasmussen&amp;quot;,
    &amp;quot;comments&amp;quot;: [
      {
        &amp;quot;guid&amp;quot;: &amp;quot;1b1e937b-8521-4c88-a13c-105d421ea030&amp;quot;,
        &amp;quot;article&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
        &amp;quot;text&amp;quot;: &amp;quot;I believe the premise to be false, while it is true that you can eat many different &amp;amp;quot;weeds&amp;amp;quot; I cannot find any methodology or theory where that doing so increases the efficiency of land use. There are some key things like nutrients in == nutrie
nts out and digestibility in humans which is not a given.&amp;lt;p&amp;gt;That said, there were some interesting recipes for what are nominally weeds in the Foxfire[1], and Euell Gibbons books[2] which were certainly edible although nothing I&amp;amp;#x27;ve tried really struck me as excepti
onal. As Boy Scouts we got a merit badge for creating a meal out of locally harvested plants, that was fun.&amp;lt;p&amp;gt;[1] &amp;lt;a href=\&amp;quot;http:&amp;amp;#x2F;&amp;amp;#x2F;www.foxfire.org&amp;amp;#x2F;thefoxfirebooks.aspx\&amp;quot; rel=\&amp;quot;nofollow\&amp;quot;&amp;gt;http:&amp;amp;#x2F;&amp;amp;#x2F;www.foxfire.org&amp;amp;#x2F;thefoxfirebooks.aspx&amp;lt;/a&amp;gt;&amp;lt;p&amp;gt;[2]
 &amp;lt;a href=\&amp;quot;http:&amp;amp;#x2F;&amp;amp;#x2F;www.amazon.com&amp;amp;#x2F;Euell-Gibbons-Handbook-Edible-Plants&amp;amp;#x2F;dp&amp;amp;#x2F;0915442787\&amp;quot; rel=\&amp;quot;nofollow\&amp;quot;&amp;gt;http:&amp;amp;#x2F;&amp;amp;#x2F;www.amazon.com&amp;amp;#x2F;Euell-Gibbons-Handbook-Edible-Plants&amp;amp;#x2F;d...&amp;lt;/a&amp;gt;&amp;quot;,
        &amp;quot;time&amp;quot;: 1428172888
      },
      {
        &amp;quot;guid&amp;quot;: &amp;quot;1ffa59ea-1b62-41fe-87c3-98ec6901d768&amp;quot;,
        &amp;quot;article&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
        &amp;quot;text&amp;quot;: &amp;quot;Something to keep in mind here is that once a viable market is found then the product will be fully commercialised and mass-produced.  No longer will poor conditions be good enough when compared to the yield you get from ideal conditions.&amp;lt;p&amp;gt;Then we will
 start fertilising them, then tweaking the seeds etc etc etc. And before long it will be just like anything else grown on the land.&amp;quot;,
        &amp;quot;time&amp;quot;: 1428188859
      },
…(略)…
        &amp;quot;guid&amp;quot;: &amp;quot;587b528f-f4fe-4620-959e-f0d087c97348&amp;quot;,
        &amp;quot;article&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
        &amp;quot;text&amp;quot;: &amp;quot;The premise that weeds are a suitable food for humans is wrong. Most of these plants are loaded with toxins. You can&amp;amp;#x27;t eat them in any quantity for calories without getting poisoned.&amp;lt;p&amp;gt;Cows and goats and sheep can eat these things, though, because 
they have more advanced digestive systems. The udder provides an added toxin filtration system.&amp;lt;p&amp;gt;In theory you might be able to design an efficient system to detoxify wild plants such as grass and weeds directly into a high quality human food. At this moment cheese is 
already an incredibly effective way to use wild forage to make human food.&amp;quot;,
        &amp;quot;time&amp;quot;: 1428192718
      }
    ],
    &amp;quot;headline&amp;quot;: &amp;quot;Wanting the Unwanted: Why Eat Weeds&amp;quot;,
    &amp;quot;url&amp;quot;: &amp;quot;http://www.rootedfood.com/musings/2015/4/1/a-foraged-affair&amp;quot;,
    &amp;quot;time&amp;quot;: 1428168580
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sleuthのq-aを見てみる&#34;&gt;sleuthのQ &amp;amp; Aを見てみる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ursiform/sleuth#q--a&#34;&gt;Q &amp;amp; A&lt;/a&gt;を見ると、sleuthのメッセージプロトコルはJSONをgzipしてHTTPで通信しているとのことです。Protocol Buffersなどの他のライブラリに依存するのを避けたいという意図で、マイクロサービスのAPIレスポンスのほとんどは小さいのでJSONをgzipする方式で十分だし、そのほうがGo以外の言語でも利用しやすいので良いだろうということです。&lt;/p&gt;

&lt;p&gt;sleuthは熊のグループの集合名詞とのことです。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;sleuthはzeromqとGoさえあれば使えるということでセットアップが簡単です。&lt;/p&gt;

&lt;p&gt;サービスの実装&lt;a href=&#34;https://github.com/afshin/sleuth-example/blob/master/article-service/main.go&#34;&gt;sleuth-example/main.go&lt;/a&gt;と&lt;a href=&#34;https://github.com/afshin/sleuth-example/blob/master/comment-service/main.go&#34;&gt;sleuth-example/main.go&lt;/a&gt;も、Goで普通にウェブサービスを実装したところに、sleuthを使うためのコードを少し足すだけでいいのでお手軽でいいですね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>gistを作成するGoのCLIを見つけた</title>
      <link>/blog/2016/06/14/go_cli_to_create_a_gist/</link>
      <pubDate>Tue, 14 Jun 2016 00:52:22 +0900</pubDate>
      
      <guid>/blog/2016/06/14/go_cli_to_create_a_gist/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/delta24/gist&#34;&gt;delta24/gist: A command line gister in Go&lt;/a&gt;です。期待通りに動かない点があったのでプルリクエストを送ったら、すぐにマージされました。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;Goはインストール済みという前提で、以下のコマンドを実行します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get -u github.com/delta24/gist
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;事前準備&#34;&gt;事前準備&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://help.github.com/articles/creating-an-access-token-for-command-line-use/&#34;&gt;Creating an access token for command-line use - User Documentation&lt;/a&gt;の手順でアクセストークンを作って、 &lt;code&gt;~/.bash_profile&lt;/code&gt; とかに &lt;code&gt;export GITHUB_TOKEN=...&lt;/code&gt; のように書くなどして環境変数として設定するか、 あるいは &lt;code&gt;~/.gist&lt;/code&gt; というファイルを作ってトークンの値を書いておきます。&lt;/p&gt;

&lt;h2 id=&#34;使い方の例&#34;&gt;使い方の例&lt;/h2&gt;

&lt;p&gt;自分のユーザでpublicなgistを作成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gist -a=false -d &#39;説明&#39; ファイル名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自分のユーザでprivate (secret)なgistを作成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gist -a=false -p=false -d &#39;説明&#39; ファイル名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;anonymousユーザでpublicなgistを作成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gist -d &#39;説明&#39; ファイル名
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Goのシリアライゼーションのベンチマークを自分でも試してみた</title>
      <link>/blog/2016/06/13/tried_go_serialization_benchmarks/</link>
      <pubDate>Mon, 13 Jun 2016 23:34:16 +0900</pubDate>
      
      <guid>/blog/2016/06/13/tried_go_serialization_benchmarks/</guid>
      <description>&lt;p&gt;2015年12月の記事ですが&lt;a href=&#34;http://qiita.com/shibukawa/items/878c5fe8ec09935fccd2&#34;&gt;最速という噂のFlatbuffersの速度のヒミツと、導入方法の紹介(Go) - Qiita&lt;/a&gt;を読んで、「gobは遅いのかー、残念」、「一方Flatbuffersは面倒そうだなー」と思っていました。&lt;/p&gt;

&lt;p&gt;で、&lt;a href=&#34;https://github.com/alecthomas/go_serialization_benchmarks/tree/48e2bb8b7b6c38c24c88a0b027b30c80175a7b59#results&#34;&gt;alecthomas/go_serialization_benchmarks at 48e2bb8b7b6c38c24c88a0b027b30c80175a7b59&lt;/a&gt;のベンチマーク結果を見てみると、あれgob遅くないよ、というかVmihailencoMsgpackとUgorjiCodecMsgpackより速くなってました。&lt;/p&gt;

&lt;p&gt;自宅サーバ (NEC Express5800/S70)でもベンチマークを試してみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench . -benchmem | tee bench.txt                                                                                                                                               

A test suite for benchmarking various Go serialization methods.

See README.md for details on running the benchmarks.

PASS
BenchmarkMsgpMarshal-2                   3000000               423 ns/op             128 B/op          1 allocs/op
BenchmarkMsgpUnmarshal-2                 2000000               741 ns/op             112 B/op          3 allocs/op
BenchmarkVmihailencoMsgpackMarshal-2      500000              3107 ns/op             368 B/op          6 allocs/op
BenchmarkVmihailencoMsgpackUnmarshal-2    300000              4469 ns/op             352 B/op         13 allocs/op
BenchmarkJsonMarshal-2                    200000              7070 ns/op            1232 B/op         10 allocs/op
BenchmarkJsonUnmarshal-2                  200000              7331 ns/op             416 B/op          7 allocs/op
BenchmarkEasyJsonMarshal-2                500000              3116 ns/op             784 B/op          5 allocs/op
BenchmarkEasyJsonUnmarshal-2              500000              2936 ns/op             160 B/op          4 allocs/op
BenchmarkBsonMarshal-2                    500000              3031 ns/op             392 B/op         10 allocs/op
BenchmarkBsonUnmarshal-2                  500000              4047 ns/op             248 B/op         21 allocs/op
BenchmarkGobMarshal-2                    1000000              2189 ns/op              48 B/op          2 allocs/op
BenchmarkGobUnmarshal-2                  1000000              2226 ns/op             112 B/op          3 allocs/op
BenchmarkXdrMarshal-2                     500000              3862 ns/op             456 B/op         21 allocs/op
BenchmarkXdrUnmarshal-2                   500000              2885 ns/op             239 B/op         11 allocs/op
BenchmarkUgorjiCodecMsgpackMarshal-2      200000              7052 ns/op            2752 B/op          8 allocs/op
BenchmarkUgorjiCodecMsgpackUnmarshal-2    200000              7586 ns/op            3008 B/op          6 allocs/op
BenchmarkUgorjiCodecBincMarshal-2         200000              7347 ns/op            2784 B/op          8 allocs/op
BenchmarkUgorjiCodecBincUnmarshal-2       200000              8163 ns/op            3168 B/op          9 allocs/op
BenchmarkSerealMarshal-2                  200000              7518 ns/op             912 B/op         21 allocs/op
BenchmarkSerealUnmarshal-2                200000              7039 ns/op            1008 B/op         34 allocs/op
BenchmarkBinaryMarshal-2                  500000              2757 ns/op             256 B/op         16 allocs/op
BenchmarkBinaryUnmarshal-2                500000              3057 ns/op             336 B/op         22 allocs/op
BenchmarkFlatBuffersMarshal-2            3000000               573 ns/op               0 B/op          0 allocs/op
BenchmarkFlatBuffersUnmarshal-2          3000000               538 ns/op             112 B/op          3 allocs/op
BenchmarkCapNProtoMarshal-2              2000000               874 ns/op              56 B/op          2 allocs/op
BenchmarkCapNProtoUnmarshal-2            2000000               817 ns/op             200 B/op          6 allocs/op
BenchmarkCapNProto2Marshal-2             1000000              1991 ns/op             244 B/op          3 allocs/op
BenchmarkCapNProto2Unmarshal-2           1000000              2064 ns/op             320 B/op          6 allocs/op
BenchmarkHproseMarshal-2                 1000000              1797 ns/op             479 B/op          8 allocs/op
BenchmarkHproseUnmarshal-2                500000              2250 ns/op             320 B/op         10 allocs/op
BenchmarkProtobufMarshal-2               1000000              2052 ns/op             200 B/op          7 allocs/op
BenchmarkProtobufUnmarshal-2             1000000              1700 ns/op             192 B/op         10 allocs/op
BenchmarkGoprotobufMarshal-2             1000000              1141 ns/op             312 B/op          4 allocs/op
BenchmarkGoprotobufUnmarshal-2           1000000              1721 ns/op             432 B/op          9 allocs/op
BenchmarkGogoprotobufMarshal-2           5000000               291 ns/op              64 B/op          1 allocs/op
BenchmarkGogoprotobufUnmarshal-2         3000000               445 ns/op              96 B/op          3 allocs/op
BenchmarkColferMarshal-2                 5000000               260 ns/op              64 B/op          1 allocs/op
BenchmarkColferUnmarshal-2               5000000               387 ns/op             112 B/op          3 allocs/op
BenchmarkGencodeMarshal-2                5000000               322 ns/op              80 B/op          2 allocs/op
BenchmarkGencodeUnmarshal-2              5000000               392 ns/op             112 B/op          3 allocs/op
BenchmarkGencodeUnsafeMarshal-2         10000000               196 ns/op              48 B/op          1 allocs/op
BenchmarkGencodeUnsafeUnmarshal-2        5000000               322 ns/op              96 B/op          3 allocs/op
BenchmarkXDR2Marshal-2                   5000000               333 ns/op              64 B/op          1 allocs/op
BenchmarkXDR2Unmarshal-2                 5000000               313 ns/op              32 B/op          2 allocs/op
ok      github.com/alecthomas/go_serialization_benchmarks       81.009s
$ go version
go version go1.6.2 linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こちらも同じくgobはVmihailencoMsgpackとUgorjiCodecMsgpackより速かったです。Goのバージョンの違いなのかライブラリの進化なのかは調べてないですが、いつのまにか逆転していたようです。&lt;/p&gt;

&lt;p&gt;ということで、Go以外の言語との相互運用性を考えなくて良いなら、gobもシリアライゼーションのライブラリ選択の候補に入れて良さそうと思いました。&lt;a href=&#34;https://golang.org/pkg/encoding/gob/&#34;&gt;gob&lt;/a&gt;を見る限りはstructに対して特に何もしなくても使えるようなのでお手軽さでは一番良さそうですし。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GoでLTSV形式でログ出力するライブラリを書いた</title>
      <link>/blog/2016/06/13/wrote_go_ltsvlog_library/</link>
      <pubDate>Mon, 13 Jun 2016 21:42:53 +0900</pubDate>
      
      <guid>/blog/2016/06/13/wrote_go_ltsvlog_library/</guid>
      <description>

&lt;h2 id=&#34;なぜ書いたか&#34;&gt;なぜ書いたか&lt;/h2&gt;

&lt;p&gt;Goで高機能なサードパーティのログ出力ライブラリと言えば&lt;a href=&#34;https://github.com/Sirupsen/logrus&#34;&gt;Sirupsen/logrus&lt;/a&gt;が有名です。私も&lt;a href=&#34;https://github.com/doloopwhile/logrusltsv&#34;&gt;doloopwhile/logrusltsv&lt;/a&gt;と組み合わせてLTSV形式のログ出力するのに使っていました。&lt;/p&gt;

&lt;p&gt;しかし、&lt;a href=&#34;http://methane.hatenablog.jp/entry/2015/09/17/logger_%E3%81%AE%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6_%5BGo%5D&#34;&gt;logger のパフォーマンスについて [Go] - methaneのブログ&lt;/a&gt;にも書かれていますが、&lt;a href=&#34;https://godoc.org/github.com/Sirupsen/logrus#WithFields&#34;&gt;logrus.WithFields&lt;/a&gt;は&lt;a href=&#34;https://godoc.org/github.com/Sirupsen/logrus#Fields&#34;&gt;Fields&lt;/a&gt;、つまり &lt;code&gt;map[string]interface{}&lt;/code&gt; の値を渡す必要があります。これはGCに負荷をかけそうというのも気になりますが、Goのmapは順不同なのでログ出力の際にキーの順番がソースに書いた順番と必ずしも一致しないというのがイマイチだよなーと思っていました。&lt;/p&gt;

&lt;p&gt;ログ出力ライブラリはライブラリによって違うものを使うのはよくないから、自作するよりメジャーなものを使うほうが良いと自重する思いもありました。&lt;/p&gt;

&lt;p&gt;一方で、&lt;a href=&#34;http://dave.cheney.net/2015/11/05/lets-talk-about-logging&#34;&gt;Let’s talk about logging | Dave Cheney&lt;/a&gt;には賛同する点も多く、感銘を受けました。&lt;/p&gt;

&lt;p&gt;で、一度自作してみようかなーと思っていたところに、&lt;a href=&#34;https://github.com/uber-go/zap&#34;&gt;uber-go/zap&lt;/a&gt;を見かけて、ログ出力の引数側を加工するという方式にインスパイアされ、ついに自分が欲しいものを自分で書いてみました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;githubレポジトリ: &lt;a href=&#34;https://github.com/hnakamur/ltsvlog&#34;&gt;hnakamur/ltsvlog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;APIドキュメント: &lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog&#34;&gt;ltsvlog - GoDoc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;githubレポジトリのREADMEに使用例のコードがあります。&lt;/p&gt;

&lt;h2 id=&#34;ltsvlogの設計と実装&#34;&gt;ltsvlogの設計と実装&lt;/h2&gt;

&lt;h3 id=&#34;ltsvlogのログレベル&#34;&gt;ltsvlogのログレベル&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://dave.cheney.net/2015/11/05/lets-talk-about-logging&#34;&gt;Let’s talk about logging | Dave Cheney&lt;/a&gt;にもありましたが、ログレベルが多すぎると使い分けで悩むので少ないほうが良いと私も思います。ただ、エラー以外にもなにかが成功したときに記録しておきたいことはあるので、ErrorとInfoは分けたほうが良いと思います。あと私はprintデバッグ信者なのでデバッグログ用のDebugレベルは必要です。&lt;/p&gt;

&lt;p&gt;ということで、ltsvlogのログレベルはDebug, Info, Errorの3つです。&lt;/p&gt;

&lt;p&gt;レベル毎に出力するかしないかの切り替えはDebugレベルのみ許可することにしました。InfoとErrorは本番運用時にもログ出力するものだけに使うという考えです。Debugレベルを出力するかどうかは&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#NewLTSVLogger&#34;&gt;NewLTSVLogger&lt;/a&gt;でロガーを作るときに指定します。&lt;/p&gt;

&lt;p&gt;またDebugレベルのログ出力は無効時には引数の評価もしたくないので、 &lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LTSVLogger.DebugEnabled&#34;&gt;LTSVLogger.DebugEnabled()&lt;/a&gt;というメソッドも用意しました。使用例はこんな感じです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    if ltsvlog.Logger.DebugEnabled() {
        ltsvlog.Logger.Debug(ltsvlog.LV{&amp;quot;msg&amp;quot;, &amp;quot;This is a debug message&amp;quot;},
            ltsvlog.LV{&amp;quot;key&amp;quot;, &amp;quot;key1&amp;quot;}, ltsvlog.LV{&amp;quot;intValue&amp;quot;, 234})
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;スタックトレースの出力&#34;&gt;スタックトレースの出力&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LTSVLogger.ErrorWithStack&#34;&gt;LTSVLogger.ErrorWithStack&lt;/a&gt;でスタックトレース付きでログ出力できます。&lt;/p&gt;

&lt;p&gt;LTSV形式ではログは1レコードで1行にする必要があります。&lt;a href=&#34;https://golang.org/pkg/runtime/#Stack&#34;&gt;runtime.Stack&lt;/a&gt;でスタックトレースをバッファに書いてくれるのですが、こちらは複数行の出力になっています。コードを適宜コピペして好きな形式で出力するようにしようかと思ったのですが、&lt;a href=&#34;https://golang.org/src/runtime/mprof.go?s=16037:16073#L574&#34;&gt;src/runtime/mprof.go&lt;/a&gt;のソースコードを見て思いとどまりました。&lt;/p&gt;

&lt;p&gt;ということで、runtime.Stackの出力結果を加工するという方式で実装しています。
実際のコードは&lt;a href=&#34;https://github.com/hnakamur/ltsvlog/blob/v0.9.3/stack.go#L13-L60&#34;&gt;ltsvlog/stack.go&lt;/a&gt;です。コールスタックから不要な部分を取り除きつつ複数行から1行に変形するということで必ず元の長さより縮むので runtime.Stack で出力したバッファをそのまま使って変形しています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/runtime/#Stack&#34;&gt;runtime.Stack&lt;/a&gt;は呼び出し側がバッファを渡す必要があるのですが、サイズが小さいとスタックトレースが途中で切れてしまいます。デフォルトで 8192 というサイズにしたのですが、足りない場合は &lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#NewLTSVLoggerCustomFormat&#34;&gt;NewLTSVLoggerCustomFormat&lt;/a&gt; の引数でバッファサイズを指定できるようにしてます。&lt;/p&gt;

&lt;h3 id=&#34;時刻とログレベルの出力&#34;&gt;時刻とログレベルの出力&lt;/h3&gt;

&lt;p&gt;時刻はUTCでフォーマットは &lt;a href=&#34;https://golang.org/pkg/time/#pkg-constants&#34;&gt;time&lt;/a&gt;パッケージの &lt;code&gt;RFC3339Nano = &amp;quot;2006-01-02T15:04:05.999999999Z07:00&amp;quot;&lt;/code&gt; に近いですが、ナノセカンドの部分は個人的な好みで9桁固定で出力するようにしました。&lt;/p&gt;

&lt;h3 id=&#34;値の文字列化&#34;&gt;値の文字列化&lt;/h3&gt;

&lt;p&gt;上のコード例のようにラベルと値の組は&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LV&#34;&gt;ltsvlog.LV&lt;/a&gt;で指定します。&lt;/p&gt;

&lt;p&gt;将来 LV にフィールドが追加されるかもしれないと防御的に実装するなら、以下のように書いたほうが良いわけですが、LabelとValueでLVということでフィールド追加するつもりは無いので &lt;code&gt;L:&lt;/code&gt; や &lt;code&gt;V:&lt;/code&gt; は省略して、上記の例のように書いています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    if ltsvlog.Logger.DebugEnabled() {
        ltsvlog.Logger.Debug(ltsvlog.LV{L: &amp;quot;msg&amp;quot;, V: &amp;quot;This is a debug message&amp;quot;},
            ltsvlog.LV{L: &amp;quot;key&amp;quot;, V: &amp;quot;key1&amp;quot;}, ltsvlog.LV{L: &amp;quot;intValue&amp;quot;, V: 234})
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値の文字列化は &lt;a href=&#34;https://github.com/hnakamur/ltsvlog/blob/v0.9.3/log.go#L175-L219&#34;&gt;https://github.com/hnakamur/ltsvlog/blob/v0.9.3/log.go#L175-L219&lt;/a&gt; で行っています。&lt;a href=&#34;https://golang.org/ref/spec#Type_switches&#34;&gt;Type switches&lt;/a&gt;を使って、値の型に応じて文字列化しています。コメントにも書いていますが、byteとuint8、runeとuintは別のcaseとして書くとコンパイルエラーになったので諦めてuint8とuintのほうだけを残しています。&lt;/p&gt;

&lt;p&gt;時刻とログレベルの出力形式と値の文字列化の方式を変えたい場合は関数を実装して&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#NewLTSVLoggerCustomFormat&#34;&gt;NewLTSVLoggerCustomFormat&lt;/a&gt; の引数に指定すれば良いようにしてあります。&lt;/p&gt;

&lt;h3 id=&#34;グローバルロガー&#34;&gt;グローバルロガー&lt;/h3&gt;

&lt;p&gt;標準の&lt;a href=&#34;https://golang.org/pkg/log/&#34;&gt;log&lt;/a&gt;パッケージではグローバルロガーの変数は非公開で&lt;a href=&#34;https://golang.org/pkg/log/#Print&#34;&gt;log.Print&lt;/a&gt;や&lt;a href=&#34;https://golang.org/pkg/log/#SetOutput&#34;&gt;log.SetOutput&lt;/a&gt;の関数で操作するようになっています。&lt;/p&gt;

&lt;p&gt;私は関数を増やすのが嫌だったのとグローバルロガーの変数は公開しても良いのではと思ったのでそうしました。&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#pkg-variables&#34;&gt;ltsvlog.Logger&lt;/a&gt;で参照できます。デフォルトでは標準出力にデバッグログありで出力するようになっています。デバッグログをオフにしたい場合はmain関数の最初のほうで(ログ出力する前に)以下のようにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; ltsvlog.Logger = ltsvlog.NewLTSVLogger(os.Stdout, false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログ出力中に設定を変えることはないという想定です。&lt;/p&gt;

&lt;h3 id=&#34;logwriterインタフェースと常に何も出力しないdiscard&#34;&gt;LogWriterインタフェースと常に何も出力しないDiscard&lt;/h3&gt;

&lt;p&gt;後付ですが&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LogWriter&#34;&gt;ltsvlog.LogWriter&lt;/a&gt;というインタフェースも定義してみました。インタフェースは Logger という名前にしたいところでしたが、グローバルロガーに Logger という名前を使っていたので仕方なく LogWriter にしました。そして常に何も出力しない Discard というのも作りました。ただし、Infoなどの引数は評価されてしまうので実行コストが0なわけではないです。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/ltsvlog#benchmark-result&#34;&gt;Benchmark result&lt;/a&gt;に標準のlogパッケージと比較したベンチマーク結果を載せています。logパッケージよりは遅い手ですがほぼ同等だと言えると思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/ltsvlog&#34;&gt;hnakamur/ltsvlog&lt;/a&gt;はコード量も大したことないので、保守で困ることはないと楽観視しています。&lt;/p&gt;

&lt;p&gt;ということで自分で書くライブラリやアプリケーションではどんどん使っていきたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Goで複数のリモートのワーカーにジョブを実行させるremoteworkersというパッケージを書いた</title>
      <link>/blog/2016/06/12/wrote_remoteworkers_go_pacakge/</link>
      <pubDate>Sun, 12 Jun 2016 21:53:35 +0900</pubDate>
      
      <guid>/blog/2016/06/12/wrote_remoteworkers_go_pacakge/</guid>
      <description>

&lt;h2 id=&#34;なぜ書いたか&#34;&gt;なぜ書いたか&lt;/h2&gt;

&lt;p&gt;仕事で複数のサーバで同じ処理を実行して結果を集めたいというニーズがあって、各サーバをgRPCのサーバにするという実装でとりあえず実現していました。でも、出来れば処理を実行するワーカーサーバから制御サーバに接続して繋ぎっぱなしにしておいて、制御サーバからジョブを送り込む方式にしたいなーと思っていて、家で実装を進めていました。&lt;/p&gt;

&lt;h2 id=&#34;これまでに試したこと&#34;&gt;これまでに試したこと&lt;/h2&gt;

&lt;p&gt;gRPCに&lt;a href=&#34;http://www.grpc.io/docs/tutorials/basic/go.html#bidirectional-streaming-rpc&#34;&gt;Bidirectional streaming RPC&lt;/a&gt;というのがあったので、&lt;a href=&#34;https://github.com/hnakamur/grpc_notification_experiment&#34;&gt;hnakamur/grpc_notification_experiment&lt;/a&gt;で試してみたのですが、複数クライアントがサーバに接続した状態で、サーバからクライアントにジョブを投げても、1つのクライアントでしか処理が実行されないということがわかりました。&lt;/p&gt;

&lt;p&gt;次に、ワーカーサーバから制御サーバにTCPのソケットで接続しておいて、制御サーバからワーカーサーバにジョブを投げて結果を集めるサンプルを書いてみました。
&lt;a href=&#34;https://github.com/hnakamur/tcp_pubsubreply_experiment&#34;&gt;hnakamur/tcp_pubsubreply_experiment&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;複数のワーカーに同じジョブを投げて結果を集めて、全てのワーカーからの結果が揃ったらクライアントに結果を返すというものです。 &lt;a href=&#34;https://github.com/hnakamur/tcp_pubsubreply_experiment/blob/f9201c075661c5d58895f9a30b47f73f5c4cc13d/main.go#L167-L189&#34;&gt;https://github.com/hnakamur/tcp_pubsubreply_experiment/blob/f9201c075661c5d58895f9a30b47f73f5c4cc13d/main.go#L167-L189&lt;/a&gt; でジョブを各ワーカーのコネクションが持つチャンネルに送って、各ワーカーの結果を返すチャンネルから受け取るという素朴な実装になっています。&lt;/p&gt;

&lt;p&gt;しかし、この実装では1つのジョブを実行中は他のジョブを実行できないという制限があります。また試しているとタイミングによっては期待通りの動きにならないことがありました。&lt;/p&gt;

&lt;h2 id=&#34;今回の実装&#34;&gt;今回の実装&lt;/h2&gt;

&lt;p&gt;実装は&lt;a href=&#34;https://github.com/hnakamur/remoteworkers&#34;&gt;hnakamur/remoteworkers&lt;/a&gt;で公開しています。使用例は&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/tree/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example&#34;&gt;remoteworkers/example&lt;/a&gt;、APIドキュメントは&lt;a href=&#34;https://godoc.org/github.com/hnakamur/remoteworkers&#34;&gt;remoteworkers - GoDoc&lt;/a&gt;を参照してください。&lt;/p&gt;

&lt;p&gt;最初はWebSocketのライブラリ&lt;a href=&#34;https://github.com/gorilla/websocket&#34;&gt;github.com/gorilla/websocket&lt;/a&gt;の&lt;a href=&#34;https://github.com/gorilla/websocket/tree/a68708917c6a4f06314ab4e52493cc61359c9d42/examples&#34;&gt;examples&lt;/a&gt;のchatとechoのclientを組み合わせて改変していきました。chatは1つのクライアントからのメッセージを他のクライアントに送って終わりですが、今回はジョブを実行して結果を集めたいので、その処理を追加で実装しました。また、元のサンプルはグローバル変数や設定用の定数を使うようになっていたのでstructを定義してグローバル変数をやめて設定もstructのメンバーに持つようにしました。&lt;/p&gt;

&lt;p&gt;ワーカーはサーバにwebsocketで接続しますが、クライアントは通常のhttpリクエストでジョブを投げてレスポンスで結果を受け取るようにしてみました。ワーカーとサーバの間のメッセージは&lt;a href=&#34;/blog/blog/2016/06/04/benchmark_go_msgpack_libraries/&#34;&gt;GoのMessagePackのライブラリのベンチマークをしてみた · hnakamur&amp;rsquo;s blog at github&lt;/a&gt;で試した&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;vmihailenco/msgpack&lt;/a&gt;を使ってMessagePackでエンコード・デコードしています。&lt;/p&gt;

&lt;p&gt;以下実装メモです。&lt;/p&gt;

&lt;h3 id=&#34;connとhub&#34;&gt;ConnとHub&lt;/h3&gt;

&lt;p&gt;サーバ側のメインの処理は、サーバとワーカーのコネクションを扱う&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go&#34;&gt;Conn&lt;/a&gt;と複数のConnの間を取り持つ&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go&#34;&gt;Hub&lt;/a&gt;が担当しています。&lt;/p&gt;

&lt;h3 id=&#34;読み取りと書き出しでgoroutineを分ける&#34;&gt;読み取りと書き出しでgoroutineを分ける&lt;/h3&gt;

&lt;p&gt;上記の&lt;a href=&#34;https://github.com/hnakamur/tcp_pubsubreply_experiment&#34;&gt;hnakamur/tcp_pubsubreply_experiment&lt;/a&gt;では、ワーカーとサーバ間のTCPコネクション1つのに対して1つgoroutineを作ってデータの読み書きをしていました。&lt;/p&gt;

&lt;p&gt;一方、&lt;a href=&#34;https://godoc.org/github.com/gorilla/websocket&#34;&gt;github.com/gorilla/websocketのAPIドキュメント&lt;/a&gt;の&lt;a href=&#34;https://godoc.org/github.com/gorilla/websocket#hdr-Concurrency&#34;&gt;Concurrency&lt;/a&gt;にコネクションは1つのコンカレントなリーダーと1つのコンカレントなライターをサポートすると書いてあります。&lt;/p&gt;

&lt;p&gt;chatのexampleを見ると&lt;a href=&#34;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L50-L69&#34;&gt;Conn.readPump()&lt;/a&gt;で読み取り処理のループ、&lt;a href=&#34;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L78-L116&#34;&gt;Conn.writePump()&lt;/a&gt;で書き出し処理のループを実装していて &lt;a href=&#34;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L127-L128&#34;&gt;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L127-L128&lt;/a&gt; でgoroutineを使って並行(concurrent)に実行しています。&lt;/p&gt;

&lt;p&gt;この方式により上記の&lt;a href=&#34;https://godoc.org/github.com/gorilla/websocket#hdr-Concurrency&#34;&gt;Concurrency&lt;/a&gt;の1つのコネクションに1つのコンカレントなリーダーと1つのコンカレントなライターという条件を自動的に満たすことが出来ます。&lt;/p&gt;

&lt;p&gt;さらに、ワーカーでのジョブの実行も &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L200-L214&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L200-L214&lt;/a&gt; のように別のgoroutineで実行するようにしました。読み取りと書き出しのgoroutineを分け、ジョブ実行のgoroutineも別にしたことで、ワーカーでジョブを実行中でも別のジョブを受け取って実行することが出来るようになりました。&lt;/p&gt;

&lt;h3 id=&#34;ジョブのディスパッチと結果の収集&#34;&gt;ジョブのディスパッチと結果の収集&lt;/h3&gt;

&lt;p&gt;各ワーカーからにジョブを投げて結果を集める部分も &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L139-L171&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L139-L171&lt;/a&gt; のように書くことで、複数のジョブを並行で実行できるようになっています。&lt;/p&gt;

&lt;p&gt;例えば、あるジョブを依頼されてそれの結果が集まる前に、次のジョブを受け取ってそちらの結果が先に集まった場合はそちらを先に返すことができます。&lt;/p&gt;

&lt;h3 id=&#34;自動で再接続&#34;&gt;自動で再接続&lt;/h3&gt;

&lt;p&gt;ワーカーとの接続が切れた場合は、残ったワーカーだけで処理を実行する仕様としました。ジョブを受け取った時にワーカーが1つもいない場合はエラーとしています。また、ワーカーからサーバへの接続が切れた場合は1秒待って再起動を無限に繰り替えすようにしています。時間は設定で変更可能です。ただし、だんだん間隔を開けるといったことは出来ないのでその場合はフォークして改変してください。&lt;/p&gt;

&lt;h3 id=&#34;返信用のチャンネルを渡して実行&#34;&gt;返信用のチャンネルを渡して実行&lt;/h3&gt;

&lt;p&gt;サーバとワーカのコネクションをHubに登録する箇所 &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L86-L92&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L86-L92&lt;/a&gt; とクライアントから依頼されたジョブをHubに投げて全ワーカーからの結果を受け取る箇所 &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L194-L203&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L194-L203&lt;/a&gt; では、結果を受け取るためのチャンネルをHubへのチャンネルに渡して実行するという方法を取りました。&lt;/p&gt;

&lt;p&gt;これによってHubとのやり取りは全てチャンネル経由になりシンプルになりました。さらに関数の中に閉じ込めることで、ライブラリの利用者はチャンネルを意識することなく単なる関数呼び出しで使えるようになっています。&lt;/p&gt;

&lt;h3 id=&#34;ジョブのエンコード-デコード&#34;&gt;ジョブのエンコード・デコード&lt;/h3&gt;

&lt;p&gt;まずクライアントではジョブをJSONでエンコードしています。
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/client/client.go#L25-L30&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/client/client.go#L25-L30&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;サーバでは受け取ったジョブをJSONでデコードします。
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L52-L54&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L52-L54&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;その後&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L193-L205&#34;&gt;Hub.RequestWork()&lt;/a&gt;でHubにジョブが渡されて
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L142&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L142&lt;/a&gt;
でMessagePackでエンコードしてワーカーに送ります。&lt;/p&gt;

&lt;p&gt;ワーカーでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L187-L188&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L187-L188&lt;/a&gt;
で受け取ったジョブをMessagePackでデコードします。&lt;/p&gt;

&lt;p&gt;ワーカーでジョブを受け取って処理する部分は
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/worker/main.go#L47-L58&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/worker/main.go#L47-L58&lt;/a&gt;
です。&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;vmihailenco/msgpack&lt;/a&gt;で &lt;code&gt;map[string]string&lt;/code&gt; 型をエンコードしてデコードすると &lt;code&gt;map[interface{}]interface{}&lt;/code&gt; になったので&lt;a href=&#34;https://golang.org/ref/spec#Type_assertions&#34;&gt;type assertion&lt;/a&gt;を使って参照する必要がありました。&lt;/p&gt;

&lt;h3 id=&#34;結果のエンコード-デコード&#34;&gt;結果のエンコード・デコード&lt;/h3&gt;

&lt;p&gt;ワーカーでの結果は
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L202-L206&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L202-L206&lt;/a&gt;
でMessagePackにエンコードしています。&lt;/p&gt;

&lt;p&gt;サーバでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L148-L163&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L148-L163&lt;/a&gt;
で結果をMessagePackでデコードしてHubに送っています。&lt;/p&gt;

&lt;p&gt;Hubでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L165-L171&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L165-L171&lt;/a&gt;
で1つのワーカーからの結果を受け取り、全てのワーカーからの結果が揃ったらクライアントへ返信するためのチャンネルに集めた結果を送ります。&lt;/p&gt;

&lt;p&gt;サーバでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L28-L39&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L28-L39&lt;/a&gt;
で集めた結果の構造を変形し、
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L69-L70&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L69-L70&lt;/a&gt;
でJSONにエンコードしています。&lt;/p&gt;

&lt;h3 id=&#34;tcpソケットからwebsocketにして良かったところ&#34;&gt;TCPソケットからWebSocketにして良かったところ&lt;/h3&gt;

&lt;p&gt;ワーカーからサーバに接続したときにワーカーのIDを登録しているのですが、TCPソケットのときはそのためにワーカーから登録用のメッセージを送って成功失敗の結果を送る必要がありました。一方WebSocketではエンドポイントに接続するときにリクエストヘッダで追加の情報を送れるので &lt;code&gt;X-Worker-ID&lt;/code&gt; と言うヘッダ名でワーカーIDを送るようにしました。&lt;/p&gt;

&lt;p&gt;また、TCPソケットだと1つのポートでクライアントとワーカーからの通信を受ける場合はメッセージの内容で区別がつくようにしておく必要があります。WebSocketの場合は1つのポートでもURLのPathを別にするという手が使えるので楽です。しかも今回のようにワーカーはWebSocketで接続し、クライアントはhttpで接続ということも出来て便利です。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;当初やりたいと思っていたことがようやく実現できました。しかも、これだけ並列性が高いプログラムなのにgoroutineとchannelのおかげですっきりシンプルなコードで実装出来ています。これなら保守や改変もしやすくて助かります。やっぱりGoは素晴らしいです！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GoのMessagePackのライブラリのベンチマークをしてみた</title>
      <link>/blog/2016/06/04/benchmark_go_msgpack_libraries/</link>
      <pubDate>Sat, 04 Jun 2016 22:17:52 +0900</pubDate>
      
      <guid>/blog/2016/06/04/benchmark_go_msgpack_libraries/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://qiita.com/yosisa/items/f21d3476bc8d368d7494&#34;&gt;Go の msgpack ライブラリ比較 - Qiita&lt;/a&gt;の記事が最終更新日から1年以上経過しているとのことなので、現在の最新のコミットで試してみました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;github.com/vmihailenco/msgpack&lt;/code&gt; を &lt;code&gt;go get&lt;/code&gt; すると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/vmihailenco/msgpack
package github.com/vmihailenco/msgpack: code in directory /home/hnakamur/gocode/src/github.com/vmihailenco/msgpack expects import &amp;quot;gopkg.in/vmihailenco/msgpack.v2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と言われたので &lt;code&gt;go get gopkg.in/vmihailenco/msgpack.v2&lt;/code&gt; で取得し、この記事のコードの &lt;code&gt;&amp;quot;github.com/vmihailenco/msgpack&amp;quot;&lt;/code&gt; を &lt;code&gt;&amp;quot;gopkg.in/vmihailenco/msgpack.v2&amp;quot;&lt;/code&gt; に書き換え &lt;code&gt;msgpack_test.go&lt;/code&gt; という名前で保存して試しました。&lt;/p&gt;

&lt;p&gt;エンコードは &lt;code&gt;gopkg.in/vmihailenco/msgpack.v2&lt;/code&gt; 、デコードは &lt;code&gt;github.com/ugorji/go/codec&lt;/code&gt; が速いという結果になりましたが、総合的にはほぼ同等と言えると思います。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench . -benchmem
testing: warning: no tests to run
PASS
BenchmarkCodecEncode-2            500000              3236 ns/op              48 B/op          2 allocs/op
BenchmarkCodecDecode-2            200000              8998 ns/op             264 B/op         25 allocs/op
BenchmarkMsgpackEncode-2          500000              2624 ns/op              48 B/op          2 allocs/op
BenchmarkMsgpackDecode-2          200000             10604 ns/op             448 B/op         35 allocs/op
ok      bitbucket.org/hnakamur/msgpack_experiment       7.146s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ベンチマークに使用したライブラリとGoのバージョンは以下の通りです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git -C $GOPATH/src/github.com/ugorji/go rev-parse HEAD
a396ed22fc049df733440d90efe17475e3929ccb
$ git -C $GOPATH/src/gopkg.in/vmihailenco/msgpack.v2 rev-parse HEAD
851cd631b60599a692b136c60eb6eb2899b0e664
$ go version
go version go1.6.2 linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;vmihailenco/msgpack: MessagePack encoding for Golang&lt;/a&gt;のベンチマークもやってみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench . -benchmem                                          
2016/06/04 22:12:13 
************************************************ 
package github.com/ugorji/go-msgpack has been deprecated (05/29/2013). 
It will be retired anytime from July 1, 2013.
Please update to faster and much much better github.com/ugorji/go/codec.
See https://github.com/ugorji/go/tree/master/codec#readme for more information.
************************************************ 
OK: 27 passed, 1 skipped
PASS
BenchmarkBool-2                         20000000                90.3 ns/op             0 B/op          0 allocs/op
BenchmarkInt0-2                         20000000                96.1 ns/op             0 B/op          0 allocs/op
BenchmarkInt1-2                         10000000               123 ns/op               0 B/op          0 allocs/op
BenchmarkInt2-2                         10000000               123 ns/op               0 B/op          0 allocs/op
BenchmarkInt4-2                         10000000               179 ns/op               0 B/op          0 allocs/op
BenchmarkInt8-2                         10000000               176 ns/op               0 B/op          0 allocs/op
BenchmarkInt0Binary-2                    5000000               340 ns/op              24 B/op          3 allocs/op
BenchmarkInt0UgorjiGoMsgpack-2           3000000               586 ns/op               8 B/op          1 allocs/op
BenchmarkInt0UgorjiGoCodec-2             5000000               360 ns/op               0 B/op          0 allocs/op
BenchmarkTime-2                          5000000               353 ns/op               0 B/op          0 allocs/op
BenchmarkDuration-2                     10000000               180 ns/op               0 B/op          0 allocs/op
BenchmarkByteSlice-2                     1000000              1021 ns/op            1024 B/op          1 allocs/op
BenchmarkByteArray-2                      500000              2741 ns/op            2112 B/op          4 allocs/op
BenchmarkByteSliceUgorjiGoCodec-2        2000000               647 ns/op               0 B/op          0 allocs/op
BenchmarkByteArrayUgorjiGoCodec-2        1000000              2632 ns/op            1088 B/op          3 allocs/op
BenchmarkMapStringString-2               1000000              1898 ns/op              16 B/op          4 allocs/op
BenchmarkMapStringStringPtr-2             500000              2461 ns/op              32 B/op          5 allocs/op
BenchmarkMapStringStringUgorjiGoCodec-2  1000000              1737 ns/op              16 B/op          4 allocs/op
BenchmarkMapIntInt-2                      500000              3424 ns/op             208 B/op         10 allocs/op
BenchmarkStringSlice-2                   3000000               530 ns/op              10 B/op          2 allocs/op
BenchmarkStringSlicePtr-2                1000000              1270 ns/op              26 B/op          3 allocs/op
BenchmarkStructVmihailencoMsgpack-2       100000             12732 ns/op            3152 B/op         27 allocs/op
BenchmarkStructMarshal-2                  300000              6003 ns/op            1808 B/op          8 allocs/op
BenchmarkStructUnmarshal-2                200000              5788 ns/op            1344 B/op         19 allocs/op
BenchmarkStructManual-2                   200000              6610 ns/op            2720 B/op         21 allocs/op
BenchmarkStructUgorjiGoMsgpack-2          100000             17138 ns/op            3616 B/op         70 allocs/op
BenchmarkStructUgorjiGoCodec-2            100000             21833 ns/op            7345 B/op         23 allocs/op
BenchmarkStructJSON-2                      20000             63809 ns/op            7896 B/op         26 allocs/op
BenchmarkStructGOB-2                       20000             96275 ns/op           14664 B/op        278 allocs/op
BenchmarkStructUnmarshalPartially-2       300000              5791 ns/op            2272 B/op         12 allocs/op
BenchmarkCSV-2                            200000              6971 ns/op            8748 B/op         12 allocs/op
BenchmarkCSVMsgpack-2                    1000000              1541 ns/op             384 B/op         13 allocs/op
ok      gopkg.in/vmihailenco/msgpack.v2 58.623s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gopkg-in-vmihailenco-msgpack-v2-でgoのstructをエンコード-デコードするインターフェース&#34;&gt;gopkg.in/vmihailenco/msgpack.v2 でGoのstructをエンコード・デコードするインターフェース&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2#Marshaler&#34;&gt;Marshaler&lt;/a&gt; はdeprecatedで&lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2#CustomEncoder&#34;&gt;CustomEncoder&lt;/a&gt;を使えとのことです。&lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2#CustomEncoder&#34;&gt;CustomEncoder&lt;/a&gt; の Example を見ると使い方も簡単そうです。&lt;/p&gt;

&lt;h2 id=&#34;gopkg-in-vmihailenco-msgpack-v2-を使うことにします&#34;&gt;gopkg.in/vmihailenco/msgpack.v2 を使うことにします&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;github.com/vmihailenco/msgpack&lt;/a&gt;も&lt;a href=&#34;https://github.com/ugorji/go/tree/master/codec&#34;&gt;go/codec at master · ugorji/go&lt;/a&gt;も活発にメンテナンスされているようです。&lt;/p&gt;

&lt;p&gt;APIドキュメント &lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2&#34;&gt;gopkg.in/vmihailenco/msgpack.v2&lt;/a&gt;、&lt;a href=&#34;https://godoc.org/github.com/ugorji/go/codec&#34;&gt;github.com/ugorji/go/codec&lt;/a&gt; を見ると私は前者のほうがしっくりきました。ということで gopkg.in/vmihailenco/msgpack.v2 を使うことにします。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>