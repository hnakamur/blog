<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on hnakamur&#39;s blog at github</title>
    <link>/blog/post/</link>
    <description>Recent content in Posts on hnakamur&#39;s blog at github</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-JP</language>
    <lastBuildDate>Sat, 02 Jul 2016 23:46:34 +0900</lastBuildDate>
    <atom:link href="/blog/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>1台のサーバに異なる設定でApache Traffic Serverを複数立ち上げるためのビルド設定</title>
      <link>/blog/2016/07/02/config-for-multiple-installations-of-apache-traffic-server/</link>
      <pubDate>Sat, 02 Jul 2016 23:46:34 +0900</pubDate>
      
      <guid>/blog/2016/07/02/config-for-multiple-installations-of-apache-traffic-server/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;Apache Traffic Serverには&lt;a href=&#34;https://docs.trafficserver.apache.org/en/latest/admin-guide/configuration/hierachical-caching.en.html&#34;&gt;Hierarchical Caching&lt;/a&gt;という機能があって、キャッシュを親と子の2階層にすることが出来ます。&lt;/p&gt;

&lt;p&gt;CentOSで1つのサーバに親と子の2つのTraffic Server 6.1.1を異なる設定で起動するような構成にしたかったのですが、本家のrpmでは出来ないようでした。
ソースを見ていたらconfigureオプションをうまく指定すれば可能だとわかり、カスタムrpmを作りました。&lt;/p&gt;

&lt;p&gt;rpmのspecファイルは&lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec&#34;&gt;apache-traffic-server-rpm/trafficserver.spec&lt;/a&gt;、ビルドしたrpmは &lt;a href=&#34;https://copr.fedorainfracloud.org/coprs/hnakamur/apache-traffic-server-6/&#34;&gt;hnakamur/apache-traffic-server-6 Copr&lt;/a&gt; で公開しています。&lt;/p&gt;

&lt;h2 id=&#34;起動オプションではやりたいことは出来なさそうでした&#34;&gt;起動オプションではやりたいことは出来なさそうでした&lt;/h2&gt;

&lt;p&gt;カスタムrpmを作る前に、本家のrpmを使いつつコマンドラインオプションや環境変数の設定によってやりたいことが実現できないか調べてみたのですが、出来なさそうでした。&lt;/p&gt;

&lt;p&gt;バージョン6.1.1のソースを見た時のメモです。&lt;/p&gt;

&lt;p&gt;まず、 &lt;code&gt;traffic_server&lt;/code&gt; コマンドには &lt;code&gt;-conf_dir&lt;/code&gt; というオプションがあります。ソースは &lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/proxy/Main.cc#L206&#34;&gt;proxy/Main.cc&lt;/a&gt; です。&lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/appendices/command-line/traffic_server.en.html&#34;&gt;traffic_serverのドキュメント&lt;/a&gt;には記載がありません。&lt;/p&gt;

&lt;p&gt;一方、 &lt;code&gt;traffic_manager&lt;/code&gt; コマンドには &lt;code&gt;-tsArgs&lt;/code&gt; というオプションがあります。 ソースは &lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/cmd/traffic_manager/traffic_manager.cc#L453&#34;&gt;cmd/traffic_manager/traffic_manager.cc&lt;/a&gt; で &lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/appendices/command-line/traffic_manager.en.html#cmdoption-traffic_manager--tsArgs&#34;&gt;traffic_managerのドキュメント&lt;/a&gt; にも説明はありませんが載っています。&lt;/p&gt;

&lt;p&gt;しかし、 &lt;code&gt;traffic_cop&lt;/code&gt; コマンドが &lt;code&gt;traffic_manager&lt;/code&gt; コマンドを起動する際には &lt;code&gt;-tsArgs&lt;/code&gt; オプションは指定していません。ソースは &lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/cmd/traffic_cop/traffic_cop.cc#L758&#34;&gt;cmd/traffic_cop/traffic_cop.cc&lt;/a&gt; です。 &lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/appendices/command-line/traffic_cop.en.html&#34;&gt;traffic_cop&lt;/a&gt; のドキュメントを見ても traffic_manager にオプションを渡すためのオプションは無いようです。&lt;/p&gt;

&lt;p&gt;rpmでインストールされるサービス起動スクリプトだと &lt;code&gt;traffic_cop&lt;/code&gt; →　&lt;code&gt;traffic_manger&lt;/code&gt; →　&lt;code&gt;traffic_sever&lt;/code&gt; という呼び出し関係になるので、こ &lt;code&gt;traffic_server&lt;/code&gt;   に &lt;code&gt;-conf_dir&lt;/code&gt; オプションを渡すことは出来なさそうです。&lt;/p&gt;

&lt;h2 id=&#34;ts-rootという環境変数を発見&#34;&gt;TS_ROOTという環境変数を発見&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/lib/ts/Layout.cc#L146-L187&#34;&gt;lib/ts/Layout.cc&lt;/a&gt; で &lt;code&gt;TS_ROOT&lt;/code&gt; という環境変数を参照しているのを見つけました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Layout::Layout(const char *_prefix)
{
  if (_prefix) {
    prefix = ats_strdup(_prefix);
  } else {
    char *env_path;
    char path[PATH_NAME_MAX];
    int len;

    if ((env_path = getenv(&amp;quot;TS_ROOT&amp;quot;))) {
      len = strlen(env_path);
      if ((len + 1) &amp;gt; PATH_NAME_MAX) {
        ink_error(&amp;quot;TS_ROOT environment variable is too big: %d, max %d\n&amp;quot;, len, PATH_NAME_MAX - 1);
        return;
      }
      ink_strlcpy(path, env_path, sizeof(path));
      while (len &amp;gt; 1 &amp;amp;&amp;amp; path[len - 1] == &#39;/&#39;) {
        path[len - 1] = &#39;\0&#39;;
        --len;
      }
    } else {
      // Use compile time --prefix
      ink_strlcpy(path, TS_BUILD_PREFIX, sizeof(path));
    }

    prefix = ats_strdup(path);
  }
  exec_prefix = layout_relative(prefix, TS_BUILD_EXEC_PREFIX);
  bindir = layout_relative(prefix, TS_BUILD_BINDIR);
  sbindir = layout_relative(prefix, TS_BUILD_SBINDIR);
  sysconfdir = layout_relative(prefix, TS_BUILD_SYSCONFDIR);
  datadir = layout_relative(prefix, TS_BUILD_DATADIR);
  includedir = layout_relative(prefix, TS_BUILD_INCLUDEDIR);
  libdir = layout_relative(prefix, TS_BUILD_LIBDIR);
  libexecdir = layout_relative(prefix, TS_BUILD_LIBEXECDIR);
  localstatedir = layout_relative(prefix, TS_BUILD_LOCALSTATEDIR);
  runtimedir = layout_relative(prefix, TS_BUILD_RUNTIMEDIR);
  logdir = layout_relative(prefix, TS_BUILD_LOGDIR);
  mandir = layout_relative(prefix, TS_BUILD_MANDIR);
  infodir = layout_relative(prefix, TS_BUILD_INFODIR);
  cachedir = layout_relative(prefix, TS_BUILD_CACHEDIR);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/lib/ts/Layout.cc#L51-L70&#34;&gt;layout_relative関数の定義&lt;/a&gt; と &lt;a href=&#34;https://github.com/apache/trafficserver/blob/d6906e2a59858005d09018994262562b03ca24e9/lib/ts/ink_file.cc#L132-L323&#34;&gt;ink_filepath_merge関数の定義&lt;/a&gt; を見ると、 layout_relative の第2引数が &lt;code&gt;/&lt;/code&gt; で始まっていると第2引数がそのまま使われ、 &lt;code&gt;/&lt;/code&gt; で始まっていないと第1引数と第2引数を必要に応じて &lt;code&gt;/&lt;/code&gt; を挟んで連結した値になることがわかりました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;TS_BUILD_SYSCONFDIR&lt;/code&gt; などは&lt;a href=&#34;https://github.com/apache/trafficserver/blob/6.1.1/lib/ts/ink_config.h.in#L110-L125&#34;&gt;trafficserver/ink_config.h.in&lt;/a&gt; で定義されていました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* Various &amp;quot;build&amp;quot; defines */
#define TS_BUILD_PREFIX &amp;quot;@prefix@&amp;quot;
#define TS_BUILD_EXEC_PREFIX &amp;quot;@rel_exec_prefix@&amp;quot;
#define TS_BUILD_BINDIR &amp;quot;@rel_bindir@&amp;quot;
#define TS_BUILD_SBINDIR &amp;quot;@rel_sbindir@&amp;quot;
#define TS_BUILD_SYSCONFDIR &amp;quot;@rel_sysconfdir@&amp;quot;
#define TS_BUILD_DATADIR &amp;quot;@rel_datadir@&amp;quot;
#define TS_BUILD_INCLUDEDIR &amp;quot;@rel_includedir@&amp;quot;
#define TS_BUILD_LIBDIR &amp;quot;@rel_libdir@&amp;quot;
#define TS_BUILD_LIBEXECDIR &amp;quot;@rel_libexecdir@&amp;quot;
#define TS_BUILD_LOCALSTATEDIR &amp;quot;@rel_localstatedir@&amp;quot;
#define TS_BUILD_RUNTIMEDIR &amp;quot;@rel_runtimedir@&amp;quot;
#define TS_BUILD_LOGDIR &amp;quot;@rel_logdir@&amp;quot;
#define TS_BUILD_MANDIR &amp;quot;@rel_mandir@&amp;quot;
#define TS_BUILD_CACHEDIR &amp;quot;@rel_cachedir@&amp;quot;
#define TS_BUILD_INFODIR &amp;quot;@rel_infodir@&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;rel_*&lt;/code&gt; という値は &lt;code&gt;configure&lt;/code&gt; 実行時にbuild/common.m4の &lt;a href=&#34;https://github.com/apache/trafficserver/blob/5a0952b01d01ef927a65fc44bac5f68c345747aa/build/common.m4#L252-L263&#34;&gt;TS_SUBST_LAYOUT_PATH&lt;/a&gt; で設定されるようです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dnl
dnl TS_SUBST_LAYOUT_PATH
dnl Export (via TS_SUBST) the various path-related variables that
dnl trafficserver will use while generating scripts and
dnl the default config file.
AC_DEFUN([TS_SUBST_LAYOUT_PATH], [
  TS_EXPAND_VAR(exp_$1, [$]$1)
  TS_PATH_RELATIVE(rel_$1, [$]exp_$1, ${prefix})
  TS_SUBST(exp_$1)
  TS_SUBST(rel_$1)
  TS_SUBST($1)
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここから呼ばれる &lt;a href=&#34;https://github.com/apache/trafficserver/blob/5a0952b01d01ef927a65fc44bac5f68c345747aa/build/common.m4#L223-L241&#34;&gt;TS_PATH_RELATIVE&lt;/a&gt; で実際の値が作られます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dnl
dnl Removes the value of $3 from the string in $2, strips of any leading
dnl slashes, and returns the value in $1.
dnl
dnl Example:
dnl orig_path=&amp;quot;${prefix}/bar&amp;quot;
dnl TS_PATH_RELATIVE(final_path, $orig_path, $prefix)
dnl    $final_path now contains &amp;quot;bar&amp;quot;
AC_DEFUN([TS_PATH_RELATIVE], [
ats_stripped=`echo $2 | sed -e &amp;quot;s#^$3##&amp;quot;`
# check if the stripping was successful
if test &amp;quot;x$2&amp;quot; != &amp;quot;x${ats_stripped}&amp;quot;; then
# it was, so strip of any leading slashes
    $1=&amp;quot;`echo ${ats_stripped} | sed -e &#39;s#^/*##&#39;`&amp;quot;
else
# it wasn&#39;t so return the original
    $1=&amp;quot;$2&amp;quot;
fi
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで、例えば &lt;code&gt;sysconfdir&lt;/code&gt; の値が &lt;code&gt;prefix&lt;/code&gt; の値で始まっていれば &lt;code&gt;rel_sysconfdir&lt;/code&gt; は &lt;code&gt;prefix&lt;/code&gt; からの相対パスになり、そうでなければ &lt;code&gt;sysconfdir&lt;/code&gt; そのままになるということがわかりました。&lt;/p&gt;

&lt;h2 id=&#34;configureオプションの指定方法&#34;&gt;configureオプションの指定方法&lt;/h2&gt;

&lt;p&gt;上記を踏まえて、私が作成した &lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec&#34;&gt;/trafficserver.spec&lt;/a&gt; では &lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec#L1&#34;&gt;1行目&lt;/a&gt;で&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%define _prefix /opt/trafficserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と設定し、 &lt;a href=&#34;https://github.com/hnakamur/apache-traffic-server-rpm/blob/d1688aec09f6761841bbc638938577cae49beccd/SPECS/trafficserver.spec#L85-L94&#34;&gt;85〜94行目&lt;/a&gt; で以下のような configure オプションを指定しています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%configure \
  --enable-layout=opt \
  --sysconfdir=%{_prefix}%{_sysconfdir} \
  --localstatedir=%{_prefix}%{_localstatedir} \
  --libexecdir=%{_prefix}/%{_lib}/plugins \
  --with-tcl=/usr/%{_lib} \
  --enable-luajit \
  --with-user=ats --with-group=ats \
  --disable-silent-rules \
  --enable-experimental-plugins
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでビルドしたtrafficserverを実行する際に、環境変数TS_ROOTを設定することで以下のようなディレクトリを参照することが出来ました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sysconfdir: ${TS_ROOT}/etc&lt;/li&gt;
&lt;li&gt;localstatedir: ${TS_ROOT}/var/run&lt;/li&gt;
&lt;li&gt;libexecdir: ${TS_ROOT}/lib64/plugins&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;私が使っているディレクトリ構成&#34;&gt;私が使っているディレクトリ構成&lt;/h2&gt;

&lt;p&gt;実際には以下のようなシンボリックリンクを貼って使っています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1段目

&lt;ul&gt;
&lt;li&gt;/opt/trafficserver-first/etc -&amp;gt; /etc/trafficserver-first&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/bin -&amp;gt; /opt/trafficserver/bin&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/lib64 -&amp;gt; /opt/trafficserver/lib64&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/var/cache -&amp;gt; /var/cache/trafficserver-first&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/var/logs -&amp;gt; /var/log/trafficserver-first&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-first/var/run -&amp;gt; /var/run/trafficserver-first&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2段目

&lt;ul&gt;
&lt;li&gt;/opt/trafficserver-second/etc -&amp;gt; /etc/trafficserver-second&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/bin -&amp;gt; /opt/trafficserver/bin&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/lib64 -&amp;gt; /opt/trafficserver/lib64&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/var/cache -&amp;gt; /var/cache/trafficserver-second&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/var/logs -&amp;gt; /var/log/trafficserver-second&lt;/li&gt;
&lt;li&gt;/opt/trafficserver-second/var/run -&amp;gt; /var/run/trafficserver-second&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;コマンド実行時の環境変数指定&#34;&gt;コマンド実行時の環境変数指定&lt;/h2&gt;

&lt;p&gt;コマンドを実行するときはPATHを通すかフルパスで指定するだけではなく、 TS_ROOT 環境変数も指定する必要があります。&lt;/p&gt;

&lt;p&gt;例えば、1段目のキャッシュを全クリアするときは &lt;a href=&#34;https://docs.trafficserver.apache.org/en/6.1.x/admin-guide/storage/index.en.html#clearing-the-cache&#34;&gt;Clearing the Cache&lt;/a&gt; の説明では &lt;code&gt;traffic_server -Cclear&lt;/code&gt; ですが、このrpmの場合は&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TS_ROOT=/opt/trafficserver-first /opt/trafficserver-first/bin/traffic_server -Cclear
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と実行する必要があります。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>lxd_containerというAnsibleモジュールを書いたときに学んだtips</title>
      <link>/blog/2016/07/01/tips_for_writing_ansible_module/</link>
      <pubDate>Fri, 01 Jul 2016 22:44:12 +0900</pubDate>
      
      <guid>/blog/2016/07/01/tips_for_writing_ansible_module/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;lxd_containerというAnsibleのモジュールを書いたときに学んだtipsのメモです。&lt;/p&gt;

&lt;h2 id=&#34;モジュールでデバッグ出力は出来ないのでデバッグ情報は戻り値のjsonに入れる&#34;&gt;モジュールでデバッグ出力は出来ないのでデバッグ情報は戻り値のJSONに入れる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://groups.google.com/d/msg/ansible-devel/s0iSb7phnqY/UB9vaLFJAwAJ&#34;&gt;ansible-dev MLでの投稿&lt;/a&gt;によるとモジュールは何も出力できないとのことなので、デバッグ情報は戻り値のJSONに入れる必要があります。&lt;/p&gt;

&lt;p&gt;Ansible 2.1からはAnsibleModuleクラスでは &lt;code&gt;_verbosity&lt;/code&gt;、それ以外では &lt;code&gt;_ansible_verbosity&lt;/code&gt; で &lt;code&gt;-v&lt;/code&gt;, &lt;code&gt;-vv&lt;/code&gt;, &lt;code&gt;-vvv&lt;/code&gt;, &lt;code&gt;-vvvv&lt;/code&gt; を指定した場合の &lt;code&gt;v&lt;/code&gt; の個数が取得できるので、それに応じて戻り値のJSONにデバッグ情報を含めるかどうか制御することが出来ます。値は &lt;code&gt;-v&lt;/code&gt; を指定しない場合は 0 で、 &lt;code&gt;-vvvv&lt;/code&gt; だと4という感じです。&lt;/p&gt;

&lt;h2 id=&#34;コードフォーマットのチェック&#34;&gt;コードフォーマットのチェック&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ansible/ansible-modules-extras/pull/2208#discussion_r62996064&#34;&gt;Ansibleのコミッタの方からのコメント&lt;/a&gt; で &lt;code&gt;pep8&lt;/code&gt; というツールでコードフォーマットのチェックを行っているということを知りました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pep8 -r --ignore=E501,E221,W291,W391,E302,E251,E203,W293,E231,E303,E201,E225,E261,E241,E402 *.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;という感じで使います。 pep8はUbuntu 16.04 では &lt;code&gt;sudo apt install pep8&lt;/code&gt; でインストールできました。&lt;/p&gt;

&lt;h2 id=&#34;ansibleモジュールのチェック&#34;&gt;Ansibleモジュールのチェック&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ansible/ansible-modules-extras&#34;&gt;ansible/ansible-modules-extras&lt;/a&gt; にプルリクエストを送ると Travis CI でチェックが走るのですが、そのチェックの1つで &lt;code&gt;ansible-validate-modules&lt;/code&gt; というコマンドが使われていました。&lt;/p&gt;

&lt;p&gt;いろいろチェックしているようなのですが、例えばモジュール内にYAMLで書いたドキュメントの書式が間違っていると &lt;code&gt;ansible-validate-modules&lt;/code&gt; エラーになりました。コミットをプッシュしてからエラーになると面倒なのでローカルで先にチェックしておくのが良いです。&lt;/p&gt;

&lt;p&gt;私はPythonのvirtualenv環境内で &lt;code&gt;pip install ansible-testing&lt;/code&gt; でインストールしました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ansible-validate-modules 対象ディレクトリ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でチェックできます。&lt;/p&gt;

&lt;h2 id=&#34;サードパーティのrequestsを使うとansible-module-utils-urlsを使うべきというエラーが出る&#34;&gt;サードパーティのrequestsを使うとansible.module_utils.urlsを使うべきというエラーが出る&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.python-requests.org/en/master/&#34;&gt;Requests: HTTP for Humans&lt;/a&gt;を使っているとansible-validate-modulesが &lt;code&gt;ansible.module_utils.urls&lt;/code&gt; を使うべきという&lt;a href=&#34;https://github.com/ansible/ansible-modules-extras/pull/2208#issuecomment-228027653&#34;&gt;エラーを出してきます&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;今回書いたlxd_containerモジュールは&lt;a href=&#34;https://github.com/lxc/lxd/blob/master/doc/rest-api.md&#34;&gt;LXD REST API&lt;/a&gt;を使うのですが (1) Unixドメインソケットでの通信、(2) クライアント証明書を使ったhttps通信の2つが必要です。が &lt;code&gt;ansible.module_utils.urls&lt;/code&gt; での実現方法がわからなかったので、今回はPython2標準ライブラリのhttplibを使って実装しました。&lt;/p&gt;

&lt;p&gt;サードパーティのライブラリを使わず標準ライブラリを使うことで、lxd_containerモジュールを使うときに依存するライブラリを入れる手間が発生しないので結果的には良かったと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>分散SQLデータベースCockroachDBのキーバリューストレージのデバッグコマンドを試してみた</title>
      <link>/blog/2016/06/30/experiment-cockroachdb-key-value-store/</link>
      <pubDate>Thu, 30 Jun 2016 06:40:12 +0900</pubDate>
      
      <guid>/blog/2016/06/30/experiment-cockroachdb-key-value-store/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;h/blog/2016/06/20/lsm-tree-and-rocksdb/&#34;&gt;LSM-TreeとRocksDB、TiDB、CockroachDBが気になる&lt;/a&gt; で紹介した &lt;a href=&#34;https://github.com/cockroachdb/cockroach#client-drivers&#34;&gt;CockroachDB&lt;/a&gt; は &lt;a href=&#34;https://github.com/cockroachdb/cockroach#what-is-cockroachdb&#34;&gt;What is CockroachDB?&lt;/a&gt; によるとスケールアウトできる分散SQLデータベースです。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach#client-drivers&#34;&gt;PostgreSQLのワイヤープロトコルをサポート&lt;/a&gt; していて、 &lt;a href=&#34;https://github.com/cockroachdb/cockroach#quickstart&#34;&gt;Quickstart&lt;/a&gt; の例のようにPostgreSQLで扱えるSQLのサブセットが使えます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach#overview&#34;&gt;Overview&lt;/a&gt; によるとストレージには &lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt; を使用し、複数台のサーバ間の合意アルゴリズムにはRaftを使用しています。&lt;/p&gt;

&lt;p&gt;分散SQLデータベースという本来の機能も魅力的なのですが、書き込みが多いケースに最適化したLSM Treeというデータ構造の実装であるRocksDBをRaftを使って分散トランザクションを実現しているという部分も個人的には興味があります。&lt;/p&gt;

&lt;p&gt;ということで、そのへんのソースを見ていこうと思います。といっても、まだ全体を把握しているわけではないので、だらだら書いていきます。
CockroachDBにデバッグ用のコマンドが用意されていたので、それで実験しつつ読み進めたいと思います。&lt;/p&gt;

&lt;h2 id=&#34;rocksdbラッパーレイヤとengineパッケージ&#34;&gt;RocksDBラッパーレイヤとengineパッケージ&lt;/h2&gt;

&lt;p&gt;RocksDBはC++で書かれているので、Goから呼び出すためcgoでラッピングしているレイヤがあります。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach/tree/master/storage/engine/rocksdb&#34;&gt;cockroach/storage/engine/rocksdb&lt;/a&gt; にC++で書かれたファイルがいくつかあります。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach/tree/master/storage/engine&#34;&gt;cockroach/storage/engine&lt;/a&gt; パッケージのドキュメント &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine&#34;&gt;engine - GoDoc&lt;/a&gt; にこのパッケージで低レベルのストレージを提供しているという説明があります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#Engine&#34;&gt;Engine&lt;/a&gt; はRocksDBなどのストレージバックエンドとやり取りするためのインターフェースです。 Engineは &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#ReadWriter&#34;&gt;ReadWriter&lt;/a&gt; インタフェースをエンベッドしていて、それがさらに &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#Reader&#34;&gt;Reader&lt;/a&gt; と &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#Writer&#34;&gt;Writer&lt;/a&gt; インタフェースをエンベッドしています。&lt;/p&gt;

&lt;p&gt;Reader や Writer インタフェースのメソッドを見るとキーバリューストアのキーは &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#MVCCKey&#34;&gt;MVCCKey&lt;/a&gt; という型になっています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type MVCCKey struct {
    Key       roachpb.Key
    Timestamp hlc.Timestamp
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/roachpb#Key&#34;&gt;roachpb.Key&lt;/a&gt; は &lt;code&gt;[]byte&lt;/code&gt; と定義されており、 &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/util/hlc#Timestamp&#34;&gt;hlc.Timestamp&lt;/a&gt; は以下のように定義されています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Timestamp struct {
    // Holds a wall time, typically a unix epoch time
    // expressed in nanoseconds.
    WallTime int64 `protobuf:&amp;quot;varint,1,opt,name=wall_time,json=wallTime&amp;quot; json:&amp;quot;wall_time&amp;quot;`
    // The logical component captures causality for events whose wall
    // times are equal. It is effectively bounded by (maximum clock
    // skew)/(minimal ns between events) and nearly impossible to
    // overflow.
    Logical int32 `protobuf:&amp;quot;varint,2,opt,name=logical&amp;quot; json:&amp;quot;logical&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine&#34;&gt;engine - GoDoc&lt;/a&gt; にEngineインタフェースの上にMVCC (Multi-Version Concurrency Control) システムが提供されていて、それがCockroachDBが分散トランザクションをサポートするための基礎になっていると書かれています。&lt;/p&gt;

&lt;p&gt;その下の &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#hdr-Notes_on_MVCC_architecture&#34;&gt;Notes on MVCC architecture&lt;/a&gt; にMVCCアーキテクチャについて詳細な説明があります。じっくり読んだほうが良いと思いますが、一旦飛ばして先に進みます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#RocksDB&#34;&gt;RocksDB&lt;/a&gt; という構造体定義があり、これが Engine インタフェースを実装しています。  &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/storage/engine#NewRocksDB&#34;&gt;NewRocksDB&lt;/a&gt; 関数で RocksDB を作成できます。&lt;/p&gt;

&lt;h2 id=&#34;newrocksdb関数の呼び出し箇所&#34;&gt;NewRocksDB関数の呼び出し箇所&lt;/h2&gt;

&lt;p&gt;NewRocksDB関数は、テストコード以外では、以下の2箇所で呼ばれていました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/server&#34;&gt;server&lt;/a&gt; パッケージの &lt;a href=&#34;https://godoc.org/github.com/cockroachdb/cockroach/server#Context.InitStores&#34;&gt;func (*Context) InitStores&lt;/a&gt;。

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/549d9b575e06921fa96b6ff4881ea348d8b6d00c/server/context.go#L260-L261&#34;&gt;cockroach/context.go at 549d9b575e06921fa96b6ff4881ea348d8b6d00c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/cli/debug.go&#34;&gt;cockroach/debug.go&lt;/a&gt; の &lt;code&gt;cli.openStore(cmd *cobra.Command, dir string, stopper *stop.Stopper) (engine.Engine, error)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/549d9b575e06921fa96b6ff4881ea348d8b6d00c/cli/debug.go#L65-L71&#34;&gt;cockroach/debug.go at 549d9b575e06921fa96b6ff4881ea348d8b6d00c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;後者を呼び出している箇所を見ていくとデバッグ用のサブコマンドがあることがわかりました。&lt;/p&gt;

&lt;h2 id=&#34;デバッグ用サブコマンドを試してみた&#34;&gt;デバッグ用サブコマンドを試してみた&lt;/h2&gt;

&lt;p&gt;前提条件としてLXDの3つのコンテナroach1, roach2, roach3で以下のようにCockroachDBを起動している状態とします。&lt;/p&gt;

&lt;p&gt;roach1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/sbin/cockroach start --host 192.168.0.13 --insecure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;roach2&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/sbin/cockroach start --join 192.168.0.13:26257 --insecure --host 192.168.0.14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;roach3&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/sbin/cockroach start --join 192.168.0.13:26257 --insecure --host 192.168.0.15
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特にコンテナでなくても1台のサーバで &lt;a href=&#34;https://github.com/cockroachdb/cockroach#quickstart&#34;&gt;Quickstart&lt;/a&gt;のlocal clusterでも構いません。その場合は下記のコマンドの &lt;code&gt;--host&lt;/code&gt; の部分を適宜読み替えてください。&lt;/p&gt;

&lt;h3 id=&#34;debug-kv-コマンドを試してみた&#34;&gt;debug kv コマンドを試してみた&lt;/h3&gt;

&lt;p&gt;debug kvコマンドで、キー・バリュー・ストアに値を設定したり取得したり出来ます。&lt;/p&gt;

&lt;p&gt;コンテナroach1で値をセットして取得してみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach1:~# cockroach debug kv scan --host 192.168.0.13
0 result(s)
root@roach1:~# cockroach debug kv put --host 192.168.0.13 foo bar
root@roach1:~# cockroach debug kv get --host 192.168.0.13 foo
&amp;quot;bar&amp;quot;
root@roach1:~# cockroach debug kv scan --host 192.168.0.13
&amp;quot;foo&amp;quot;   &amp;quot;bar&amp;quot;
1 result(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記で設定した値がコンテナroach2でも取得できました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug kv scan --host 192.168.0.14
&amp;quot;foo&amp;quot;   &amp;quot;bar&amp;quot;
1 result(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナroach2からroach1上の値を変更も出来ます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug kv put --host 192.168.0.13 foo &#39;Hello, key value store in CockroachDB&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナroach1上の値一覧を取得して更新されていることを確認しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach1:~# cockroach debug kv scan --host 192.168.0.13
&amp;quot;foo&amp;quot;   &amp;quot;Hello, key value store in CockroachDB&amp;quot;
1 result(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;debug-keys-コマンドを試してみた&#34;&gt;debug keys コマンドを試してみた&lt;/h3&gt;

&lt;p&gt;debug keysコマンドで、キー・バリュー・ストアの内部構造をダンプして見ることが出来ます。このコマンドはサーバを停止した状態でデータのディレクトリを指定して実行するようになっています。&lt;/p&gt;

&lt;p&gt;サーバが起動したまま実行すると以下のようにロックが取得できないというエラーになります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug keys ./cockroach-data
Error: storage/engine/rocksdb.go:158: could not open rocksdb instance: IO error: lock ./cockroach-data/LOCK: Resource temporarily unavailable
Usage:
  cockroach debug keys [directory] [flags]

Flags:
      --from string
        Start key in pretty-printed format. See also --raw.

      --raw
        Interpret keys as raw bytes.

      --to string
        Exclusive end key in pretty-printed format. See also --raw.

      --values
        Print values along with their associated key.

Global Flags:
      --alsologtostderr value[=INFO]   logs at or above this threshold go to stderr (default NONE)
      --log-backtrace-at value         when logging hits line file:N, emit a stack trace (default :0)
      --log-dir value                  if non-empty, write log files in this directory
      --logtostderr                    log to standard error instead of files
      --no-color value                 disable standard error log colorization
      --verbosity value                log level for V logs
      --vmodule value                  comma-separated list of pattern=N settings for file-filtered logging

Failed running &amp;quot;debug&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこでコンテナroach2のサーバを停止してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach quit --host 192.168.0.14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サーバを停止したらキーの一覧を表示してみます。以下の例では &lt;code&gt;foo&lt;/code&gt; の前後5行を表示しています。
fooという文字列の後にタイムスタンプがついているのがわかります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@roach2:~# cockroach debug keys ./cockroach-data | grep -A 5 -B 5 foo
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466351519.447511853,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466265107.436191749,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466265097.406397710,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466178687.396782782,0&amp;quot;
&amp;quot;/System/\&amp;quot;update-cluster\&amp;quot;/1466178677.619687555,85&amp;quot;
&amp;quot;\&amp;quot;foo\&amp;quot;/1467234744.564568969,0&amp;quot;
&amp;quot;\&amp;quot;foo\&amp;quot;/1467221373.376922221,0&amp;quot;
&amp;quot;/Table/2/1/0/\&amp;quot;bank\&amp;quot;/3/1/1466178749.722011447,0&amp;quot;
&amp;quot;/Table/2/1/0/\&amp;quot;system\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&amp;quot;/Table/2/1/1/\&amp;quot;descriptor\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&amp;quot;/Table/2/1/1/\&amp;quot;eventlog\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&amp;quot;/Table/2/1/1/\&amp;quot;lease\&amp;quot;/3/1/1466178677.367397368,0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--values&lt;/code&gt; オプションも追加すると、キーだけではなく値も表示されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cockroach debug keys --values cockroach-data/ | less
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;を実行して、 &lt;code&gt;foo&lt;/code&gt; のキーに対応する部分を見てみると以下のようになっていました。横に長過ぎるので折り返して表示しています。&lt;/p&gt;

&lt;p&gt;/Local/RangeID/21/u/RaftLog/logIndex:104861: Type:EntryNormal Term:51415 Index:104861  by {2 2 2}
  Put [&amp;ldquo;foo&amp;rdquo;,/Min)
  range_id:21 origin_replica:&lt;node_id:2 store_id:2 replica_id:2 &gt; cmd:&lt;header:&lt;timestamp:&lt;wall_time:1467234744564568969 logical:0 &gt; replica:&lt;node_id:2 store_id:2 replica_id:2 &gt; range_id:21 user_priority:NORMAL read_consistency:CONSISTENT trace:&lt;trace_id:4947902158296355776 span_id:7041358067641207168 &gt; max_scan_results:0 distinct_spans:false &amp;gt; requests:&lt;put:&lt;header:&lt;key:&#34;foo&#34; &gt; value:&lt;raw_bytes:&#34;s|S\306\003Hello, key value store in CockroachDB&#34; timestamp:&lt;wall_time:0 logical:0 &gt; &amp;gt; inline:false blind:false &amp;gt; &amp;gt; &amp;gt; max_lease_index:990&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;CockroachDBのキーバリューストレージのデバッグコマンドを試してみました。対応するソースコードも読んでみたいところですが、
&lt;a href=&#34;https://www.arangodb.com/2016/06/arangodb-3-0-a-solid-ground-to-scale/&#34;&gt;ArangoDB 3.0 – A Solid Ground to Scale – ArangoDB&lt;/a&gt;
というニュースを知ったので、今後はArangoDBのほうを先に調べたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>連番ファイル名の命名規則について実験してみた</title>
      <link>/blog/2016/06/22/experimented_with_naming_for_many_sequential_numbered_files/</link>
      <pubDate>Wed, 22 Jun 2016 23:40:27 +0900</pubDate>
      
      <guid>/blog/2016/06/22/experimented_with_naming_for_many_sequential_numbered_files/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;0〜1,000,000といった連番のファイルを作るときに、1つのディレクトリに全てのファイルを入れると、遅くなるとか取り扱いが面倒になるという懸念があります。&lt;/p&gt;

&lt;p&gt;そこで、ディレクトリを切って分割するのですが、数が少ない場合でも多い場合でも良さそうな方法を思いついたのでメモです。&lt;/p&gt;

&lt;h2 id=&#34;素朴な案&#34;&gt;素朴な案&lt;/h2&gt;

&lt;p&gt;最初に思いついたのは以下のような命名規則です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0/000/000
0/000/001
...
0/000/999
0/001/000
0/001/001
...
0/001/999
0/002/000
...
0/999/999
1/000/000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この方式には2つの欠点があります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイルを1つしか作らない場合でも、ディレクトリが必要になる。&lt;/li&gt;
&lt;li&gt;ゼロパディングする際にファイルの最大数を考えて桁数を決めておく必要がある。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;改善案&#34;&gt;改善案&lt;/h2&gt;

&lt;p&gt;上記の2つの欠点を解消する案を思いつきました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.b
1.b
...
999.b
1/000.b
1/001.b
...
1/999.b
2/000.b
...
999/999.b
1/000/000.b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイル名とディレクトリ名が衝突しないようにするため、ファイル名に拡張子を付ける必要があります。&lt;/p&gt;

&lt;p&gt;この方式には以下の利点があります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ファイル数が1000個以下ならディレクトリを作る必要が無い&lt;/li&gt;
&lt;li&gt;1つのディレクトリ直下にはファイルが最大1000、ディレクトリが最大1000で最大でも合計2000エントリで済む&lt;/li&gt;
&lt;li&gt;ファイルの最大数を事前に決めなくても、パスの長さ制限の範囲内であればこの命名規則でどんどん深いディレクトリを作ってファイルを格納できる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サンプルコード&#34;&gt;サンプルコード&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/many_files_experiment&#34;&gt;hnakamur/many_files_experiment&lt;/a&gt; におきました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LSM-TreeとRocksDB、TiDB、CockroachDBが気になる</title>
      <link>/blog/2016/06/20/lsm-tree-and-rocksdb/</link>
      <pubDate>Mon, 20 Jun 2016 22:23:54 +0900</pubDate>
      
      <guid>/blog/2016/06/20/lsm-tree-and-rocksdb/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;キーバリューストアについて調べていたらLSM-Treeというデータ構造とRocksDBが気になったということで調査メモです。ただし、それぞれの技術詳細を調査したり自分で検証してみたというメモではないです。&lt;/p&gt;

&lt;p&gt;そうではなく、いろんな記事で言及されていたり、ソフトウェアで採用されているのが気になったというだけの浅いメモです。が、脳内バッファからあふれる量になったので自分用に軽くまとめ。&lt;/p&gt;

&lt;h2 id=&#34;lsm-tree&#34;&gt;LSM Tree&lt;/h2&gt;

&lt;p&gt;Log-structured merge-treeを略してLSM Treeと呼ぶそうです。概要は&lt;a href=&#34;https://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;Log-structured merge-tree - Wikipedia&lt;/a&gt;を参照してください。&lt;/p&gt;

&lt;p&gt;CockroachDBのデザインドキュメントの&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/docs/design.md#read-vs-write-optimization-spectrum&#34;&gt;Read vs. Write Optimization Spectrum&lt;/a&gt;によると、B+ Treeというデータ構造は書き込みより読み取りが多いケースに最適化されているが、LSM Treeのほうは書き込みが多いケースに最適化されているそうです。&lt;/p&gt;

&lt;p&gt;一方、LSM Treeのほうはディスク使用量は肥大化しがちで定期的にコンパクションする必要があって、コンパクションには負荷がかかるので、この方式を各実装で工夫しているという話を何処かで読んだんですがリンクを紛失してしまいました。&lt;/p&gt;

&lt;h2 id=&#34;influxdbの事例&#34;&gt;InfluxDBの事例&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.13/concepts/storage_engine/&#34;&gt;InfluxData | Documentation | Storage Engine&lt;/a&gt;によるとInfluxDBのストレージエンジンは以下の変遷を辿ったそうです。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;LSM Treeの実装の1つである&lt;a href=&#34;https://github.com/google/leveldb&#34;&gt;LevelDB&lt;/a&gt;を採用&lt;/li&gt;
&lt;li&gt;B+Treeの実装の1つである&lt;a href=&#34;https://github.com/boltdb/bolt&#34;&gt;BoltDB&lt;/a&gt;を採用&lt;/li&gt;
&lt;li&gt;LSM Treeに似た独自のデータ構造でストレージエンジンを自作&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;tidbの事例&#34;&gt;TiDBの事例&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/pingcap/tidb&#34;&gt;pingcap/tidb: TiDB is a distributed NewSQL database compatible with MySQL protocol&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TiDB自体はGoで書かれている。&lt;/li&gt;
&lt;li&gt;MySQLのプロトコルを解釈できる。&lt;/li&gt;
&lt;li&gt;MySQLで使用できるSQLのサブセットを実装している。&lt;/li&gt;
&lt;li&gt;TiDBはRustで書かれRaftアルゴリズムを使った分散トランザクション対応のキーバリューデータベース &lt;a href=&#34;https://github.com/pingcap/tikv&#34;&gt;TiKV&lt;/a&gt;を使っている。

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/tidb#what-is-tidb&#34;&gt;What is TiDB?&lt;/a&gt;にはGolevelDB, LevelDB, RocksDB, LMDB, BoltDBに対応しているとあるのですが、TiDBの開発者のLi Shenさんによるとgoleveldbはローカルストレージとしてのみ利用可能で、分散環境ではTiKVを使っているそうです。&lt;/li&gt;
&lt;li&gt;TiKVのストレージエンジンはLSM Treeの実装である&lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;を採用。Li ShenさんによるとTiDBの開発チームはRocsDBのチームとも連絡をとっているそうです。&lt;/li&gt;
&lt;li&gt;TiKV用の&lt;a href=&#34;https://github.com/pingcap/tidb/blob/master/store/tikv/txn.go&#34;&gt;Goのクライアント&lt;/a&gt;もある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;現在バリバリ開発中。&lt;a href=&#34;https://github.com/pingcap/tidb/blob/master/docs/ROADMAP.md&#34;&gt;ロードマップ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TiDBの紹介記事: &lt;a href=&#34;https://www.infiniteloop.co.jp/blog/2016/05/install-tidb/&#34;&gt;MySQL は分散DBの夢を見るか、Google F1 論文を実装した TiDB を使ってみた | 株式会社インフィニットループ技術ブログ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TiDBの起源についてのブログ記事。&lt;a href=&#34;http://0xffff.me/thoughts-behind-tidb-part-1/&#34;&gt;Thoughts behind TiDB - Part I&lt;/a&gt;。私は中国語読めないのでGoogle翻訳で英語にして読みました。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cockroachdbの事例&#34;&gt;CockroachDBの事例&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach&#34;&gt;cockroachdb/cockroach: A Scalable, Survivable, Strongly-Consistent SQL Database&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;名前の由来: &lt;a href=&#34;https://github.com/cockroachdb/cockroach/wiki#why-the-name-cockroach&#34;&gt;Why the name Cockroach?&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CoackroachDBはGoで書かれている。&lt;/li&gt;
&lt;li&gt;PostgreSQLのプロトコルを解釈できる。&lt;/li&gt;
&lt;li&gt;PostgreSQLで使用できるSQLのサブセットを実装している。&lt;/li&gt;
&lt;li&gt;ストレージエンジンは&lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;を採用。&lt;/li&gt;
&lt;li&gt;現在バリバリ開発中。

&lt;ul&gt;
&lt;li&gt;バージョン1.0に向けてベータ版を頻繁に出している。 &lt;a href=&#34;https://github.com/cockroachdb/cockroach/releases&#34;&gt;Releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/wiki&#34;&gt;ロードマップ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;デザインドキュメント &lt;a href=&#34;https://github.com/cockroachdb/cockroach#design&#34;&gt;Design overview&lt;/a&gt;, &lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/docs/design.md&#34;&gt;full design doc&lt;/a&gt;と&lt;a href=&#34;https://www.cockroachlabs.com/docs/frequently-asked-questions.html&#34;&gt;Frequently Asked Questions&lt;/a&gt;がとても充実しています

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cockroachdb/cockroach/blob/master/docs/design.md#lock-free-distributed-transactions&#34;&gt;Lock-Free Distributed Transactions&lt;/a&gt;にCockroachDBの分散トランザクションの設計について解説があります。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lsm-treeの実装はいろいろあるがrocksdbが良いらしい&#34;&gt;LSM Treeの実装はいろいろあるがRocksDBが良いらしい&lt;/h2&gt;

&lt;p&gt;InfluxDBの開発元influxdataのブログのベンチマーク記事 &lt;a href=&#34;https://influxdata.com/blog/benchmarking-leveldb-vs-rocksdb-vs-hyperleveldb-vs-lmdb-performance-for-influxdb/&#34;&gt;Benchmarking LevelDB vs. RocksDB vs. HyperLevelDB vs. LMDB Performance for InfluxDB | InfluxData&lt;/a&gt;でも値の書き込みとクエリ実行の性能が良いのはRocksDBとなっています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://smalldatum.blogspot.jp/2015/04/comparing-leveldb-and-rocksdb-take-2.html&#34;&gt;Small Datum: Comparing LevelDB and RocksDB, take 2&lt;/a&gt;にRocksDBとLevelDBのベンチマークがありますが、RocksDBのほうが良い感じです。&lt;/p&gt;

&lt;p&gt;上記の通りTiDBでもCockroachDBでもRocksDBを採用していますし、現在のところ有望そうです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://rocksdb.blogspot.jp/2013/11/the-history-of-rocksdb.html&#34;&gt;Rocksdb: The History of RocksDB&lt;/a&gt;にRocksDBを開始した頃の話が書かれていました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/facebook/rocksdb/wiki/RocksDB-FAQ&#34;&gt;RocksDB FAQ&lt;/a&gt;の &amp;ldquo;Q: What&amp;rsquo;s the maximum key and value sizes supported?&amp;rdquo; によると、RocksDBは大きなサイズのキー用にはデザインされておらず、推奨されるキーと値の最大サイズはそれぞれ8MBと3GBとのことです。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;書き込みが多いケースに向いているキーバリューストアであるRocksDBと、RocksDBをつかて分散トランザクションを実現しているデータベースであるTiDBとCockroachDBの今後に注目したいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>sleuthというGoのライブラリでサービスディスカバリを試してみた</title>
      <link>/blog/2016/06/15/tried-service-discovery-with-sleuth/</link>
      <pubDate>Wed, 15 Jun 2016 06:56:10 +0900</pubDate>
      
      <guid>/blog/2016/06/15/tried-service-discovery-with-sleuth/</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://darian.af/post/master-less-peer-to-peer-micro-service-autodiscovery-in-golang-with-sleuth/&#34;&gt;Service autodiscovery in Go with sleuth - darian.af&lt;/a&gt;という記事を見かけて試してみたのでメモです。&lt;/p&gt;

&lt;h2 id=&#34;github-com-ursiform-sleuthのセットアップ&#34;&gt;github.com/ursiform/sleuthのセットアップ&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ursiform/sleuth#installation&#34;&gt;Installation&lt;/a&gt;を見ながらセットアップします。&lt;/p&gt;

&lt;p&gt;いきなりgo getでインストールしてみるとZeroMQ version 4が必要というエラーメッセージが出ました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/ursiform/sleuth
# github.com/pebbe/zmq4
In file included from ../../../pebbe/zmq4/ctxoptions_unix.go:7:0:
zmq4.h:2:2: error: #error &amp;quot;You need ZeroMQ version 4 to build this&amp;quot;
 #error &amp;quot;You need ZeroMQ version 4 to build this&amp;quot;
  ^
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ubuntu 16.04では&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install -y libzmq3-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS 7では&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo yum install -y zeromq-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でZeroMQ 4.xのライブラリとヘッダファイルがインストールできます。&lt;/p&gt;

&lt;p&gt;このあとで go get でsleuthをインストールすると今度は大丈夫でした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get -u github.com/ursiform/sleuth
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動作確認のためエコーバックのサービスの例を試す&#34;&gt;動作確認のためエコーバックのサービスの例を試す&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ursiform/sleuth#examples&#34;&gt;Examples&lt;/a&gt;のExample (1)にエコーバックのサーバとクライアントがあるのでそれを試します。&lt;/p&gt;

&lt;p&gt;コードをコピペするのが面倒な人は&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get -d github.com/hnakamur/sleuth-echo-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;で取得できます。&lt;/p&gt;

&lt;p&gt;以下のコマンドでプロジェクトのディレクトリに移動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd $GOPATH/src/github.com/hnakamur/sleuth-echo-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のコマンドでエコーバックのサーバを起動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(cd echo-server &amp;amp;&amp;amp; go run main.go &amp;amp;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;起動すると以下のようなログが出力されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/06/15 06:54:06 [**warning**] sleuth: config.Interface not defined [801]
2016/06/15 06:54:06 [ listening ] sleuth: [SLEUTH-v0:5670][echo-service E13055]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のコマンドでクライアントを実行し、&amp;rdquo;It works.&amp;rdquo; と表示されれば成功です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ (cd echo-client &amp;amp;&amp;amp; go run main.go)
It works.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;curlでも試してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s -d Hello 127.0.0.1:9873/echo-service/
Hello
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;サービスディスカバリの例を試す&#34;&gt;サービスディスカバリの例を試す&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;go get -u github.com/afshin/sleuth-example/...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でサンプルのコードと依存するライブラリを取得し&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd $GOPATH/src/github.com/afshin/sleuth-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;でプロジェクトのディレクトリに移動します。&lt;/p&gt;

&lt;p&gt;この例にはarticle-serviceとcomment-serviceという2つのサービスが含まれています。&lt;/p&gt;

&lt;p&gt;まずは article-service を起動します。article-serviceはポート9872で起動されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ (cd article-service &amp;amp;&amp;amp; go run main.go)
2016/06/14 22:38:08 [**warning**] sleuth: config.Interface not defined [801]
2016/06/14 22:38:08 [ listening ] sleuth: [SLEUTH-v0:5670][client-only EC740A]
2016/06/14 22:38:08 [**blocked**] sleuth: waiting for client to find [comment-service]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログに書かれているようにcomment-serviceが見つからなくて待っている状態です。&lt;/p&gt;

&lt;p&gt;別の端末を開いて以下のコマンドを実行してcomment-serviceを起動します。comment-serviceはポート9871で起動されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ (cd comment-service &amp;amp;&amp;amp; go run main.go)
2016/06/15 07:47:42 [**warning**] sleuth: config.Interface not defined [801]
2016/06/15 07:47:42 [ listening ] sleuth: [SLEUTH-v0:5670][comment-service 0DBE04]
ready...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;comment-serviceを起動するとarticle-serviceの端末には以下のログが追加で出力されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/06/15 07:47:43 [*unblocked*] sleuth: client found [comment-service]
ready...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまりarticle-serviceがcomment-serviceを発見（サービスディカバリ）出来たということです。&lt;/p&gt;

&lt;p&gt;別の端末を開いて以下のコマンドを実行してcurlでarticle-serviceから記事のデータを1件取得してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s localhost:9872/articles/049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d | jq .
{
  &amp;quot;success&amp;quot;: true,
  &amp;quot;data&amp;quot;: {
    &amp;quot;guid&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
    &amp;quot;byline&amp;quot;: &amp;quot;Kristen Rasmussen&amp;quot;,
    &amp;quot;headline&amp;quot;: &amp;quot;Wanting the Unwanted: Why Eat Weeds&amp;quot;,
    &amp;quot;url&amp;quot;: &amp;quot;http://www.rootedfood.com/musings/2015/4/1/a-foraged-affair&amp;quot;,
    &amp;quot;time&amp;quot;: 1428168580
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;comment-serviceからコメントのデータを1件取得します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s localhost:9871/comments/06500da3-f9b0-4731-b0fa-fbc6cbe8c155 | jq .
{
  &amp;quot;success&amp;quot;: true,
  &amp;quot;data&amp;quot;: [
    {
      &amp;quot;guid&amp;quot;: &amp;quot;d7041752-6854-4b2c-ad6d-1b48d898668d&amp;quot;,
      &amp;quot;article&amp;quot;: &amp;quot;06500da3-f9b0-4731-b0fa-fbc6cbe8c155&amp;quot;,
      &amp;quot;text&amp;quot;: &amp;quot;Star Trek, on the other hand, consistently presents an optimistic view of our capacity for civilization. I love science-fiction, even when it&amp;amp;#x27;s dystopian. But why does so much of it have to be dystopian?&amp;quot;,
      &amp;quot;time&amp;quot;: 1452738329
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に2つのサービスを連携させた使い方として、以下のコマンドで1件の記事とそれに紐づくコメントを取得します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s localhost:9872/articles/049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d?includecomments=true | jq .
{
  &amp;quot;success&amp;quot;: true,
  &amp;quot;data&amp;quot;: {
    &amp;quot;guid&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
    &amp;quot;byline&amp;quot;: &amp;quot;Kristen Rasmussen&amp;quot;,
    &amp;quot;comments&amp;quot;: [
      {
        &amp;quot;guid&amp;quot;: &amp;quot;1b1e937b-8521-4c88-a13c-105d421ea030&amp;quot;,
        &amp;quot;article&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
        &amp;quot;text&amp;quot;: &amp;quot;I believe the premise to be false, while it is true that you can eat many different &amp;amp;quot;weeds&amp;amp;quot; I cannot find any methodology or theory where that doing so increases the efficiency of land use. There are some key things like nutrients in == nutrie
nts out and digestibility in humans which is not a given.&amp;lt;p&amp;gt;That said, there were some interesting recipes for what are nominally weeds in the Foxfire[1], and Euell Gibbons books[2] which were certainly edible although nothing I&amp;amp;#x27;ve tried really struck me as excepti
onal. As Boy Scouts we got a merit badge for creating a meal out of locally harvested plants, that was fun.&amp;lt;p&amp;gt;[1] &amp;lt;a href=\&amp;quot;http:&amp;amp;#x2F;&amp;amp;#x2F;www.foxfire.org&amp;amp;#x2F;thefoxfirebooks.aspx\&amp;quot; rel=\&amp;quot;nofollow\&amp;quot;&amp;gt;http:&amp;amp;#x2F;&amp;amp;#x2F;www.foxfire.org&amp;amp;#x2F;thefoxfirebooks.aspx&amp;lt;/a&amp;gt;&amp;lt;p&amp;gt;[2]
 &amp;lt;a href=\&amp;quot;http:&amp;amp;#x2F;&amp;amp;#x2F;www.amazon.com&amp;amp;#x2F;Euell-Gibbons-Handbook-Edible-Plants&amp;amp;#x2F;dp&amp;amp;#x2F;0915442787\&amp;quot; rel=\&amp;quot;nofollow\&amp;quot;&amp;gt;http:&amp;amp;#x2F;&amp;amp;#x2F;www.amazon.com&amp;amp;#x2F;Euell-Gibbons-Handbook-Edible-Plants&amp;amp;#x2F;d...&amp;lt;/a&amp;gt;&amp;quot;,
        &amp;quot;time&amp;quot;: 1428172888
      },
      {
        &amp;quot;guid&amp;quot;: &amp;quot;1ffa59ea-1b62-41fe-87c3-98ec6901d768&amp;quot;,
        &amp;quot;article&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
        &amp;quot;text&amp;quot;: &amp;quot;Something to keep in mind here is that once a viable market is found then the product will be fully commercialised and mass-produced.  No longer will poor conditions be good enough when compared to the yield you get from ideal conditions.&amp;lt;p&amp;gt;Then we will
 start fertilising them, then tweaking the seeds etc etc etc. And before long it will be just like anything else grown on the land.&amp;quot;,
        &amp;quot;time&amp;quot;: 1428188859
      },
…(略)…
        &amp;quot;guid&amp;quot;: &amp;quot;587b528f-f4fe-4620-959e-f0d087c97348&amp;quot;,
        &amp;quot;article&amp;quot;: &amp;quot;049cd8fc-a66b-4a3d-956b-7c2ab5fb9c5d&amp;quot;,
        &amp;quot;text&amp;quot;: &amp;quot;The premise that weeds are a suitable food for humans is wrong. Most of these plants are loaded with toxins. You can&amp;amp;#x27;t eat them in any quantity for calories without getting poisoned.&amp;lt;p&amp;gt;Cows and goats and sheep can eat these things, though, because 
they have more advanced digestive systems. The udder provides an added toxin filtration system.&amp;lt;p&amp;gt;In theory you might be able to design an efficient system to detoxify wild plants such as grass and weeds directly into a high quality human food. At this moment cheese is 
already an incredibly effective way to use wild forage to make human food.&amp;quot;,
        &amp;quot;time&amp;quot;: 1428192718
      }
    ],
    &amp;quot;headline&amp;quot;: &amp;quot;Wanting the Unwanted: Why Eat Weeds&amp;quot;,
    &amp;quot;url&amp;quot;: &amp;quot;http://www.rootedfood.com/musings/2015/4/1/a-foraged-affair&amp;quot;,
    &amp;quot;time&amp;quot;: 1428168580
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sleuthのq-aを見てみる&#34;&gt;sleuthのQ &amp;amp; Aを見てみる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ursiform/sleuth#q--a&#34;&gt;Q &amp;amp; A&lt;/a&gt;を見ると、sleuthのメッセージプロトコルはJSONをgzipしてHTTPで通信しているとのことです。Protocol Buffersなどの他のライブラリに依存するのを避けたいという意図で、マイクロサービスのAPIレスポンスのほとんどは小さいのでJSONをgzipする方式で十分だし、そのほうがGo以外の言語でも利用しやすいので良いだろうということです。&lt;/p&gt;

&lt;p&gt;sleuthは熊のグループの集合名詞とのことです。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;sleuthはzeromqとGoさえあれば使えるということでセットアップが簡単です。&lt;/p&gt;

&lt;p&gt;サービスの実装&lt;a href=&#34;https://github.com/afshin/sleuth-example/blob/master/article-service/main.go&#34;&gt;sleuth-example/main.go&lt;/a&gt;と&lt;a href=&#34;https://github.com/afshin/sleuth-example/blob/master/comment-service/main.go&#34;&gt;sleuth-example/main.go&lt;/a&gt;も、Goで普通にウェブサービスを実装したところに、sleuthを使うためのコードを少し足すだけでいいのでお手軽でいいですね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>gistを作成するGoのCLIを見つけた</title>
      <link>/blog/2016/06/14/go_cli_to_create_a_gist/</link>
      <pubDate>Tue, 14 Jun 2016 00:52:22 +0900</pubDate>
      
      <guid>/blog/2016/06/14/go_cli_to_create_a_gist/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/delta24/gist&#34;&gt;delta24/gist: A command line gister in Go&lt;/a&gt;です。期待通りに動かない点があったのでプルリクエストを送ったら、すぐにマージされました。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;Goはインストール済みという前提で、以下のコマンドを実行します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get -u github.com/delta24/gist
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;事前準備&#34;&gt;事前準備&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://help.github.com/articles/creating-an-access-token-for-command-line-use/&#34;&gt;Creating an access token for command-line use - User Documentation&lt;/a&gt;の手順でアクセストークンを作って、 &lt;code&gt;~/.bash_profile&lt;/code&gt; とかに &lt;code&gt;export GITHUB_TOKEN=...&lt;/code&gt; のように書くなどして環境変数として設定するか、 あるいは &lt;code&gt;~/.gist&lt;/code&gt; というファイルを作ってトークンの値を書いておきます。&lt;/p&gt;

&lt;h2 id=&#34;使い方の例&#34;&gt;使い方の例&lt;/h2&gt;

&lt;p&gt;自分のユーザでpublicなgistを作成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gist -a=false -d &#39;説明&#39; ファイル名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自分のユーザでprivate (secret)なgistを作成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gist -a=false -p=false -d &#39;説明&#39; ファイル名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;anonymousユーザでpublicなgistを作成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gist -d &#39;説明&#39; ファイル名
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Goのシリアライゼーションのベンチマークを自分でも試してみた</title>
      <link>/blog/2016/06/13/tried_go_serialization_benchmarks/</link>
      <pubDate>Mon, 13 Jun 2016 23:34:16 +0900</pubDate>
      
      <guid>/blog/2016/06/13/tried_go_serialization_benchmarks/</guid>
      <description>&lt;p&gt;2015年12月の記事ですが&lt;a href=&#34;http://qiita.com/shibukawa/items/878c5fe8ec09935fccd2&#34;&gt;最速という噂のFlatbuffersの速度のヒミツと、導入方法の紹介(Go) - Qiita&lt;/a&gt;を読んで、「gobは遅いのかー、残念」、「一方Flatbuffersは面倒そうだなー」と思っていました。&lt;/p&gt;

&lt;p&gt;で、&lt;a href=&#34;https://github.com/alecthomas/go_serialization_benchmarks/tree/48e2bb8b7b6c38c24c88a0b027b30c80175a7b59#results&#34;&gt;alecthomas/go_serialization_benchmarks at 48e2bb8b7b6c38c24c88a0b027b30c80175a7b59&lt;/a&gt;のベンチマーク結果を見てみると、あれgob遅くないよ、というかVmihailencoMsgpackとUgorjiCodecMsgpackより速くなってました。&lt;/p&gt;

&lt;p&gt;自宅サーバ (NEC Express5800/S70)でもベンチマークを試してみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench . -benchmem | tee bench.txt                                                                                                                                               

A test suite for benchmarking various Go serialization methods.

See README.md for details on running the benchmarks.

PASS
BenchmarkMsgpMarshal-2                   3000000               423 ns/op             128 B/op          1 allocs/op
BenchmarkMsgpUnmarshal-2                 2000000               741 ns/op             112 B/op          3 allocs/op
BenchmarkVmihailencoMsgpackMarshal-2      500000              3107 ns/op             368 B/op          6 allocs/op
BenchmarkVmihailencoMsgpackUnmarshal-2    300000              4469 ns/op             352 B/op         13 allocs/op
BenchmarkJsonMarshal-2                    200000              7070 ns/op            1232 B/op         10 allocs/op
BenchmarkJsonUnmarshal-2                  200000              7331 ns/op             416 B/op          7 allocs/op
BenchmarkEasyJsonMarshal-2                500000              3116 ns/op             784 B/op          5 allocs/op
BenchmarkEasyJsonUnmarshal-2              500000              2936 ns/op             160 B/op          4 allocs/op
BenchmarkBsonMarshal-2                    500000              3031 ns/op             392 B/op         10 allocs/op
BenchmarkBsonUnmarshal-2                  500000              4047 ns/op             248 B/op         21 allocs/op
BenchmarkGobMarshal-2                    1000000              2189 ns/op              48 B/op          2 allocs/op
BenchmarkGobUnmarshal-2                  1000000              2226 ns/op             112 B/op          3 allocs/op
BenchmarkXdrMarshal-2                     500000              3862 ns/op             456 B/op         21 allocs/op
BenchmarkXdrUnmarshal-2                   500000              2885 ns/op             239 B/op         11 allocs/op
BenchmarkUgorjiCodecMsgpackMarshal-2      200000              7052 ns/op            2752 B/op          8 allocs/op
BenchmarkUgorjiCodecMsgpackUnmarshal-2    200000              7586 ns/op            3008 B/op          6 allocs/op
BenchmarkUgorjiCodecBincMarshal-2         200000              7347 ns/op            2784 B/op          8 allocs/op
BenchmarkUgorjiCodecBincUnmarshal-2       200000              8163 ns/op            3168 B/op          9 allocs/op
BenchmarkSerealMarshal-2                  200000              7518 ns/op             912 B/op         21 allocs/op
BenchmarkSerealUnmarshal-2                200000              7039 ns/op            1008 B/op         34 allocs/op
BenchmarkBinaryMarshal-2                  500000              2757 ns/op             256 B/op         16 allocs/op
BenchmarkBinaryUnmarshal-2                500000              3057 ns/op             336 B/op         22 allocs/op
BenchmarkFlatBuffersMarshal-2            3000000               573 ns/op               0 B/op          0 allocs/op
BenchmarkFlatBuffersUnmarshal-2          3000000               538 ns/op             112 B/op          3 allocs/op
BenchmarkCapNProtoMarshal-2              2000000               874 ns/op              56 B/op          2 allocs/op
BenchmarkCapNProtoUnmarshal-2            2000000               817 ns/op             200 B/op          6 allocs/op
BenchmarkCapNProto2Marshal-2             1000000              1991 ns/op             244 B/op          3 allocs/op
BenchmarkCapNProto2Unmarshal-2           1000000              2064 ns/op             320 B/op          6 allocs/op
BenchmarkHproseMarshal-2                 1000000              1797 ns/op             479 B/op          8 allocs/op
BenchmarkHproseUnmarshal-2                500000              2250 ns/op             320 B/op         10 allocs/op
BenchmarkProtobufMarshal-2               1000000              2052 ns/op             200 B/op          7 allocs/op
BenchmarkProtobufUnmarshal-2             1000000              1700 ns/op             192 B/op         10 allocs/op
BenchmarkGoprotobufMarshal-2             1000000              1141 ns/op             312 B/op          4 allocs/op
BenchmarkGoprotobufUnmarshal-2           1000000              1721 ns/op             432 B/op          9 allocs/op
BenchmarkGogoprotobufMarshal-2           5000000               291 ns/op              64 B/op          1 allocs/op
BenchmarkGogoprotobufUnmarshal-2         3000000               445 ns/op              96 B/op          3 allocs/op
BenchmarkColferMarshal-2                 5000000               260 ns/op              64 B/op          1 allocs/op
BenchmarkColferUnmarshal-2               5000000               387 ns/op             112 B/op          3 allocs/op
BenchmarkGencodeMarshal-2                5000000               322 ns/op              80 B/op          2 allocs/op
BenchmarkGencodeUnmarshal-2              5000000               392 ns/op             112 B/op          3 allocs/op
BenchmarkGencodeUnsafeMarshal-2         10000000               196 ns/op              48 B/op          1 allocs/op
BenchmarkGencodeUnsafeUnmarshal-2        5000000               322 ns/op              96 B/op          3 allocs/op
BenchmarkXDR2Marshal-2                   5000000               333 ns/op              64 B/op          1 allocs/op
BenchmarkXDR2Unmarshal-2                 5000000               313 ns/op              32 B/op          2 allocs/op
ok      github.com/alecthomas/go_serialization_benchmarks       81.009s
$ go version
go version go1.6.2 linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こちらも同じくgobはVmihailencoMsgpackとUgorjiCodecMsgpackより速かったです。Goのバージョンの違いなのかライブラリの進化なのかは調べてないですが、いつのまにか逆転していたようです。&lt;/p&gt;

&lt;p&gt;ということで、Go以外の言語との相互運用性を考えなくて良いなら、gobもシリアライゼーションのライブラリ選択の候補に入れて良さそうと思いました。&lt;a href=&#34;https://golang.org/pkg/encoding/gob/&#34;&gt;gob&lt;/a&gt;を見る限りはstructに対して特に何もしなくても使えるようなのでお手軽さでは一番良さそうですし。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GoでLTSV形式でログ出力するライブラリを書いた</title>
      <link>/blog/2016/06/13/wrote_go_ltsvlog_library/</link>
      <pubDate>Mon, 13 Jun 2016 21:42:53 +0900</pubDate>
      
      <guid>/blog/2016/06/13/wrote_go_ltsvlog_library/</guid>
      <description>

&lt;h2 id=&#34;なぜ書いたか&#34;&gt;なぜ書いたか&lt;/h2&gt;

&lt;p&gt;Goで高機能なサードパーティのログ出力ライブラリと言えば&lt;a href=&#34;https://github.com/Sirupsen/logrus&#34;&gt;Sirupsen/logrus&lt;/a&gt;が有名です。私も&lt;a href=&#34;https://github.com/doloopwhile/logrusltsv&#34;&gt;doloopwhile/logrusltsv&lt;/a&gt;と組み合わせてLTSV形式のログ出力するのに使っていました。&lt;/p&gt;

&lt;p&gt;しかし、&lt;a href=&#34;http://methane.hatenablog.jp/entry/2015/09/17/logger_%E3%81%AE%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6_%5BGo%5D&#34;&gt;logger のパフォーマンスについて [Go] - methaneのブログ&lt;/a&gt;にも書かれていますが、&lt;a href=&#34;https://godoc.org/github.com/Sirupsen/logrus#WithFields&#34;&gt;logrus.WithFields&lt;/a&gt;は&lt;a href=&#34;https://godoc.org/github.com/Sirupsen/logrus#Fields&#34;&gt;Fields&lt;/a&gt;、つまり &lt;code&gt;map[string]interface{}&lt;/code&gt; の値を渡す必要があります。これはGCに負荷をかけそうというのも気になりますが、Goのmapは順不同なのでログ出力の際にキーの順番がソースに書いた順番と必ずしも一致しないというのがイマイチだよなーと思っていました。&lt;/p&gt;

&lt;p&gt;ログ出力ライブラリはライブラリによって違うものを使うのはよくないから、自作するよりメジャーなものを使うほうが良いと自重する思いもありました。&lt;/p&gt;

&lt;p&gt;一方で、&lt;a href=&#34;http://dave.cheney.net/2015/11/05/lets-talk-about-logging&#34;&gt;Let’s talk about logging | Dave Cheney&lt;/a&gt;には賛同する点も多く、感銘を受けました。&lt;/p&gt;

&lt;p&gt;で、一度自作してみようかなーと思っていたところに、&lt;a href=&#34;https://github.com/uber-go/zap&#34;&gt;uber-go/zap&lt;/a&gt;を見かけて、ログ出力の引数側を加工するという方式にインスパイアされ、ついに自分が欲しいものを自分で書いてみました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;githubレポジトリ: &lt;a href=&#34;https://github.com/hnakamur/ltsvlog&#34;&gt;hnakamur/ltsvlog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;APIドキュメント: &lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog&#34;&gt;ltsvlog - GoDoc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;githubレポジトリのREADMEに使用例のコードがあります。&lt;/p&gt;

&lt;h2 id=&#34;ltsvlogの設計と実装&#34;&gt;ltsvlogの設計と実装&lt;/h2&gt;

&lt;h3 id=&#34;ltsvlogのログレベル&#34;&gt;ltsvlogのログレベル&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://dave.cheney.net/2015/11/05/lets-talk-about-logging&#34;&gt;Let’s talk about logging | Dave Cheney&lt;/a&gt;にもありましたが、ログレベルが多すぎると使い分けで悩むので少ないほうが良いと私も思います。ただ、エラー以外にもなにかが成功したときに記録しておきたいことはあるので、ErrorとInfoは分けたほうが良いと思います。あと私はprintデバッグ信者なのでデバッグログ用のDebugレベルは必要です。&lt;/p&gt;

&lt;p&gt;ということで、ltsvlogのログレベルはDebug, Info, Errorの3つです。&lt;/p&gt;

&lt;p&gt;レベル毎に出力するかしないかの切り替えはDebugレベルのみ許可することにしました。InfoとErrorは本番運用時にもログ出力するものだけに使うという考えです。Debugレベルを出力するかどうかは&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#NewLTSVLogger&#34;&gt;NewLTSVLogger&lt;/a&gt;でロガーを作るときに指定します。&lt;/p&gt;

&lt;p&gt;またDebugレベルのログ出力は無効時には引数の評価もしたくないので、 &lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LTSVLogger.DebugEnabled&#34;&gt;LTSVLogger.DebugEnabled()&lt;/a&gt;というメソッドも用意しました。使用例はこんな感じです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    if ltsvlog.Logger.DebugEnabled() {
        ltsvlog.Logger.Debug(ltsvlog.LV{&amp;quot;msg&amp;quot;, &amp;quot;This is a debug message&amp;quot;},
            ltsvlog.LV{&amp;quot;key&amp;quot;, &amp;quot;key1&amp;quot;}, ltsvlog.LV{&amp;quot;intValue&amp;quot;, 234})
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;スタックトレースの出力&#34;&gt;スタックトレースの出力&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LTSVLogger.ErrorWithStack&#34;&gt;LTSVLogger.ErrorWithStack&lt;/a&gt;でスタックトレース付きでログ出力できます。&lt;/p&gt;

&lt;p&gt;LTSV形式ではログは1レコードで1行にする必要があります。&lt;a href=&#34;https://golang.org/pkg/runtime/#Stack&#34;&gt;runtime.Stack&lt;/a&gt;でスタックトレースをバッファに書いてくれるのですが、こちらは複数行の出力になっています。コードを適宜コピペして好きな形式で出力するようにしようかと思ったのですが、&lt;a href=&#34;https://golang.org/src/runtime/mprof.go?s=16037:16073#L574&#34;&gt;src/runtime/mprof.go&lt;/a&gt;のソースコードを見て思いとどまりました。&lt;/p&gt;

&lt;p&gt;ということで、runtime.Stackの出力結果を加工するという方式で実装しています。
実際のコードは&lt;a href=&#34;https://github.com/hnakamur/ltsvlog/blob/v0.9.3/stack.go#L13-L60&#34;&gt;ltsvlog/stack.go&lt;/a&gt;です。コールスタックから不要な部分を取り除きつつ複数行から1行に変形するということで必ず元の長さより縮むので runtime.Stack で出力したバッファをそのまま使って変形しています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/runtime/#Stack&#34;&gt;runtime.Stack&lt;/a&gt;は呼び出し側がバッファを渡す必要があるのですが、サイズが小さいとスタックトレースが途中で切れてしまいます。デフォルトで 8192 というサイズにしたのですが、足りない場合は &lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#NewLTSVLoggerCustomFormat&#34;&gt;NewLTSVLoggerCustomFormat&lt;/a&gt; の引数でバッファサイズを指定できるようにしてます。&lt;/p&gt;

&lt;h3 id=&#34;時刻とログレベルの出力&#34;&gt;時刻とログレベルの出力&lt;/h3&gt;

&lt;p&gt;時刻はUTCでフォーマットは &lt;a href=&#34;https://golang.org/pkg/time/#pkg-constants&#34;&gt;time&lt;/a&gt;パッケージの &lt;code&gt;RFC3339Nano = &amp;quot;2006-01-02T15:04:05.999999999Z07:00&amp;quot;&lt;/code&gt; に近いですが、ナノセカンドの部分は個人的な好みで9桁固定で出力するようにしました。&lt;/p&gt;

&lt;h3 id=&#34;値の文字列化&#34;&gt;値の文字列化&lt;/h3&gt;

&lt;p&gt;上のコード例のようにラベルと値の組は&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LV&#34;&gt;ltsvlog.LV&lt;/a&gt;で指定します。&lt;/p&gt;

&lt;p&gt;将来 LV にフィールドが追加されるかもしれないと防御的に実装するなら、以下のように書いたほうが良いわけですが、LabelとValueでLVということでフィールド追加するつもりは無いので &lt;code&gt;L:&lt;/code&gt; や &lt;code&gt;V:&lt;/code&gt; は省略して、上記の例のように書いています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    if ltsvlog.Logger.DebugEnabled() {
        ltsvlog.Logger.Debug(ltsvlog.LV{L: &amp;quot;msg&amp;quot;, V: &amp;quot;This is a debug message&amp;quot;},
            ltsvlog.LV{L: &amp;quot;key&amp;quot;, V: &amp;quot;key1&amp;quot;}, ltsvlog.LV{L: &amp;quot;intValue&amp;quot;, V: 234})
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;値の文字列化は &lt;a href=&#34;https://github.com/hnakamur/ltsvlog/blob/v0.9.3/log.go#L175-L219&#34;&gt;https://github.com/hnakamur/ltsvlog/blob/v0.9.3/log.go#L175-L219&lt;/a&gt; で行っています。&lt;a href=&#34;https://golang.org/ref/spec#Type_switches&#34;&gt;Type switches&lt;/a&gt;を使って、値の型に応じて文字列化しています。コメントにも書いていますが、byteとuint8、runeとuintは別のcaseとして書くとコンパイルエラーになったので諦めてuint8とuintのほうだけを残しています。&lt;/p&gt;

&lt;p&gt;時刻とログレベルの出力形式と値の文字列化の方式を変えたい場合は関数を実装して&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#NewLTSVLoggerCustomFormat&#34;&gt;NewLTSVLoggerCustomFormat&lt;/a&gt; の引数に指定すれば良いようにしてあります。&lt;/p&gt;

&lt;h3 id=&#34;グローバルロガー&#34;&gt;グローバルロガー&lt;/h3&gt;

&lt;p&gt;標準の&lt;a href=&#34;https://golang.org/pkg/log/&#34;&gt;log&lt;/a&gt;パッケージではグローバルロガーの変数は非公開で&lt;a href=&#34;https://golang.org/pkg/log/#Print&#34;&gt;log.Print&lt;/a&gt;や&lt;a href=&#34;https://golang.org/pkg/log/#SetOutput&#34;&gt;log.SetOutput&lt;/a&gt;の関数で操作するようになっています。&lt;/p&gt;

&lt;p&gt;私は関数を増やすのが嫌だったのとグローバルロガーの変数は公開しても良いのではと思ったのでそうしました。&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#pkg-variables&#34;&gt;ltsvlog.Logger&lt;/a&gt;で参照できます。デフォルトでは標準出力にデバッグログありで出力するようになっています。デバッグログをオフにしたい場合はmain関数の最初のほうで(ログ出力する前に)以下のようにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; ltsvlog.Logger = ltsvlog.NewLTSVLogger(os.Stdout, false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ログ出力中に設定を変えることはないという想定です。&lt;/p&gt;

&lt;h3 id=&#34;logwriterインタフェースと常に何も出力しないdiscard&#34;&gt;LogWriterインタフェースと常に何も出力しないDiscard&lt;/h3&gt;

&lt;p&gt;後付ですが&lt;a href=&#34;https://godoc.org/github.com/hnakamur/ltsvlog#LogWriter&#34;&gt;ltsvlog.LogWriter&lt;/a&gt;というインタフェースも定義してみました。インタフェースは Logger という名前にしたいところでしたが、グローバルロガーに Logger という名前を使っていたので仕方なく LogWriter にしました。そして常に何も出力しない Discard というのも作りました。ただし、Infoなどの引数は評価されてしまうので実行コストが0なわけではないです。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/ltsvlog#benchmark-result&#34;&gt;Benchmark result&lt;/a&gt;に標準のlogパッケージと比較したベンチマーク結果を載せています。logパッケージよりは遅い手ですがほぼ同等だと言えると思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hnakamur/ltsvlog&#34;&gt;hnakamur/ltsvlog&lt;/a&gt;はコード量も大したことないので、保守で困ることはないと楽観視しています。&lt;/p&gt;

&lt;p&gt;ということで自分で書くライブラリやアプリケーションではどんどん使っていきたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Goで複数のリモートのワーカーにジョブを実行させるremoteworkersというパッケージを書いた</title>
      <link>/blog/2016/06/12/wrote_remoteworkers_go_pacakge/</link>
      <pubDate>Sun, 12 Jun 2016 21:53:35 +0900</pubDate>
      
      <guid>/blog/2016/06/12/wrote_remoteworkers_go_pacakge/</guid>
      <description>

&lt;h2 id=&#34;なぜ書いたか&#34;&gt;なぜ書いたか&lt;/h2&gt;

&lt;p&gt;仕事で複数のサーバで同じ処理を実行して結果を集めたいというニーズがあって、各サーバをgRPCのサーバにするという実装でとりあえず実現していました。でも、出来れば処理を実行するワーカーサーバから制御サーバに接続して繋ぎっぱなしにしておいて、制御サーバからジョブを送り込む方式にしたいなーと思っていて、家で実装を進めていました。&lt;/p&gt;

&lt;h2 id=&#34;これまでに試したこと&#34;&gt;これまでに試したこと&lt;/h2&gt;

&lt;p&gt;gRPCに&lt;a href=&#34;http://www.grpc.io/docs/tutorials/basic/go.html#bidirectional-streaming-rpc&#34;&gt;Bidirectional streaming RPC&lt;/a&gt;というのがあったので、&lt;a href=&#34;https://github.com/hnakamur/grpc_notification_experiment&#34;&gt;hnakamur/grpc_notification_experiment&lt;/a&gt;で試してみたのですが、複数クライアントがサーバに接続した状態で、サーバからクライアントにジョブを投げても、1つのクライアントでしか処理が実行されないということがわかりました。&lt;/p&gt;

&lt;p&gt;次に、ワーカーサーバから制御サーバにTCPのソケットで接続しておいて、制御サーバからワーカーサーバにジョブを投げて結果を集めるサンプルを書いてみました。
&lt;a href=&#34;https://github.com/hnakamur/tcp_pubsubreply_experiment&#34;&gt;hnakamur/tcp_pubsubreply_experiment&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;複数のワーカーに同じジョブを投げて結果を集めて、全てのワーカーからの結果が揃ったらクライアントに結果を返すというものです。 &lt;a href=&#34;https://github.com/hnakamur/tcp_pubsubreply_experiment/blob/f9201c075661c5d58895f9a30b47f73f5c4cc13d/main.go#L167-L189&#34;&gt;https://github.com/hnakamur/tcp_pubsubreply_experiment/blob/f9201c075661c5d58895f9a30b47f73f5c4cc13d/main.go#L167-L189&lt;/a&gt; でジョブを各ワーカーのコネクションが持つチャンネルに送って、各ワーカーの結果を返すチャンネルから受け取るという素朴な実装になっています。&lt;/p&gt;

&lt;p&gt;しかし、この実装では1つのジョブを実行中は他のジョブを実行できないという制限があります。また試しているとタイミングによっては期待通りの動きにならないことがありました。&lt;/p&gt;

&lt;h2 id=&#34;今回の実装&#34;&gt;今回の実装&lt;/h2&gt;

&lt;p&gt;実装は&lt;a href=&#34;https://github.com/hnakamur/remoteworkers&#34;&gt;hnakamur/remoteworkers&lt;/a&gt;で公開しています。使用例は&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/tree/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example&#34;&gt;remoteworkers/example&lt;/a&gt;、APIドキュメントは&lt;a href=&#34;https://godoc.org/github.com/hnakamur/remoteworkers&#34;&gt;remoteworkers - GoDoc&lt;/a&gt;を参照してください。&lt;/p&gt;

&lt;p&gt;最初はWebSocketのライブラリ&lt;a href=&#34;https://github.com/gorilla/websocket&#34;&gt;github.com/gorilla/websocket&lt;/a&gt;の&lt;a href=&#34;https://github.com/gorilla/websocket/tree/a68708917c6a4f06314ab4e52493cc61359c9d42/examples&#34;&gt;examples&lt;/a&gt;のchatとechoのclientを組み合わせて改変していきました。chatは1つのクライアントからのメッセージを他のクライアントに送って終わりですが、今回はジョブを実行して結果を集めたいので、その処理を追加で実装しました。また、元のサンプルはグローバル変数や設定用の定数を使うようになっていたのでstructを定義してグローバル変数をやめて設定もstructのメンバーに持つようにしました。&lt;/p&gt;

&lt;p&gt;ワーカーはサーバにwebsocketで接続しますが、クライアントは通常のhttpリクエストでジョブを投げてレスポンスで結果を受け取るようにしてみました。ワーカーとサーバの間のメッセージは&lt;a href=&#34;/blog/blog/2016/06/04/benchmark_go_msgpack_libraries/&#34;&gt;GoのMessagePackのライブラリのベンチマークをしてみた · hnakamur&amp;rsquo;s blog at github&lt;/a&gt;で試した&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;vmihailenco/msgpack&lt;/a&gt;を使ってMessagePackでエンコード・デコードしています。&lt;/p&gt;

&lt;p&gt;以下実装メモです。&lt;/p&gt;

&lt;h3 id=&#34;connとhub&#34;&gt;ConnとHub&lt;/h3&gt;

&lt;p&gt;サーバ側のメインの処理は、サーバとワーカーのコネクションを扱う&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go&#34;&gt;Conn&lt;/a&gt;と複数のConnの間を取り持つ&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go&#34;&gt;Hub&lt;/a&gt;が担当しています。&lt;/p&gt;

&lt;h3 id=&#34;読み取りと書き出しでgoroutineを分ける&#34;&gt;読み取りと書き出しでgoroutineを分ける&lt;/h3&gt;

&lt;p&gt;上記の&lt;a href=&#34;https://github.com/hnakamur/tcp_pubsubreply_experiment&#34;&gt;hnakamur/tcp_pubsubreply_experiment&lt;/a&gt;では、ワーカーとサーバ間のTCPコネクション1つのに対して1つgoroutineを作ってデータの読み書きをしていました。&lt;/p&gt;

&lt;p&gt;一方、&lt;a href=&#34;https://godoc.org/github.com/gorilla/websocket&#34;&gt;github.com/gorilla/websocketのAPIドキュメント&lt;/a&gt;の&lt;a href=&#34;https://godoc.org/github.com/gorilla/websocket#hdr-Concurrency&#34;&gt;Concurrency&lt;/a&gt;にコネクションは1つのコンカレントなリーダーと1つのコンカレントなライターをサポートすると書いてあります。&lt;/p&gt;

&lt;p&gt;chatのexampleを見ると&lt;a href=&#34;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L50-L69&#34;&gt;Conn.readPump()&lt;/a&gt;で読み取り処理のループ、&lt;a href=&#34;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L78-L116&#34;&gt;Conn.writePump()&lt;/a&gt;で書き出し処理のループを実装していて &lt;a href=&#34;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L127-L128&#34;&gt;https://github.com/gorilla/websocket/blob/a68708917c6a4f06314ab4e52493cc61359c9d42/examples/chat/conn.go#L127-L128&lt;/a&gt; でgoroutineを使って並行(concurrent)に実行しています。&lt;/p&gt;

&lt;p&gt;この方式により上記の&lt;a href=&#34;https://godoc.org/github.com/gorilla/websocket#hdr-Concurrency&#34;&gt;Concurrency&lt;/a&gt;の1つのコネクションに1つのコンカレントなリーダーと1つのコンカレントなライターという条件を自動的に満たすことが出来ます。&lt;/p&gt;

&lt;p&gt;さらに、ワーカーでのジョブの実行も &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L200-L214&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L200-L214&lt;/a&gt; のように別のgoroutineで実行するようにしました。読み取りと書き出しのgoroutineを分け、ジョブ実行のgoroutineも別にしたことで、ワーカーでジョブを実行中でも別のジョブを受け取って実行することが出来るようになりました。&lt;/p&gt;

&lt;h3 id=&#34;ジョブのディスパッチと結果の収集&#34;&gt;ジョブのディスパッチと結果の収集&lt;/h3&gt;

&lt;p&gt;各ワーカーからにジョブを投げて結果を集める部分も &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L139-L171&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L139-L171&lt;/a&gt; のように書くことで、複数のジョブを並行で実行できるようになっています。&lt;/p&gt;

&lt;p&gt;例えば、あるジョブを依頼されてそれの結果が集まる前に、次のジョブを受け取ってそちらの結果が先に集まった場合はそちらを先に返すことができます。&lt;/p&gt;

&lt;h3 id=&#34;自動で再接続&#34;&gt;自動で再接続&lt;/h3&gt;

&lt;p&gt;ワーカーとの接続が切れた場合は、残ったワーカーだけで処理を実行する仕様としました。ジョブを受け取った時にワーカーが1つもいない場合はエラーとしています。また、ワーカーからサーバへの接続が切れた場合は1秒待って再起動を無限に繰り替えすようにしています。時間は設定で変更可能です。ただし、だんだん間隔を開けるといったことは出来ないのでその場合はフォークして改変してください。&lt;/p&gt;

&lt;h3 id=&#34;返信用のチャンネルを渡して実行&#34;&gt;返信用のチャンネルを渡して実行&lt;/h3&gt;

&lt;p&gt;サーバとワーカのコネクションをHubに登録する箇所 &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L86-L92&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L86-L92&lt;/a&gt; とクライアントから依頼されたジョブをHubに投げて全ワーカーからの結果を受け取る箇所 &lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L194-L203&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L194-L203&lt;/a&gt; では、結果を受け取るためのチャンネルをHubへのチャンネルに渡して実行するという方法を取りました。&lt;/p&gt;

&lt;p&gt;これによってHubとのやり取りは全てチャンネル経由になりシンプルになりました。さらに関数の中に閉じ込めることで、ライブラリの利用者はチャンネルを意識することなく単なる関数呼び出しで使えるようになっています。&lt;/p&gt;

&lt;h3 id=&#34;ジョブのエンコード-デコード&#34;&gt;ジョブのエンコード・デコード&lt;/h3&gt;

&lt;p&gt;まずクライアントではジョブをJSONでエンコードしています。
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/client/client.go#L25-L30&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/client/client.go#L25-L30&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;サーバでは受け取ったジョブをJSONでデコードします。
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L52-L54&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L52-L54&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;その後&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L193-L205&#34;&gt;Hub.RequestWork()&lt;/a&gt;でHubにジョブが渡されて
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L142&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L142&lt;/a&gt;
でMessagePackでエンコードしてワーカーに送ります。&lt;/p&gt;

&lt;p&gt;ワーカーでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L187-L188&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L187-L188&lt;/a&gt;
で受け取ったジョブをMessagePackでデコードします。&lt;/p&gt;

&lt;p&gt;ワーカーでジョブを受け取って処理する部分は
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/worker/main.go#L47-L58&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/worker/main.go#L47-L58&lt;/a&gt;
です。&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;vmihailenco/msgpack&lt;/a&gt;で &lt;code&gt;map[string]string&lt;/code&gt; 型をエンコードしてデコードすると &lt;code&gt;map[interface{}]interface{}&lt;/code&gt; になったので&lt;a href=&#34;https://golang.org/ref/spec#Type_assertions&#34;&gt;type assertion&lt;/a&gt;を使って参照する必要がありました。&lt;/p&gt;

&lt;h3 id=&#34;結果のエンコード-デコード&#34;&gt;結果のエンコード・デコード&lt;/h3&gt;

&lt;p&gt;ワーカーでの結果は
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L202-L206&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/worker.go#L202-L206&lt;/a&gt;
でMessagePackにエンコードしています。&lt;/p&gt;

&lt;p&gt;サーバでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L148-L163&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/conn.go#L148-L163&lt;/a&gt;
で結果をMessagePackでデコードしてHubに送っています。&lt;/p&gt;

&lt;p&gt;Hubでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L165-L171&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/hub.go#L165-L171&lt;/a&gt;
で1つのワーカーからの結果を受け取り、全てのワーカーからの結果が揃ったらクライアントへ返信するためのチャンネルに集めた結果を送ります。&lt;/p&gt;

&lt;p&gt;サーバでは
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L28-L39&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L28-L39&lt;/a&gt;
で集めた結果の構造を変形し、
&lt;a href=&#34;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L69-L70&#34;&gt;https://github.com/hnakamur/remoteworkers/blob/0ee6c4fa0ffe12af7ff6e7aefd5e3f0ebe042e31/example/server/main.go#L69-L70&lt;/a&gt;
でJSONにエンコードしています。&lt;/p&gt;

&lt;h3 id=&#34;tcpソケットからwebsocketにして良かったところ&#34;&gt;TCPソケットからWebSocketにして良かったところ&lt;/h3&gt;

&lt;p&gt;ワーカーからサーバに接続したときにワーカーのIDを登録しているのですが、TCPソケットのときはそのためにワーカーから登録用のメッセージを送って成功失敗の結果を送る必要がありました。一方WebSocketではエンドポイントに接続するときにリクエストヘッダで追加の情報を送れるので &lt;code&gt;X-Worker-ID&lt;/code&gt; と言うヘッダ名でワーカーIDを送るようにしました。&lt;/p&gt;

&lt;p&gt;また、TCPソケットだと1つのポートでクライアントとワーカーからの通信を受ける場合はメッセージの内容で区別がつくようにしておく必要があります。WebSocketの場合は1つのポートでもURLのPathを別にするという手が使えるので楽です。しかも今回のようにワーカーはWebSocketで接続し、クライアントはhttpで接続ということも出来て便利です。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;当初やりたいと思っていたことがようやく実現できました。しかも、これだけ並列性が高いプログラムなのにgoroutineとchannelのおかげですっきりシンプルなコードで実装出来ています。これなら保守や改変もしやすくて助かります。やっぱりGoは素晴らしいです！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GoのMessagePackのライブラリのベンチマークをしてみた</title>
      <link>/blog/2016/06/04/benchmark_go_msgpack_libraries/</link>
      <pubDate>Sat, 04 Jun 2016 22:17:52 +0900</pubDate>
      
      <guid>/blog/2016/06/04/benchmark_go_msgpack_libraries/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://qiita.com/yosisa/items/f21d3476bc8d368d7494&#34;&gt;Go の msgpack ライブラリ比較 - Qiita&lt;/a&gt;の記事が最終更新日から1年以上経過しているとのことなので、現在の最新のコミットで試してみました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;github.com/vmihailenco/msgpack&lt;/code&gt; を &lt;code&gt;go get&lt;/code&gt; すると&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go get github.com/vmihailenco/msgpack
package github.com/vmihailenco/msgpack: code in directory /home/hnakamur/gocode/src/github.com/vmihailenco/msgpack expects import &amp;quot;gopkg.in/vmihailenco/msgpack.v2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;と言われたので &lt;code&gt;go get gopkg.in/vmihailenco/msgpack.v2&lt;/code&gt; で取得し、この記事のコードの &lt;code&gt;&amp;quot;github.com/vmihailenco/msgpack&amp;quot;&lt;/code&gt; を &lt;code&gt;&amp;quot;gopkg.in/vmihailenco/msgpack.v2&amp;quot;&lt;/code&gt; に書き換え &lt;code&gt;msgpack_test.go&lt;/code&gt; という名前で保存して試しました。&lt;/p&gt;

&lt;p&gt;エンコードは &lt;code&gt;gopkg.in/vmihailenco/msgpack.v2&lt;/code&gt; 、デコードは &lt;code&gt;github.com/ugorji/go/codec&lt;/code&gt; が速いという結果になりましたが、総合的にはほぼ同等と言えると思います。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench . -benchmem
testing: warning: no tests to run
PASS
BenchmarkCodecEncode-2            500000              3236 ns/op              48 B/op          2 allocs/op
BenchmarkCodecDecode-2            200000              8998 ns/op             264 B/op         25 allocs/op
BenchmarkMsgpackEncode-2          500000              2624 ns/op              48 B/op          2 allocs/op
BenchmarkMsgpackDecode-2          200000             10604 ns/op             448 B/op         35 allocs/op
ok      bitbucket.org/hnakamur/msgpack_experiment       7.146s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ベンチマークに使用したライブラリとGoのバージョンは以下の通りです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git -C $GOPATH/src/github.com/ugorji/go rev-parse HEAD
a396ed22fc049df733440d90efe17475e3929ccb
$ git -C $GOPATH/src/gopkg.in/vmihailenco/msgpack.v2 rev-parse HEAD
851cd631b60599a692b136c60eb6eb2899b0e664
$ go version
go version go1.6.2 linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;vmihailenco/msgpack: MessagePack encoding for Golang&lt;/a&gt;のベンチマークもやってみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench . -benchmem                                          
2016/06/04 22:12:13 
************************************************ 
package github.com/ugorji/go-msgpack has been deprecated (05/29/2013). 
It will be retired anytime from July 1, 2013.
Please update to faster and much much better github.com/ugorji/go/codec.
See https://github.com/ugorji/go/tree/master/codec#readme for more information.
************************************************ 
OK: 27 passed, 1 skipped
PASS
BenchmarkBool-2                         20000000                90.3 ns/op             0 B/op          0 allocs/op
BenchmarkInt0-2                         20000000                96.1 ns/op             0 B/op          0 allocs/op
BenchmarkInt1-2                         10000000               123 ns/op               0 B/op          0 allocs/op
BenchmarkInt2-2                         10000000               123 ns/op               0 B/op          0 allocs/op
BenchmarkInt4-2                         10000000               179 ns/op               0 B/op          0 allocs/op
BenchmarkInt8-2                         10000000               176 ns/op               0 B/op          0 allocs/op
BenchmarkInt0Binary-2                    5000000               340 ns/op              24 B/op          3 allocs/op
BenchmarkInt0UgorjiGoMsgpack-2           3000000               586 ns/op               8 B/op          1 allocs/op
BenchmarkInt0UgorjiGoCodec-2             5000000               360 ns/op               0 B/op          0 allocs/op
BenchmarkTime-2                          5000000               353 ns/op               0 B/op          0 allocs/op
BenchmarkDuration-2                     10000000               180 ns/op               0 B/op          0 allocs/op
BenchmarkByteSlice-2                     1000000              1021 ns/op            1024 B/op          1 allocs/op
BenchmarkByteArray-2                      500000              2741 ns/op            2112 B/op          4 allocs/op
BenchmarkByteSliceUgorjiGoCodec-2        2000000               647 ns/op               0 B/op          0 allocs/op
BenchmarkByteArrayUgorjiGoCodec-2        1000000              2632 ns/op            1088 B/op          3 allocs/op
BenchmarkMapStringString-2               1000000              1898 ns/op              16 B/op          4 allocs/op
BenchmarkMapStringStringPtr-2             500000              2461 ns/op              32 B/op          5 allocs/op
BenchmarkMapStringStringUgorjiGoCodec-2  1000000              1737 ns/op              16 B/op          4 allocs/op
BenchmarkMapIntInt-2                      500000              3424 ns/op             208 B/op         10 allocs/op
BenchmarkStringSlice-2                   3000000               530 ns/op              10 B/op          2 allocs/op
BenchmarkStringSlicePtr-2                1000000              1270 ns/op              26 B/op          3 allocs/op
BenchmarkStructVmihailencoMsgpack-2       100000             12732 ns/op            3152 B/op         27 allocs/op
BenchmarkStructMarshal-2                  300000              6003 ns/op            1808 B/op          8 allocs/op
BenchmarkStructUnmarshal-2                200000              5788 ns/op            1344 B/op         19 allocs/op
BenchmarkStructManual-2                   200000              6610 ns/op            2720 B/op         21 allocs/op
BenchmarkStructUgorjiGoMsgpack-2          100000             17138 ns/op            3616 B/op         70 allocs/op
BenchmarkStructUgorjiGoCodec-2            100000             21833 ns/op            7345 B/op         23 allocs/op
BenchmarkStructJSON-2                      20000             63809 ns/op            7896 B/op         26 allocs/op
BenchmarkStructGOB-2                       20000             96275 ns/op           14664 B/op        278 allocs/op
BenchmarkStructUnmarshalPartially-2       300000              5791 ns/op            2272 B/op         12 allocs/op
BenchmarkCSV-2                            200000              6971 ns/op            8748 B/op         12 allocs/op
BenchmarkCSVMsgpack-2                    1000000              1541 ns/op             384 B/op         13 allocs/op
ok      gopkg.in/vmihailenco/msgpack.v2 58.623s
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gopkg-in-vmihailenco-msgpack-v2-でgoのstructをエンコード-デコードするインターフェース&#34;&gt;gopkg.in/vmihailenco/msgpack.v2 でGoのstructをエンコード・デコードするインターフェース&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2#Marshaler&#34;&gt;Marshaler&lt;/a&gt; はdeprecatedで&lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2#CustomEncoder&#34;&gt;CustomEncoder&lt;/a&gt;を使えとのことです。&lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2#CustomEncoder&#34;&gt;CustomEncoder&lt;/a&gt; の Example を見ると使い方も簡単そうです。&lt;/p&gt;

&lt;h2 id=&#34;gopkg-in-vmihailenco-msgpack-v2-を使うことにします&#34;&gt;gopkg.in/vmihailenco/msgpack.v2 を使うことにします&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vmihailenco/msgpack&#34;&gt;github.com/vmihailenco/msgpack&lt;/a&gt;も&lt;a href=&#34;https://github.com/ugorji/go/tree/master/codec&#34;&gt;go/codec at master · ugorji/go&lt;/a&gt;も活発にメンテナンスされているようです。&lt;/p&gt;

&lt;p&gt;APIドキュメント &lt;a href=&#34;https://godoc.org/gopkg.in/vmihailenco/msgpack.v2&#34;&gt;gopkg.in/vmihailenco/msgpack.v2&lt;/a&gt;、&lt;a href=&#34;https://godoc.org/github.com/ugorji/go/codec&#34;&gt;github.com/ugorji/go/codec&lt;/a&gt; を見ると私は前者のほうがしっくりきました。ということで gopkg.in/vmihailenco/msgpack.v2 を使うことにします。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LXDのREST APIクライアントライブラリpylxdを試してみた</title>
      <link>/blog/2016/05/07/tried-pylxd/</link>
      <pubDate>Sat, 07 May 2016 21:17:35 +0900</pubDate>
      
      <guid>/blog/2016/05/07/tried-pylxd/</guid>
      <description>

&lt;p&gt;Python Package Index (PyPI)の &lt;a href=&#34;https://pypi.python.org/pypi/pylxd/2.0.0&#34;&gt;pylxd 2.0.0&lt;/a&gt;のページにインストール方法と使い方の例が書いてあるので、これに沿って試しました。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;Ubuntu 16.04だとaptでインストール可能なのでそちらでインストールしました。Python3用のpython3-pylxdパッケージとPython2用のpython-pylxdパッケージがありますが、今後Ansibleのモジュールを作ることを想定してPython2用のパッケージをインストールして試してみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install -y python-pylxd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インストールしたpython-pylxdのバージョンは &lt;code&gt;2.0.0-0ubuntu1&lt;/code&gt; です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ dpkg-query -W -f=&#39;${Version}\n&#39; python-pylxd
2.0.0-0ubuntu1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;試してみる&#34;&gt;試してみる&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ python
Python 2.7.11+ (default, Apr 17 2016, 14:00:29)
[GCC 5.3.1 20160413] on linux2
Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information.
&amp;gt;&amp;gt;&amp;gt; from pylxd import api
&amp;gt;&amp;gt;&amp;gt; lxd = api.API()
&amp;gt;&amp;gt;&amp;gt; lxd.container_defined(&#39;cent01&#39;)
True
&amp;gt;&amp;gt;&amp;gt; lxd.container_defined(&#39;hoge&#39;)
False
&amp;gt;&amp;gt;&amp;gt; lxd.container_list()
[u&#39;cent01&#39;, u&#39;cent02&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここから先は &lt;a href=&#34;https://github.com/lxc/pylxd/blob/master/pylxd/client.py&#34;&gt;pylxd/client.py&lt;/a&gt; と &lt;a href=&#34;https://github.com/lxc/pylxd/blob/master/pylxd/container.py&#34;&gt;pylxd/container.py&lt;/a&gt; の ソースを見ながら試しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from pylxd.client import Client
&amp;gt;&amp;gt;&amp;gt; client = Client()
&amp;gt;&amp;gt;&amp;gt; client.containers.all()
[&amp;lt;pylxd.container.Container object at 0x7fd44065db00&amp;gt;, &amp;lt;pylxd.container.Container object at 0x7fd44065db98&amp;gt;]
&amp;gt;&amp;gt;&amp;gt; client.containers.get(u&#39;cent01&#39;)
&amp;lt;pylxd.container.Container object at 0x7fd44065dc30&amp;gt;
&amp;gt;&amp;gt;&amp;gt; client.containers.get(u&#39;cent01&#39;).status
u&#39;Running&#39;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>LXDのREST APIをcurlで試してみた</title>
      <link>/blog/2016/05/07/tried-lxd-rest-api-with-curl/</link>
      <pubDate>Sat, 07 May 2016 21:17:34 +0900</pubDate>
      
      <guid>/blog/2016/05/07/tried-lxd-rest-api-with-curl/</guid>
      <description>

&lt;h2 id=&#34;lxdのrest-api&#34;&gt;LXDのREST API&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://linuxcontainers.org/ja/lxd/rest-api/&#34;&gt;Linux Containers - LXD - REST API&lt;/a&gt;と&lt;a href=&#34;https://github.com/lxc/lxd/blob/master/doc/rest-api.md&#34;&gt;lxd/rest-api.md at master · lxc/lxd&lt;/a&gt;にLXDのREST APIについて説明があります。&lt;/p&gt;

&lt;p&gt;また&lt;a href=&#34;https://github.com/lxc/lxd#using-the-rest-api&#34;&gt;Using the REST API&lt;/a&gt;に &lt;code&gt;curl&lt;/code&gt; コマンドでのAPI呼び出し例が書かれていました。&lt;/p&gt;

&lt;h2 id=&#34;curlでhttpsのエンドポイントにアクセスしてみたがエラー&#34;&gt;curlでhttpsのエンドポイントにアクセスしてみたがエラー&lt;/h2&gt;

&lt;p&gt;まずはhttpsのURLで &lt;a href=&#34;https://github.com/lxc/lxd/blob/master/doc/rest-api.md#10&#34;&gt;/1.0&lt;/a&gt; エンドポイントを試してみたのですが、 &lt;code&gt;ALPN, server did not agree to a protocol&lt;/code&gt; というエラーになってしまいました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -k -v --cert ~/.config/lxc/client.crt --key ~/.config/lxc/client.key https://127.0.0.1:8443/1.0
*   Trying 127.0.0.1...
* Connected to 127.0.0.1 (127.0.0.1) port 8443 (#0)
* found 173 certificates in /etc/ssl/certs/ca-certificates.crt
* found 692 certificates in /etc/ssl/certs
* ALPN, offering http/1.1
* SSL connection using TLS1.2 / ECDHE_RSA_AES_128_GCM_SHA256
*        server certificate verification SKIPPED
*        server certificate status verification SKIPPED
*        common name: root@express (does not match &#39;127.0.0.1&#39;)
*        server certificate expiration date OK
*        server certificate activation date OK
*        certificate public key: RSA
*        certificate version: #3
*        subject: O=linuxcontainers.org,CN=root@express
*        start date: Tue, 03 May 2016 11:26:51 GMT
*        expire date: Fri, 01 May 2026 11:26:51 GMT
*        issuer: O=linuxcontainers.org,CN=root@express
*        compression: NULL
* ALPN, server did not agree to a protocol
&amp;gt; GET /1.0 HTTP/1.1
&amp;gt; Host: 127.0.0.1:8443
&amp;gt; User-Agent: curl/7.47.0
&amp;gt; Accept: */*
&amp;gt;
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Content-Type: application/json
&amp;lt; Date: Sat, 07 May 2016 12:25:53 GMT
&amp;lt; Content-Length: 162
&amp;lt;
{&amp;quot;type&amp;quot;:&amp;quot;sync&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;Success&amp;quot;,&amp;quot;status_code&amp;quot;:200,&amp;quot;metadata&amp;quot;:{&amp;quot;api_extensions&amp;quot;:[],&amp;quot;api_status&amp;quot;:&amp;quot;stable&amp;quot;,&amp;quot;api_version&amp;quot;:&amp;quot;1.0&amp;quot;,&amp;quot;auth&amp;quot;:&amp;quot;untrusted&amp;quot;,&amp;quot;public&amp;quot;:false}}
* Connection #0 to host 127.0.0.1 left intact
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この件は&lt;a href=&#34;https://lists.linuxcontainers.org/pipermail/lxc-users/2016-May/011603.html&#34;&gt;[lxc-users] The error &amp;ldquo;ALPN, server did not agree to a protocol&amp;rdquo; from LXD Rest API&lt;/a&gt;で質問してみました。&lt;/p&gt;

&lt;h2 id=&#34;curlでunix-domain-socket経由でアクセスしてみたら成功&#34;&gt;curlでunix domain socket経由でアクセスしてみたら成功&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/toritori0318/items/193df8f749a9c4bda883&#34;&gt;curlでunix domain socket経由アクセスする - Qiita&lt;/a&gt;を参考に以下のようにアクセスしてみると成功しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s --unix-socket /var/lib/lxd/unix.socket https:/1.0 | jq .
{
  &amp;quot;type&amp;quot;: &amp;quot;sync&amp;quot;,
  &amp;quot;status&amp;quot;: &amp;quot;Success&amp;quot;,
  &amp;quot;status_code&amp;quot;: 200,
  &amp;quot;metadata&amp;quot;: {
    &amp;quot;api_extensions&amp;quot;: [],
    &amp;quot;api_status&amp;quot;: &amp;quot;stable&amp;quot;,
    &amp;quot;api_version&amp;quot;: &amp;quot;1.0&amp;quot;,
    &amp;quot;auth&amp;quot;: &amp;quot;trusted&amp;quot;,
    &amp;quot;config&amp;quot;: {
      &amp;quot;core.https_address&amp;quot;: &amp;quot;127.0.0.1:8443&amp;quot;,
      &amp;quot;core.trust_password&amp;quot;: true
    },
    &amp;quot;environment&amp;quot;: {
      &amp;quot;addresses&amp;quot;: [
        &amp;quot;127.0.0.1:8443&amp;quot;
      ],
      &amp;quot;architectures&amp;quot;: [
        &amp;quot;x86_64&amp;quot;,
        &amp;quot;i686&amp;quot;
      ],
      &amp;quot;certificate&amp;quot;: &amp;quot;-----BEGIN CERTIFICATE-----\n …(略)… \n-----END CERTIFICATE-----\n&amp;quot;,
      &amp;quot;driver&amp;quot;: &amp;quot;lxc&amp;quot;,
      &amp;quot;driver_version&amp;quot;: &amp;quot;2.0.0&amp;quot;,
      &amp;quot;kernel&amp;quot;: &amp;quot;Linux&amp;quot;,
      &amp;quot;kernel_architecture&amp;quot;: &amp;quot;x86_64&amp;quot;,
      &amp;quot;kernel_version&amp;quot;: &amp;quot;4.4.0-21-generic&amp;quot;,
      &amp;quot;server&amp;quot;: &amp;quot;lxd&amp;quot;,
      &amp;quot;server_pid&amp;quot;: 6446,
      &amp;quot;server_version&amp;quot;: &amp;quot;2.0.0&amp;quot;,
      &amp;quot;storage&amp;quot;: &amp;quot;dir&amp;quot;,
      &amp;quot;storage_version&amp;quot;: &amp;quot;&amp;quot;
    },
    &amp;quot;public&amp;quot;: false
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;sudo lxd init&lt;/code&gt; でLXDをネットワーク越しに使うかの問いにnoと答えた環境では以下のような出力になりました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -s --unix-socket /var/lib/lxd/unix.socket http:/1.0 | jq .
{
  &amp;quot;type&amp;quot;: &amp;quot;sync&amp;quot;,
  &amp;quot;status&amp;quot;: &amp;quot;Success&amp;quot;,
  &amp;quot;status_code&amp;quot;: 200,
  &amp;quot;metadata&amp;quot;: {
    &amp;quot;api_extensions&amp;quot;: [],
    &amp;quot;api_status&amp;quot;: &amp;quot;stable&amp;quot;,
    &amp;quot;api_version&amp;quot;: &amp;quot;1.0&amp;quot;,
    &amp;quot;auth&amp;quot;: &amp;quot;trusted&amp;quot;,
    &amp;quot;config&amp;quot;: {},
    &amp;quot;environment&amp;quot;: {
      &amp;quot;addresses&amp;quot;: [],
      &amp;quot;architectures&amp;quot;: [
        &amp;quot;x86_64&amp;quot;,
        &amp;quot;i686&amp;quot;
      ],
      &amp;quot;certificate&amp;quot;: &amp;quot;-----BEGIN CERTIFICATE-----\n …(略)… \n-----END CERTIFICATE-----\n&amp;quot;,
      &amp;quot;driver&amp;quot;: &amp;quot;lxc&amp;quot;,
      &amp;quot;driver_version&amp;quot;: &amp;quot;2.0.0&amp;quot;,
      &amp;quot;kernel&amp;quot;: &amp;quot;Linux&amp;quot;,
      &amp;quot;kernel_architecture&amp;quot;: &amp;quot;x86_64&amp;quot;,
      &amp;quot;kernel_version&amp;quot;: &amp;quot;4.4.0-21-generic&amp;quot;,
      &amp;quot;server&amp;quot;: &amp;quot;lxd&amp;quot;,
      &amp;quot;server_pid&amp;quot;: 2150,
      &amp;quot;server_version&amp;quot;: &amp;quot;2.0.0&amp;quot;,
      &amp;quot;storage&amp;quot;: &amp;quot;dir&amp;quot;,
      &amp;quot;storage_version&amp;quot;: &amp;quot;&amp;quot;
    },
    &amp;quot;public&amp;quot;: false
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>AnsibleのLXDコネクションプラグインを試してみた</title>
      <link>/blog/2016/05/07/tried-ansible-lxd-connection-plugin/</link>
      <pubDate>Sat, 07 May 2016 20:32:13 +0900</pubDate>
      
      <guid>/blog/2016/05/07/tried-ansible-lxd-connection-plugin/</guid>
      <description>

&lt;p&gt;LXDを使うとなるとAnsibleのLXDコネクションプラグインが欲しいなと思って&lt;a href=&#34;https://github.com/ansible/ansible&#34;&gt;ansible/ansibleのgithubのレポジトリ&lt;/a&gt;を眺めていたら &lt;a href=&#34;https://github.com/ansible/ansible/blob/fca5ba153e9258d6a9a28c418d8339d507eee81c/lib/ansible/plugins/connection/lxd.py&#34;&gt;lib/ansible/plugins/connection/lxd.py&lt;/a&gt; に既に作られていることに気付きました。&lt;/p&gt;

&lt;p&gt;ソースを見ると &lt;code&gt;lxc&lt;/code&gt; コマンドを使った実装になっていました。aptでインストールしたansible 2.0.0.2にこのファイルだけ追加して使えないか試してみたのですが、 &lt;code&gt;AttributeError: &#39;PlayContext&#39; object has no attribute &#39;executable&#39;&lt;/code&gt; というエラーが出て使えませんでした。&lt;/p&gt;

&lt;p&gt;そこでvirtualenvで環境を作ってpipでgithubのmasterのansibleをインストールして試してみました。&lt;/p&gt;

&lt;h2 id=&#34;インストール手順&#34;&gt;インストール手順&lt;/h2&gt;

&lt;p&gt;インストール手順は以下の通りです。
まず、virtualenv環境でAnsibleをインストールするのに必要なパッケージをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt update
sudo apt install -y virtualenv build-essential python-dev libffi-dev libssl-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;作業ディレクトリを作ってそこに移動し、virtualenvで環境を作ってansibleをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir ~/ansible-lxd-example
cd ~/ansible-lxd-example
virtualenv venv
. venv/bin/activate
pip install git+https://github.com/ansible/ansible
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使ってみる&#34;&gt;使ってみる&lt;/h2&gt;

&lt;p&gt;以下のような設定ファイルとテスト用のプレイブックを作りました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat ansible.cfg
[defaults]
inventory = hosts
$ cat hosts
[containers]
cent01 ansible_connection=lxd
cent02 ansible_connection=lxd
$ cat test.yml
---
- hosts: containers
  remote_user: root
  tasks:
    - debug: msg=ipv4_address={{ ansible_default_ipv4.address }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;実行してみると、問題なく動作しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ansible-playbook test.yml

PLAY [containers] **************************************************************

TASK [setup] *******************************************************************
ok: [cent01]
ok: [cent02]

TASK [debug] *******************************************************************
ok: [cent01] =&amp;gt; {
    &amp;quot;msg&amp;quot;: &amp;quot;ipv4_address=10.155.92.101&amp;quot;
}
ok: [cent02] =&amp;gt; {
    &amp;quot;msg&amp;quot;: &amp;quot;ipv4_address=10.155.92.103&amp;quot;
}

PLAY RECAP *********************************************************************
cent01                     : ok=2    changed=0    unreachable=0    failed=0
cent02                     : ok=2    changed=0    unreachable=0    failed=0

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>LXDコンテナで固定IPアドレスを使うための設定</title>
      <link>/blog/2016/05/07/how-to-use-fixed-ip-address-for-a-lxd-container/</link>
      <pubDate>Sat, 07 May 2016 18:01:51 +0900</pubDate>
      
      <guid>/blog/2016/05/07/how-to-use-fixed-ip-address-for-a-lxd-container/</guid>
      <description>

&lt;h2 id=&#34;設定まとめ&#34;&gt;設定まとめ&lt;/h2&gt;

&lt;p&gt;自分が後から参照することを想定して先に設定方法をまとめます。&lt;/p&gt;

&lt;p&gt;LXDコンテナで固定IPアドレスを使うためには以下の設定が必要です。なお、設定にはroot権限が必要です。&lt;/p&gt;

&lt;p&gt;まず &lt;code&gt;/etc/dnsmasq.conf&lt;/code&gt; に以下のようにコンテナ名に対するIPアドレスを指定します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dhcp-host=cent01,10.64.177.101
dhcp-host=cent02,10.64.177.102
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;lxd-bridge&lt;/code&gt; サービスを再起動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl restart lxd-bridge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IPアドレスを変更したコンテナを再起動します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lxc restart cent01
lxc restart cent02
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;調査メモ&#34;&gt;調査メモ&lt;/h2&gt;

&lt;p&gt;以下は調査メモです。&lt;/p&gt;

&lt;p&gt;まず &lt;a href=&#34;https://github.com/lxc/lxd/issues/1168&#34;&gt;Persistent IP for Containers · Issue #1168 · lxc/lxd&lt;/a&gt; に固定IPアドレスを使うための情報がありました。LXDで特にサポートはないが、各コンテナでDHCPを使わずに静的IPアドレスを使用するか、あるいはホストのDHCPサーバ側で設定すれば実現できるとのことです。&lt;/p&gt;

&lt;p&gt;各コンテナで静的IPアドレスを使う方法も試してみたのですが、ホストのコンテナ内から別のコンテナをコンテナ名で参照しようとすると変更前のIPアドレスで通信しようとしてしまいうまく行きませんでした。&lt;/p&gt;

&lt;p&gt;これを実現するにはホストのDHCPサーバに各コンテナのIPアドレスを把握してもらう必要があるので、後者のDHCPサーバ側で設定するほうが良いです。&lt;/p&gt;

&lt;h3 id=&#34;lxdのブリッジインターフェースとdnsmasqの設定ファイル&#34;&gt;LXDのブリッジインターフェースとdnsmasqの設定ファイル&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://insights.ubuntu.com/2016/04/07/lxd-networking-lxdbr0-explained/&#34;&gt;LXD networking: lxdbr0 explained | Ubuntu Insights&lt;/a&gt;と&lt;a href=&#34;https://gist.github.com/cronnelly/98345100afe21840267270da3283b371&#34;&gt;lxcbr0 is being replaced by lxdbr0&lt;/a&gt;によると、 LXCでは &lt;code&gt;lxcbr0&lt;/code&gt; というブリッジインターフェースを使っていましたが、LXDでは &lt;code&gt;lxdbr0&lt;/code&gt; と別のインターフェースを使うように変更されたそうです。&lt;/p&gt;

&lt;p&gt;これらの記事を見るとLXCの &lt;code&gt;lxcbr0&lt;/code&gt; はインストール時に固定のアドレスネットワークが設定されて環境によっては既存のネットワークと衝突するという問題があったので、LXD の &lt;code&gt;lxdbr0&lt;/code&gt; ではインストール時にはIPv4やIPv6のサブネットは設定せずに &lt;code&gt;sudo lxd init&lt;/code&gt; を実行したときに設定するように変更されたということのようです。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo lxd init&lt;/code&gt; で生成した &lt;code&gt;lxdbr0&lt;/code&gt; 用の設定は &lt;code&gt;/etc/default/lxd-bridge&lt;/code&gt; に保存されています。
ファイルの先頭に書かれていますが、変更したい場合は直接編集せずに &lt;code&gt;dpkg-reconfigure -p medium lxd&lt;/code&gt; を実行するのが良いそうです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/default/lxd-bridge
# WARNING: This file is generated by a debconf template!
# It is recommended to update it by using &amp;quot;dpkg-reconfigure -p medium lxd&amp;quot;

# Whether to setup a new bridge or use an existing one
USE_LXD_BRIDGE=&amp;quot;true&amp;quot;

# Bridge name
# This is still used even if USE_LXD_BRIDGE is set to false
# set to an empty value to fully disable
LXD_BRIDGE=&amp;quot;lxdbr0&amp;quot;

# Update the &amp;quot;default&amp;quot; LXD profile
UPDATE_PROFILE=&amp;quot;true&amp;quot;

# Path to an extra dnsmasq configuration file
LXD_CONFILE=&amp;quot;&amp;quot;

# DNS domain for the bridge
LXD_DOMAIN=&amp;quot;lxd&amp;quot;

# IPv4
## IPv4 address (e.g. 10.0.8.1)
LXD_IPV4_ADDR=&amp;quot;10.16.29.1&amp;quot;

## IPv4 netmask (e.g. 255.255.255.0)
LXD_IPV4_NETMASK=&amp;quot;255.255.255.0&amp;quot;

## IPv4 network (e.g. 10.0.8.0/24)
LXD_IPV4_NETWORK=&amp;quot;10.16.29.1/24&amp;quot;

## IPv4 DHCP range (e.g. 10.0.8.2,10.0.8.254)
LXD_IPV4_DHCP_RANGE=&amp;quot;10.16.29.2,10.16.29.254&amp;quot;

## IPv4 DHCP number of hosts (e.g. 250)
LXD_IPV4_DHCP_MAX=&amp;quot;252&amp;quot;

## NAT IPv4 traffic
LXD_IPV4_NAT=&amp;quot;true&amp;quot;

# IPv6
## IPv6 address (e.g. 2001:470:b368:4242::1)
LXD_IPV6_ADDR=&amp;quot;fd94:d372:e27f:2987::1&amp;quot;

## IPv6 CIDR mask (e.g. 64)
LXD_IPV6_MASK=&amp;quot;64&amp;quot;

## IPv6 network (e.g. 2001:470:b368:4242::/64)
LXD_IPV6_NETWORK=&amp;quot;fd94:d372:e27f:2987::1/64&amp;quot;

## NAT IPv6 traffic
LXD_IPV6_NAT=&amp;quot;true&amp;quot;

# Run a minimal HTTP PROXY server
LXD_IPV6_PROXY=&amp;quot;false&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このブリッジインタフェースを有効にするには &lt;code&gt;lxd-bridge.service&lt;/code&gt; を開始します。サービスの定義ファイルは以下のようになっていました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /lib/systemd/system/lxd-bridge.service
[Unit]
Description=LXD - network bridge
Documentation=man:lxd(1)
Before=lxd.service

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/lib/lxd/lxd-bridge.start
ExecStop=/usr/lib/lxd/lxd-bridge stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ExecStart&lt;/code&gt; に指定しているスクリプトの中身は以下のようになっていました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /usr/lib/lxd/lxd-bridge.start
#!/bin/sh -e

[ ! -e /etc/default/lxd-bridge ] &amp;amp;&amp;amp; exit 0

. /etc/default/lxd-bridge

# Start by bringing up the bridge
/usr/lib/lxd/lxd-bridge start

# Switch LXD in setup mode if needed
if [ &amp;quot;${UPDATE_PROFILE:-true}&amp;quot; = &amp;quot;true&amp;quot; ] &amp;amp;&amp;amp; [ -e &amp;quot;/var/lib/lxd&amp;quot; ] &amp;amp;&amp;amp; \
    ([ ! -e &amp;quot;/var/lib/lxd-bridge/timestamp&amp;quot; ] || \
     [ &amp;quot;/etc/default/lxd-bridge&amp;quot; -nt &amp;quot;/var/lib/lxd-bridge/timestamp&amp;quot; ]); then

    mkdir -p /var/lib/lxd-bridge
    touch /var/lib/lxd-bridge/timestamp

    touch /var/lib/lxd/.setup_mode
fi

exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここから呼ばれる &lt;code&gt;/usr/lib/lxd/lxd-bridge&lt;/code&gt; を見てみると、initスクリプトになっていて &lt;code&gt;iptables&lt;/code&gt;, &lt;code&gt;ip6tables&lt;/code&gt;, &lt;code&gt;dnsmasq&lt;/code&gt; を実行するようになっていました。また &lt;code&gt;/usr/lib/lxd/lxd-bridge&lt;/code&gt; は上記の &lt;code&gt;/etc/default/lxd-bridge&lt;/code&gt; を読み込むようになっています。&lt;/p&gt;

&lt;p&gt;起動された &lt;code&gt;dnsmasq&lt;/code&gt; を &lt;code&gt;ps&lt;/code&gt; で見ると以下のようなコマンドラインになっていました。&lt;/p&gt;

&lt;p&gt;$ ps auxww | grep [d]nsmasq
  lxd       2134  0.0  0.0  49984   388 ?        S    09:48   0:00 dnsmasq -s lxd -S /lxd/ -u lxd &amp;ndash;strict-order &amp;ndash;bind-interfaces &amp;ndash;pid-file=/run/lxd-bridge//dnsmasq.pid &amp;ndash;dhcp-no-override &amp;ndash;except-interface=lo &amp;ndash;interface=lxdbr0 &amp;ndash;dhcp-leasefile=/var/lib/lxd-bridge//dnsmasq.lxdbr0.leases &amp;ndash;dhcp-authoritative &amp;ndash;listen-address 10.16.29.1 &amp;ndash;dhcp-range 10.16.29.2,10.16.29.254 &amp;ndash;dhcp-lease-max=252 &amp;ndash;dhcp-range=fd94:d372:e27f:2987::1,ra-only &amp;ndash;listen-address fd94:d372:e27f:2987::1&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/usr/lib/lxd/lxd-bridge&lt;/code&gt; を見ると &lt;code&gt;/etc/default/lxd-bridge&lt;/code&gt; の &lt;code&gt;LXD_CONFILE&lt;/code&gt; にファイル名を指定しておけば &lt;code&gt;dnsmasq&lt;/code&gt; の &lt;code&gt;--conf-file&lt;/code&gt; オプションを使ってそのファイルを読み込むように書かれています。この方法を使おうかと思ったのですが、一方で &lt;code&gt;/etc/default/lxd-bridge&lt;/code&gt; の設定にかかわらず &lt;code&gt;--dhcp-authoritative&lt;/code&gt; オプションが常に指定されるように書かれています。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;man dnsmasq&lt;/code&gt; によると &lt;code&gt;--dhcp-authoritative&lt;/code&gt; オプションはネットワーク内に他にDHCPサーバが無く唯一のDHCPになっているときに指定するオプションとのことです。ホストで稼働する &lt;code&gt;dnsmasq&lt;/code&gt; が1つという前提であれば、デフォルトの設定ファイル &lt;code&gt;/etc/dnsmasq.conf&lt;/code&gt; を作ってそこに設定を書くほうが手っ取り早いので、そうすることにしました。&lt;/p&gt;

&lt;h3 id=&#34;lxd-bridge-serviceの設定変更はreloadではなくrestartが必要&#34;&gt;lxd-bridge.serviceの設定変更はreloadではなくrestartが必要&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;sudo systemctl reload lxd-bridge&lt;/code&gt; を実行してみると以下のようなエラーが出て失敗しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo systemctl reload lxd-bridge
Failed to reload lxd-bridge.service: Job type reload is not applicable for unit lxd-bridge.service.
See system logs and &#39;systemctl status lxd-bridge.service&#39; for details.
$ sudo systemctl status lxd-bridge
● lxd-bridge.service - LXD - network bridge
   Loaded: loaded (/lib/systemd/system/lxd-bridge.service; static; vendor preset: enabled)
   Active: active (exited) since 土 2016-05-07 13:06:06 JST; 6h ago
     Docs: man:lxd(1)
  Process: 3704 ExecStop=/usr/lib/lxd/lxd-bridge stop (code=exited, status=0/SUCCESS)
  Process: 3723 ExecStart=/usr/lib/lxd/lxd-bridge.start (code=exited, status=0/SUCCESS)
 Main PID: 3723 (code=exited, status=0/SUCCESS)
    Tasks: 1 (limit: 512)
   Memory: 412.0K
      CPU: 1.293s
   CGroup: /system.slice/lxd-bridge.service
           └─3755 dnsmasq -s lxd -S /lxd/ -u lxd --strict-order --bind-interfaces --pid-file=/run/lxd-bridge//dnsmasq.pid --dhcp-no-override --except-interface=lo --interface=lxdbr0 --dhcp-leasefile=/var/lib/lxd-bridge//dnsmasq.lxdbr0.leases --dhcp-authoritative --lis
 5月 07 18:56:28 express dnsmasq-dhcp[3755]: not giving name cent02 to the DHCP lease of 10.155.92.102 because the name exists in /etc/hosts with address 10.155.92.201
 5月 07 19:06:21 express dnsmasq-dhcp[3755]: DHCPREQUEST(lxdbr0) 10.155.92.102 00:16:3e:59:21:d7
 5月 07 19:06:21 express dnsmasq-dhcp[3755]: DHCPACK(lxdbr0) 10.155.92.102 00:16:3e:59:21:d7 cent02
 5月 07 19:06:21 express dnsmasq-dhcp[3755]: not giving name cent02 to the DHCP lease of 10.155.92.102 because the name exists in /etc/hosts with address 10.155.92.201
 5月 07 19:23:24 express dnsmasq-dhcp[3755]: DHCPREQUEST(lxdbr0) 10.155.92.101 00:16:3e:5f:01:7e
 5月 07 19:23:24 express dnsmasq-dhcp[3755]: DHCPACK(lxdbr0) 10.155.92.101 00:16:3e:5f:01:7e cent01
 5月 07 19:23:24 express dnsmasq-dhcp[3755]: not giving name cent02 to the DHCP lease of 10.155.92.102 because the name exists in /etc/hosts with address 10.155.92.201
 5月 07 19:33:08 express dnsmasq-dhcp[3755]: DHCPREQUEST(lxdbr0) 10.155.92.102 00:16:3e:59:21:d7
 5月 07 19:33:08 express dnsmasq-dhcp[3755]: DHCPACK(lxdbr0) 10.155.92.102 00:16:3e:59:21:d7 cent02
 5月 07 19:33:08 express dnsmasq-dhcp[3755]: not giving name cent02 to the DHCP lease of 10.155.92.102 because the name exists in /etc/hosts with address 10.155.92.201
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ということで、設定ファイルを変更反映するにも &lt;code&gt;sudo systemctl restart lxd-bridge&lt;/code&gt; のように再起動する必要があります。&lt;/p&gt;

&lt;h3 id=&#34;dnsmasqの再起動後-コンテナの再起動が必要&#34;&gt;dnsmasqの再起動後、コンテナの再起動が必要&lt;/h3&gt;

&lt;p&gt;dnsmasqを再起動しただけではコンテナのIPアドレスは変わらないのでネットワークを再起動する必要がありました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lxc exec cent01 systemctl restart network
lxc exec cent02 systemctl restart network
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナごと再起動でも良いと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lxc restart cent01
lxc restart cent02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;何回か試してみたところ、作っただけで特に何もしてないコンテナだとネットワーク再起動よりコンテナ自体を再起動するほうが速かったです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time lxc exec cent02 systemctl restart network

real    0m2.878s
user    0m0.008s
sys     0m0.000s
$ time lxc restart cent02

real    0m1.236s
user    0m0.004s
sys     0m0.004s
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>